{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Window_penalized_loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfhwWQo2ikbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OZ_CsJHR7km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sX533lPQhuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link_news = 'https://drive.google.com/open?id=1m27dY61RYh3Dk9uxe_idITMI3uN32CHx'\n",
        "link_price = 'https://drive.google.com/open?id=1C_oMK5Gk1F_aiHxyNc0L-cQg51CqdwIV'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5dbXWs7R_rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, id_news = link_news.split('=')\n",
        "_, id_price = link_price.split('=')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET5X4lzLSBTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id_news}) \n",
        "downloaded.GetContentFile('unagg_ffill_news.csv')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdtDNcpqSD-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id_price}) \n",
        "downloaded.GetContentFile('unagg_ffill_price.csv')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjyQl8XMim1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news = pd.read_csv('unagg_ffill_news.csv', index_col = 0)\n",
        "price = pd.read_csv('unagg_ffill_price.csv', index_col = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti2t_r2BUzEM",
        "colab_type": "code",
        "outputId": "97aa067d-fc43-4f2e-ee57-84f17afb8127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "news.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>event_impact_gt_mu_pos_add_sigma_pos_avg</th>\n",
              "      <th>event_impact_gt_mu_pos_add_sigma_pos_sum</th>\n",
              "      <th>event_impact_gt_mu_pos_add_sigma_pos_min</th>\n",
              "      <th>event_impact_gt_mu_pos_add_sigma_pos_max</th>\n",
              "      <th>event_impact_lt_mu_sub_sigma_avg</th>\n",
              "      <th>event_impact_lt_mu_sub_sigma_sum</th>\n",
              "      <th>event_impact_lt_mu_sub_sigma_min</th>\n",
              "      <th>event_impact_lt_mu_sub_sigma_max</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_sigma_neg_avg</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_sigma_neg_sum</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_sigma_neg_min</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_sigma_neg_max</th>\n",
              "      <th>entity_source_republish_score_avg</th>\n",
              "      <th>entity_source_republish_score_sum</th>\n",
              "      <th>entity_source_republish_score_min</th>\n",
              "      <th>entity_source_republish_score_max</th>\n",
              "      <th>event_source_timeliness_score_avg</th>\n",
              "      <th>event_source_timeliness_score_sum</th>\n",
              "      <th>event_source_timeliness_score_min</th>\n",
              "      <th>event_source_timeliness_score_max</th>\n",
              "      <th>event_impact_pct_change_avg_avg</th>\n",
              "      <th>event_impact_pct_change_avg_sum</th>\n",
              "      <th>event_impact_pct_change_avg_min</th>\n",
              "      <th>event_impact_pct_change_avg_max</th>\n",
              "      <th>story_group_traffic_sum_avg</th>\n",
              "      <th>story_group_traffic_sum_sum</th>\n",
              "      <th>story_group_traffic_sum_min</th>\n",
              "      <th>story_group_traffic_sum_max</th>\n",
              "      <th>overall_source_timeliness_score_avg</th>\n",
              "      <th>overall_source_timeliness_score_sum</th>\n",
              "      <th>overall_source_timeliness_score_min</th>\n",
              "      <th>overall_source_timeliness_score_max</th>\n",
              "      <th>event_impact_lt_1pct_neg_avg</th>\n",
              "      <th>event_impact_lt_1pct_neg_sum</th>\n",
              "      <th>event_impact_lt_1pct_neg_min</th>\n",
              "      <th>event_impact_lt_1pct_neg_max</th>\n",
              "      <th>story_traffic_avg</th>\n",
              "      <th>story_traffic_sum</th>\n",
              "      <th>story_traffic_min</th>\n",
              "      <th>...</th>\n",
              "      <th>story_group_count_avg</th>\n",
              "      <th>story_group_count_sum</th>\n",
              "      <th>story_group_count_min</th>\n",
              "      <th>story_group_count_max</th>\n",
              "      <th>event_relevance_avg</th>\n",
              "      <th>event_relevance_sum</th>\n",
              "      <th>event_relevance_min</th>\n",
              "      <th>event_relevance_max</th>\n",
              "      <th>event_impact_gt_1pct_pos_avg</th>\n",
              "      <th>event_impact_gt_1pct_pos_sum</th>\n",
              "      <th>event_impact_gt_1pct_pos_min</th>\n",
              "      <th>event_impact_gt_1pct_pos_max</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_2sigma_neg_avg</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_2sigma_neg_sum</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_2sigma_neg_min</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_2sigma_neg_max</th>\n",
              "      <th>event_author_republish_score_avg</th>\n",
              "      <th>event_author_republish_score_sum</th>\n",
              "      <th>event_author_republish_score_min</th>\n",
              "      <th>event_author_republish_score_max</th>\n",
              "      <th>event_source_republish_score_avg</th>\n",
              "      <th>event_source_republish_score_sum</th>\n",
              "      <th>event_source_republish_score_min</th>\n",
              "      <th>event_source_republish_score_max</th>\n",
              "      <th>overall_author_republish_score_avg</th>\n",
              "      <th>overall_author_republish_score_sum</th>\n",
              "      <th>overall_author_republish_score_min</th>\n",
              "      <th>overall_author_republish_score_max</th>\n",
              "      <th>event_sentiment_avg</th>\n",
              "      <th>event_sentiment_sum</th>\n",
              "      <th>event_sentiment_min</th>\n",
              "      <th>event_sentiment_max</th>\n",
              "      <th>entity_relevance_avg</th>\n",
              "      <th>entity_relevance_sum</th>\n",
              "      <th>entity_relevance_min</th>\n",
              "      <th>entity_relevance_max</th>\n",
              "      <th>count</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>dayofwork</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>44.081467</td>\n",
              "      <td>132.2444</td>\n",
              "      <td>41.8747</td>\n",
              "      <td>48.2883</td>\n",
              "      <td>0.0399</td>\n",
              "      <td>0.1197</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0576</td>\n",
              "      <td>1.826834e+11</td>\n",
              "      <td>5.480502e+11</td>\n",
              "      <td>3927884.0</td>\n",
              "      <td>5.459995e+11</td>\n",
              "      <td>50.182067</td>\n",
              "      <td>150.5462</td>\n",
              "      <td>49.0802</td>\n",
              "      <td>50.7330</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17420247.0</td>\n",
              "      <td>52260741.0</td>\n",
              "      <td>3927884.0</td>\n",
              "      <td>...</td>\n",
              "      <td>227.0</td>\n",
              "      <td>681.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>664.0</td>\n",
              "      <td>68.8</td>\n",
              "      <td>206.4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>99.9</td>\n",
              "      <td>11.111133</td>\n",
              "      <td>33.3334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.6667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.991267</td>\n",
              "      <td>2.9738</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.7946</td>\n",
              "      <td>1.4719</td>\n",
              "      <td>4.4157</td>\n",
              "      <td>1.0416</td>\n",
              "      <td>2.0318</td>\n",
              "      <td>0.985133</td>\n",
              "      <td>2.9554</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.2690</td>\n",
              "      <td>24.066667</td>\n",
              "      <td>72.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.8</td>\n",
              "      <td>96.666667</td>\n",
              "      <td>290.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>44.081467</td>\n",
              "      <td>132.2444</td>\n",
              "      <td>41.8747</td>\n",
              "      <td>48.2883</td>\n",
              "      <td>0.0399</td>\n",
              "      <td>0.1197</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0576</td>\n",
              "      <td>1.826834e+11</td>\n",
              "      <td>5.480502e+11</td>\n",
              "      <td>3927884.0</td>\n",
              "      <td>5.459995e+11</td>\n",
              "      <td>50.182067</td>\n",
              "      <td>150.5462</td>\n",
              "      <td>49.0802</td>\n",
              "      <td>50.7330</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17420247.0</td>\n",
              "      <td>52260741.0</td>\n",
              "      <td>3927884.0</td>\n",
              "      <td>...</td>\n",
              "      <td>227.0</td>\n",
              "      <td>681.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>664.0</td>\n",
              "      <td>68.8</td>\n",
              "      <td>206.4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>99.9</td>\n",
              "      <td>11.111133</td>\n",
              "      <td>33.3334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.6667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.991267</td>\n",
              "      <td>2.9738</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.7946</td>\n",
              "      <td>1.4719</td>\n",
              "      <td>4.4157</td>\n",
              "      <td>1.0416</td>\n",
              "      <td>2.0318</td>\n",
              "      <td>0.985133</td>\n",
              "      <td>2.9554</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.2690</td>\n",
              "      <td>24.066667</td>\n",
              "      <td>72.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.8</td>\n",
              "      <td>96.666667</td>\n",
              "      <td>290.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>34.793300</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>48.244200</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344400</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>0.401200</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>-15.000000</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>34.793300</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>48.244200</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344400</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>0.401200</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>-15.000000</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>34.793300</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>48.244200</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344400</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>0.401200</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>-15.000000</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 145 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  ticker  event_impact_gt_mu_pos_add_sigma_pos_avg  ...  hour  dayofwork\n",
              "0   AAPL                                       0.0  ...     0          5\n",
              "1   AAPL                                       0.0  ...     1          5\n",
              "2   AAPL                                       0.0  ...     2          5\n",
              "3   AAPL                                       0.0  ...     3          5\n",
              "4   AAPL                                       0.0  ...     4          5\n",
              "\n",
              "[5 rows x 145 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "93peXEd-VYsd",
        "colab": {}
      },
      "source": [
        "ffill = news.merge(price, how = 'left', on = ['ticker', 'day'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9u4_t4L5VYfk",
        "colab": {}
      },
      "source": [
        "ffill.drop(['date_x', 'date_y', 'open_price_change'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sGo4vr6vVXmP",
        "colab": {}
      },
      "source": [
        "ffill.fillna(method = 'ffill', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyGQ4LARmFHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ffill_train = ffill[pd.to_datetime(ffill['day']) <= datetime.datetime(2017,5,3)]\n",
        "ffill_validation = ffill[(pd.to_datetime(ffill['day']) >= datetime.datetime(2017,5,4)) & \\\n",
        "                                 (pd.to_datetime(ffill['day']) <= datetime.datetime(2018,4,4))]\n",
        "ffill_test = ffill[pd.to_datetime(ffill['day']) >= datetime.datetime(2018,4,5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SPPb3w8ztX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ffill_train.reset_index(drop = True, inplace = True)\n",
        "ffill_validation.reset_index(drop = True, inplace = True)\n",
        "ffill_test.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOo6MFKjwRNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "std = StandardScaler()\n",
        "std.fit(ffill_train.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1))\n",
        "std_train = pd.DataFrame(std.transform(ffill_train.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1)), \\\n",
        "                          columns = list(ffill_train.columns[1:142]) + list(ffill_train.columns[145:151]))\n",
        "std_val = pd.DataFrame(std.transform(ffill_validation.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1)),\\\n",
        "                        columns = list(ffill_train.columns[1:142]) + list(ffill_train.columns[145:151]))\n",
        "std_test = pd.DataFrame(std.transform(ffill_test.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1)), \\\n",
        "                         columns = list(ffill_train.columns[1:142]) + list(ffill_train.columns[145:151]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6YCuuYfwV6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_train = std_train.merge(ffill_train[['ticker','day', 'hour', 'dayofwork']], left_index = True, right_index = True)\n",
        "std_val = std_val.merge(ffill_validation[['ticker','day', 'hour', 'dayofwork']], left_index = True, right_index = True)\n",
        "std_test = std_test.merge(ffill_test[['ticker','day', 'hour', 'dayofwork']], left_index = True, right_index = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mowc2Qv0GEak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class TensoredDataset(Dataset):\n",
        "    def __init__(self, news, price):\n",
        "        self.input_tensors = []\n",
        "        self.target_tensors = []\n",
        "        \n",
        "        for ticker in news['ticker'].unique():\n",
        "            for i, day in enumerate(news['day'].unique()[:-1]):\n",
        "                second_day = str(datetime.datetime.strptime(day, '%Y-%m-%d').date() + datetime.timedelta(days=1))\n",
        "                third_day = str(datetime.datetime.strptime(day, '%Y-%m-%d').date() + datetime.timedelta(days=2)) \n",
        "                \n",
        "                input_array = news[(news['ticker'] == ticker) & (news['day'].isin([day, second_day]))].iloc[8:32]\n",
        "                self.input_tensors.append(torch.from_numpy(input_array.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1).values))\n",
        "                \n",
        "                if input_array['dayofwork'].unique()[0] <= 5:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == day)]['open_price_change']\n",
        "                    self.target_tensors.append(torch.from_numpy(target_array.values))\n",
        "                elif input_array['dayofwork'].unique()[0] == 6:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == third_day)]['open_price_change']\n",
        "                    self.target_tensors.append(torch.from_numpy(target_array.values))                    \n",
        "                elif input_array['dayofwork'].unique()[0] == 7:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == second_day)]['open_price_change']\n",
        "                    self.target_tensors.append(torch.from_numpy(target_array.values))                \n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.input_tensors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (self.input_tensors[idx], self.target_tensors[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Jwtu9Ktvz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WindowTensoredDataset(Dataset):\n",
        "    def __init__(self, news, price):\n",
        "        self.input_tensors = []\n",
        "        self.target_tensors = []\n",
        "        \n",
        "        for ticker in news['ticker'].unique():\n",
        "            for i, day in enumerate(news['day'].unique()[:-2]):\n",
        "                second_day = str(datetime.datetime.strptime(day, '%Y-%m-%d').date() + datetime.timedelta(days=1))\n",
        "                third_day = str(datetime.datetime.strptime(day, '%Y-%m-%d').date() + datetime.timedelta(days=2)) \n",
        "                fourth_day = str(datetime.datetime.strptime(day, '%Y-%m-%d').date() + datetime.timedelta(days=3))\n",
        "                \n",
        "                input_array = news[(news['ticker'] == ticker) & (news['day'].isin([day, second_day, third_day]))].iloc[9:56]\n",
        "                input_tensor = torch.from_numpy(input_array.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1).values)\n",
        "                input_window_array = input_tensor.unfold(0,24,1)\n",
        "                for window_array in input_window_array:\n",
        "                    self.input_tensors.append(window_array.T)\n",
        "                \n",
        "                if input_array['dayofwork'].unique()[1] <= 5:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == second_day)]['open_price_change']\n",
        "                    self.target_tensors += [torch.from_numpy(target_array.values)] * 24\n",
        "                elif input_array['dayofwork'].unique()[1] == 6:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == fourth_day)]['open_price_change']\n",
        "                    self.target_tensors += [torch.from_numpy(target_array.values)] * 24                   \n",
        "                elif input_array['dayofwork'].unique()[1] == 7:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == third_day)]['open_price_change']\n",
        "                    self.target_tensors += [torch.from_numpy(target_array.values)] * 24               \n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.input_tensors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (self.input_tensors[idx], self.target_tensors[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY60LIkdvaZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTM_dataset = {}\n",
        "# LSTM_dataset['train'] = WindowTensoredDataset(std_train, price)\n",
        "# LSTM_dataset['val'] = TensoredDataset(std_val, price)\n",
        "LSTM_dataset['test'] = TensoredDataset(std_test, price)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPCCDahl9pBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loaders = {}\n",
        "batch_size = 128\n",
        "\n",
        "for split, dataset in LSTM_dataset.items():\n",
        "    if split != 'test':\n",
        "        data_loaders[split] = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    else:\n",
        "        data_loaders[split] = DataLoader(dataset, batch_size=batch_size, shuffle=False)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAFMIVMjNuBA",
        "colab_type": "text"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXLB07ISmKpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def my_loss(output, target):\n",
        "    output_sign = torch.sign(output)\n",
        "    output_sign[output_sign == 0] = 1.0\n",
        "\n",
        "    target_sign = torch.sign(target)\n",
        "    target_sign[target_sign == 0] = 1.0\n",
        "\n",
        "    sign = -((torch.abs(output_sign + target_sign) - 2) / 2 - 1)\n",
        "\n",
        "    loss = torch.mean(((output - target) *sign) **2)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CkSLUjSrvyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, options):\n",
        "        super().__init__()\n",
        "        \n",
        "        # create each LM part here \n",
        "        self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], dropout=options['lstm_dropout'], batch_first=True)\n",
        "        # self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], batch_first=True)\n",
        "        self.projection = nn.Linear(options['hidden_size'], 1)\n",
        "        \n",
        "    def forward(self, inp):\n",
        "\n",
        "        lstm_outputs = self.lstm(inp)\n",
        "        \n",
        "        batch_size, sequence_size, input_size = lstm_outputs[0].size()[0], lstm_outputs[0].size()[1], lstm_outputs[0].size()[2]\n",
        "        lstm_output = lstm_outputs[0][:,-1,:].reshape(batch_size, 1, input_size)\n",
        "        \n",
        "        lr = self.projection(lstm_output)\n",
        "        \n",
        "        return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6aqdIqGPIN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "num_gpus = torch.cuda.device_count()\n",
        "if num_gpus > 0:\n",
        "    current_device = 'cuda'\n",
        "else:\n",
        "    current_device = 'cpu'\n",
        "\n",
        "dimen = 147\n",
        "hidden_size = 32\n",
        "num_layers = 5\n",
        "lstm_dropout = 0.1\n",
        "\n",
        "options = {\n",
        "    'input_size': dimen,\n",
        "    'hidden_size': hidden_size,\n",
        "    'num_layers': num_layers,\n",
        "    'lstm_dropout': lstm_dropout,\n",
        "}\n",
        "\n",
        "    \n",
        "model_lstm = LSTM(options).to(current_device)\n",
        "\n",
        "\n",
        "# model_parameters = [p for p in model_lstm.parameters() if p.requires_grad]\n",
        "# optimizer = optim.SGD(model_parameters, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx8LBCKPsN1I",
        "colab_type": "code",
        "outputId": "56ccc9e7-c2e5-4ff3-d983-d5e74e547fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model_lstm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(147, 32, num_layers=5, batch_first=True, dropout=0.1)\n",
              "  (projection): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPtCQbkFsOX4",
        "colab_type": "code",
        "outputId": "c21dcf4f-17cc-4bf7-94ef-6a93edf3e8b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "for epoch_number in range(50):\n",
        "    train_loss_cache = 10000\n",
        "    val_loss_cache = 0\n",
        "\n",
        "    model_lstm.train()\n",
        "        \n",
        "\n",
        "    for i, (inp, target) in enumerate(data_loaders['train']):\n",
        "        optimizer.zero_grad()\n",
        "        inp = inp.to(current_device)\n",
        "        target = target.to(current_device)\n",
        "        lr = model_lstm(inp.float())\n",
        "        loss = my_loss(lr.view(-1), target.float().view(-1))\n",
        "\n",
        "        if loss < train_loss_cache:\n",
        "            train_loss_cache = loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print('Step {} train customized mean square loss = {:.{prec}f}'.format(i, loss, prec=6))\n",
        "\n",
        "    train_loss_list.append(round(train_loss_cache.item(), 8))       \n",
        "    #do valid\n",
        "\n",
        "    target_list = []\n",
        "    prediction_list = []\n",
        "    \n",
        "#     valid_loss_cache = valid_loss_cache_l1 = valid_loss_cache_special = valid_accuracy_cache = 0\n",
        "#     n = 0\n",
        "    model_lstm.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inp, target) in enumerate(data_loaders['val']):\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            lr = model_lstm(inp.float())\n",
        "            prediction_list.append(lr.view(-1))\n",
        "            target_list.append(target.float().view(-1))\n",
        "#             val_loss = criterion(lr.view(-1), target.float().view(-1)) \n",
        "#             valid_loss_cache += val_loss\n",
        "            \n",
        "#             criterion_l1 = nn.L1Loss()\n",
        "#             valid_loss_l1 = criterion_l1(lr.view(-1), target.float().view(-1)) \n",
        "#             valid_loss_cache_l1 += valid_loss_l1\n",
        "            \n",
        "#             valid_loss_special = ((lr.view(-1) - target.float().view(-1)) ** 2 / (torch.abs(target.float().view(-1)) + 1)).sum()\n",
        "#             valid_loss_cache_special += valid_loss_special\n",
        "            \n",
        "#             sign_prediction = torch.sign(lr.view(-1))\n",
        "#             sign_prediction[sign_prediction == 0] = 1\n",
        "#             sign_target = torch.sign(target.float().view(-1))\n",
        "#             sign_target[sign_target == 0] = 1\n",
        "#             valid_accuracy = (((sign_prediction + sign_target).sum()/2).tolist())/(sign_prediction.size()[0])\n",
        "#             valid_accuracy_cache += valid_accuracy\n",
        "            \n",
        "#             n += 1\n",
        "        prediction_tensor = torch.cat(prediction_list)\n",
        "        target_tensor = torch.cat(target_list)\n",
        "\n",
        "        print(prediction_tensor)\n",
        "        print(target_tensor)\n",
        "            \n",
        "#         avg_val_loss = valid_loss_cache / n\n",
        "        val_loss = my_loss(prediction_tensor, target_tensor)\n",
        "        val_loss_list.append(val_loss)\n",
        "        print('Validation customized mean square loss after {} epoch = {:.{prec}f}'.format(epoch_number, val_loss, prec=8))\n",
        "        \n",
        "#         avg_val_loss_l1 = valid_loss_cache_l1 / n\n",
        "        criterion_l1 = nn.L1Loss()\n",
        "        val_loss_l1 = criterion_l1(prediction_tensor, target_tensor)\n",
        "        print('Validation mean absolute loss after {} epoch = {:.{prec}f}'.format(epoch_number, val_loss_l1, prec=8))\n",
        "    \n",
        "#         avg_val_loss_special = valid_loss_cache_special / n\n",
        "        val_loss_special = ((prediction_tensor - target_tensor) ** 2 / (torch.abs(target_tensor) + 1)).mean()\n",
        "        print('Validation special loss after {} epoch = {:.{prec}f}'.format(epoch_number, val_loss_special, prec=8))\n",
        "        \n",
        "#         avg_val_accuracy = valid_accuracy_cache / n\n",
        "        sign_prediction = torch.sign(prediction_tensor)\n",
        "        sign_prediction[sign_prediction == 0] = 1\n",
        "        sign_target = torch.sign(target_tensor)\n",
        "        sign_target[sign_target == 0] = 1\n",
        "        val_accuracy = ((torch.abs(sign_prediction + sign_target).sum()/2).tolist())/(sign_prediction.size()[0])\n",
        "        print('Validation accuracy after {} epoch = {:.{prec}f}'.format(epoch_number, val_accuracy, prec=8))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 train customized mean square loss = 0.077577\n",
            "Step 1000 train customized mean square loss = 0.000822\n",
            "Step 2000 train customized mean square loss = 0.001018\n",
            "Step 3000 train customized mean square loss = 0.000865\n",
            "Step 4000 train customized mean square loss = 0.000389\n",
            "tensor([0.0009, 0.0009, 0.0002,  ..., 0.0005, 0.0007, 0.0004], device='cuda:0')\n",
            "tensor([ 0.0037, -0.0020,  0.0179,  ..., -0.0223,  0.0492, -0.0071],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 0 epoch = 0.00055310\n",
            "Validation mean absolute loss after 0 epoch = 0.00969680\n",
            "Validation special loss after 0 epoch = 0.00021582\n",
            "Validation accuracy after 0 epoch = 0.54831108\n",
            "Step 0 train customized mean square loss = 0.000661\n",
            "Step 1000 train customized mean square loss = 0.000496\n",
            "Step 2000 train customized mean square loss = 0.000781\n",
            "Step 3000 train customized mean square loss = 0.000677\n",
            "Step 4000 train customized mean square loss = 0.000890\n",
            "tensor([ 3.2625e-04,  7.5344e-04, -9.3807e-05,  ..., -7.2103e-05,\n",
            "         3.7122e-04,  3.4712e-04], device='cuda:0')\n",
            "tensor([-0.0052, -0.0313, -0.0437,  ..., -0.0030, -0.0265,  0.0054],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 1 epoch = 0.00055734\n",
            "Validation mean absolute loss after 1 epoch = 0.00969703\n",
            "Validation special loss after 1 epoch = 0.00021586\n",
            "Validation accuracy after 1 epoch = 0.54454046\n",
            "Step 0 train customized mean square loss = 0.000746\n",
            "Step 1000 train customized mean square loss = 0.000558\n",
            "Step 2000 train customized mean square loss = 0.000391\n",
            "Step 3000 train customized mean square loss = 0.000513\n",
            "Step 4000 train customized mean square loss = 0.000586\n",
            "tensor([-8.1630e-04, -1.9580e-05,  7.9518e-04,  ...,  7.9877e-04,\n",
            "         5.6279e-04, -6.4635e-04], device='cuda:0')\n",
            "tensor([ 0.0118,  0.0096, -0.0001,  ..., -0.0053, -0.0068, -0.0042],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 2 epoch = 0.00055537\n",
            "Validation mean absolute loss after 2 epoch = 0.00969855\n",
            "Validation special loss after 2 epoch = 0.00021592\n",
            "Validation accuracy after 2 epoch = 0.54108405\n",
            "Step 0 train customized mean square loss = 0.000331\n",
            "Step 1000 train customized mean square loss = 0.000636\n",
            "Step 2000 train customized mean square loss = 0.000722\n",
            "Step 3000 train customized mean square loss = 0.000511\n",
            "Step 4000 train customized mean square loss = 0.000456\n",
            "tensor([ 4.9548e-04, -9.3423e-05, -4.6939e-06,  ..., -4.6606e-04,\n",
            "         3.0241e-04,  5.7881e-04], device='cuda:0')\n",
            "tensor([ 0.0086,  0.0096,  0.0000,  ...,  0.0085, -0.0126,  0.0015],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 3 epoch = 0.00055533\n",
            "Validation mean absolute loss after 3 epoch = 0.00969717\n",
            "Validation special loss after 3 epoch = 0.00021592\n",
            "Validation accuracy after 3 epoch = 0.54155538\n",
            "Step 0 train customized mean square loss = 0.000522\n",
            "Step 1000 train customized mean square loss = 0.000743\n",
            "Step 2000 train customized mean square loss = 0.000528\n",
            "Step 3000 train customized mean square loss = 0.000590\n",
            "Step 4000 train customized mean square loss = 0.000627\n",
            "tensor([0.0003, 0.0005, 0.0004,  ..., 0.0001, 0.0001, 0.0007], device='cuda:0')\n",
            "tensor([ 0.0338, -0.0050,  0.0174,  ...,  0.0060,  0.0086,  0.0114],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 4 epoch = 0.00055456\n",
            "Validation mean absolute loss after 4 epoch = 0.00969233\n",
            "Validation special loss after 4 epoch = 0.00021584\n",
            "Validation accuracy after 4 epoch = 0.55051060\n",
            "Step 0 train customized mean square loss = 0.000662\n",
            "Step 1000 train customized mean square loss = 0.001027\n",
            "Step 2000 train customized mean square loss = 0.000474\n",
            "Step 3000 train customized mean square loss = 0.000497\n",
            "Step 4000 train customized mean square loss = 0.000558\n",
            "tensor([-8.7636e-05,  3.9035e-04,  3.2674e-04,  ...,  8.5320e-04,\n",
            "         5.9464e-04,  8.4724e-04], device='cuda:0')\n",
            "tensor([-0.0140,  0.0105,  0.0046,  ...,  0.0208,  0.0106, -0.0061],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 5 epoch = 0.00055268\n",
            "Validation mean absolute loss after 5 epoch = 0.00969080\n",
            "Validation special loss after 5 epoch = 0.00021582\n",
            "Validation accuracy after 5 epoch = 0.55223881\n",
            "Step 0 train customized mean square loss = 0.000409\n",
            "Step 1000 train customized mean square loss = 0.000271\n",
            "Step 2000 train customized mean square loss = 0.000882\n",
            "Step 3000 train customized mean square loss = 0.000779\n",
            "Step 4000 train customized mean square loss = 0.000648\n",
            "tensor([ 3.8870e-04,  2.6369e-04,  5.4806e-04,  ...,  4.4545e-05,\n",
            "        -8.9215e-04, -2.1022e-04], device='cuda:0')\n",
            "tensor([ 0.0088, -0.0061, -0.0048,  ...,  0.0038,  0.0298, -0.0003],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 6 epoch = 0.00054413\n",
            "Validation mean absolute loss after 6 epoch = 0.00971666\n",
            "Validation special loss after 6 epoch = 0.00021635\n",
            "Validation accuracy after 6 epoch = 0.51264729\n",
            "Step 0 train customized mean square loss = 0.000592\n",
            "Step 1000 train customized mean square loss = 0.000487\n",
            "Step 2000 train customized mean square loss = 0.000525\n",
            "Step 3000 train customized mean square loss = 0.000523\n",
            "Step 4000 train customized mean square loss = 0.000832\n",
            "tensor([-0.0001, -0.0005,  0.0007,  ...,  0.0006,  0.0007,  0.0002],\n",
            "       device='cuda:0')\n",
            "tensor([-0.0003,  0.0683,  0.0100,  ...,  0.0025, -0.0045,  0.0051],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 7 epoch = 0.00055192\n",
            "Validation mean absolute loss after 7 epoch = 0.00968866\n",
            "Validation special loss after 7 epoch = 0.00021580\n",
            "Validation accuracy after 7 epoch = 0.55648075\n",
            "Step 0 train customized mean square loss = 0.000384\n",
            "Step 1000 train customized mean square loss = 0.000416\n",
            "Step 2000 train customized mean square loss = 0.000827\n",
            "Step 3000 train customized mean square loss = 0.000522\n",
            "Step 4000 train customized mean square loss = 0.000616\n",
            "tensor([ 9.6771e-04,  5.0948e-04,  2.1632e-04,  ...,  5.5381e-04,\n",
            "         4.2137e-04, -1.9034e-05], device='cuda:0')\n",
            "tensor([ 0.0086, -0.0110,  0.0075,  ...,  0.0840, -0.0077,  0.0076],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 8 epoch = 0.00054995\n",
            "Validation mean absolute loss after 8 epoch = 0.00969005\n",
            "Validation special loss after 8 epoch = 0.00021585\n",
            "Validation accuracy after 8 epoch = 0.55161037\n",
            "Step 0 train customized mean square loss = 0.000483\n",
            "Step 1000 train customized mean square loss = 0.000633\n",
            "Step 2000 train customized mean square loss = 0.000646\n",
            "Step 3000 train customized mean square loss = 0.000526\n",
            "Step 4000 train customized mean square loss = 0.000451\n",
            "tensor([ 1.0563e-04, -3.5083e-05,  4.5172e-04,  ..., -1.9524e-04,\n",
            "         3.8018e-04,  5.3371e-04], device='cuda:0')\n",
            "tensor([-0.0026,  0.0039,  0.0151,  ...,  0.0024, -0.0143,  0.0079],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 9 epoch = 0.00054633\n",
            "Validation mean absolute loss after 9 epoch = 0.00969341\n",
            "Validation special loss after 9 epoch = 0.00021593\n",
            "Validation accuracy after 9 epoch = 0.55066771\n",
            "Step 0 train customized mean square loss = 0.000417\n",
            "Step 1000 train customized mean square loss = 0.000567\n",
            "Step 2000 train customized mean square loss = 0.000559\n",
            "Step 3000 train customized mean square loss = 0.000789\n",
            "Step 4000 train customized mean square loss = 0.001303\n",
            "tensor([ 3.3157e-05,  1.3882e-04,  7.0941e-05,  ..., -6.9547e-05,\n",
            "         2.2782e-04,  1.3509e-04], device='cuda:0')\n",
            "tensor([ 0.0042,  0.0055,  0.0221,  ..., -0.0031,  0.0028, -0.0029],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 10 epoch = 0.00054004\n",
            "Validation mean absolute loss after 10 epoch = 0.00970538\n",
            "Validation special loss after 10 epoch = 0.00021618\n",
            "Validation accuracy after 10 epoch = 0.52521603\n",
            "Step 0 train customized mean square loss = 0.000391\n",
            "Step 1000 train customized mean square loss = 0.001156\n",
            "Step 2000 train customized mean square loss = 0.000494\n",
            "Step 3000 train customized mean square loss = 0.001730\n",
            "Step 4000 train customized mean square loss = 0.000501\n",
            "tensor([0.0006, 0.0005, 0.0009,  ..., 0.0007, 0.0003, 0.0005], device='cuda:0')\n",
            "tensor([-0.0287,  0.0043, -0.0182,  ...,  0.0127, -0.0123, -0.0037],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 11 epoch = 0.00055354\n",
            "Validation mean absolute loss after 11 epoch = 0.00968618\n",
            "Validation special loss after 11 epoch = 0.00021578\n",
            "Validation accuracy after 11 epoch = 0.55962294\n",
            "Step 0 train customized mean square loss = 0.000520\n",
            "Step 1000 train customized mean square loss = 0.000879\n",
            "Step 2000 train customized mean square loss = 0.000511\n",
            "Step 3000 train customized mean square loss = 0.000410\n",
            "Step 4000 train customized mean square loss = 0.000452\n",
            "tensor([-1.2693e-04,  2.1979e-04,  9.5807e-05,  ...,  2.6541e-04,\n",
            "        -5.7155e-05,  4.0126e-04], device='cuda:0')\n",
            "tensor([ 0.0075,  0.0000, -0.0026,  ...,  0.0041, -0.0147, -0.0022],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 12 epoch = 0.00054503\n",
            "Validation mean absolute loss after 12 epoch = 0.00971466\n",
            "Validation special loss after 12 epoch = 0.00021636\n",
            "Validation accuracy after 12 epoch = 0.51076198\n",
            "Step 0 train customized mean square loss = 0.000395\n",
            "Step 1000 train customized mean square loss = 0.000475\n",
            "Step 2000 train customized mean square loss = 0.000647\n",
            "Step 3000 train customized mean square loss = 0.000569\n",
            "Step 4000 train customized mean square loss = 0.000344\n",
            "tensor([3.5614e-06, 3.5881e-04, 5.2693e-04,  ..., 5.3050e-05, 6.6292e-04,\n",
            "        4.7167e-04], device='cuda:0')\n",
            "tensor([-0.0265,  0.0065,  0.0074,  ...,  0.0202, -0.0096,  0.0042],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 13 epoch = 0.00054961\n",
            "Validation mean absolute loss after 13 epoch = 0.00968916\n",
            "Validation special loss after 13 epoch = 0.00021586\n",
            "Validation accuracy after 13 epoch = 0.55365279\n",
            "Step 0 train customized mean square loss = 0.000572\n",
            "Step 1000 train customized mean square loss = 0.000373\n",
            "Step 2000 train customized mean square loss = 0.000518\n",
            "Step 3000 train customized mean square loss = 0.000897\n",
            "Step 4000 train customized mean square loss = 0.000422\n",
            "tensor([-2.7016e-04,  9.2069e-05, -1.1777e-04,  ...,  1.1044e-04,\n",
            "        -5.7105e-05, -3.9912e-04], device='cuda:0')\n",
            "tensor([-0.0005, -0.0005, -0.0015,  ...,  0.0042,  0.0061,  0.0187],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 14 epoch = 0.00054024\n",
            "Validation mean absolute loss after 14 epoch = 0.00971003\n",
            "Validation special loss after 14 epoch = 0.00021629\n",
            "Validation accuracy after 14 epoch = 0.51484682\n",
            "Step 0 train customized mean square loss = 0.000704\n",
            "Step 1000 train customized mean square loss = 0.000581\n",
            "Step 2000 train customized mean square loss = 0.000539\n",
            "Step 3000 train customized mean square loss = 0.000435\n",
            "Step 4000 train customized mean square loss = 0.000458\n",
            "tensor([-1.0725e-04,  1.8483e-04,  8.3175e-05,  ...,  5.2088e-04,\n",
            "         2.7419e-04,  4.9681e-04], device='cuda:0')\n",
            "tensor([ 0.0002,  0.0207,  0.0041,  ...,  0.0025, -0.0033,  0.0077],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 15 epoch = 0.00054950\n",
            "Validation mean absolute loss after 15 epoch = 0.00968862\n",
            "Validation special loss after 15 epoch = 0.00021586\n",
            "Validation accuracy after 15 epoch = 0.55506677\n",
            "Step 0 train customized mean square loss = 0.000322\n",
            "Step 1000 train customized mean square loss = 0.000600\n",
            "Step 2000 train customized mean square loss = 0.000364\n",
            "Step 3000 train customized mean square loss = 0.000606\n",
            "Step 4000 train customized mean square loss = 0.000773\n",
            "tensor([4.1051e-04, 1.3718e-04, 1.7753e-04,  ..., 5.7308e-04, 2.2418e-04,\n",
            "        7.2777e-05], device='cuda:0')\n",
            "tensor([ 0.0003,  0.0015, -0.0006,  ...,  0.0007,  0.0338, -0.0012],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 16 epoch = 0.00054916\n",
            "Validation mean absolute loss after 16 epoch = 0.00969817\n",
            "Validation special loss after 16 epoch = 0.00021607\n",
            "Validation accuracy after 16 epoch = 0.54469756\n",
            "Step 0 train customized mean square loss = 0.000885\n",
            "Step 1000 train customized mean square loss = 0.000867\n",
            "Step 2000 train customized mean square loss = 0.001011\n",
            "Step 3000 train customized mean square loss = 0.000849\n",
            "Step 4000 train customized mean square loss = 0.000458\n",
            "tensor([ 2.3512e-04,  1.7856e-04, -4.2558e-05,  ...,  7.4623e-05,\n",
            "        -1.1433e-04,  1.4905e-04], device='cuda:0')\n",
            "tensor([ 0.0340,  0.0059,  0.0082,  ...,  0.0054,  0.0348, -0.0004],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 17 epoch = 0.00053455\n",
            "Validation mean absolute loss after 17 epoch = 0.00970067\n",
            "Validation special loss after 17 epoch = 0.00021613\n",
            "Validation accuracy after 17 epoch = 0.54202671\n",
            "Step 0 train customized mean square loss = 0.000337\n",
            "Step 1000 train customized mean square loss = 0.000477\n",
            "Step 2000 train customized mean square loss = 0.000456\n",
            "Step 3000 train customized mean square loss = 0.000575\n",
            "Step 4000 train customized mean square loss = 0.000565\n",
            "tensor([ 3.1301e-04,  9.1327e-05, -1.0252e-04,  ...,  1.4348e-04,\n",
            "         1.2140e-04,  8.8159e-05], device='cuda:0')\n",
            "tensor([-0.0096,  0.0049, -0.0055,  ...,  0.0094,  0.0064,  0.0146],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 18 epoch = 0.00054513\n",
            "Validation mean absolute loss after 18 epoch = 0.00969561\n",
            "Validation special loss after 18 epoch = 0.00021603\n",
            "Validation accuracy after 18 epoch = 0.55161037\n",
            "Step 0 train customized mean square loss = 0.000483\n",
            "Step 1000 train customized mean square loss = 0.000961\n",
            "Step 2000 train customized mean square loss = 0.000748\n",
            "Step 3000 train customized mean square loss = 0.000604\n",
            "Step 4000 train customized mean square loss = 0.000447\n",
            "tensor([-4.0497e-04,  2.4792e-05,  4.1209e-04,  ...,  8.4203e-05,\n",
            "        -3.6854e-05,  1.4413e-04], device='cuda:0')\n",
            "tensor([0.0045, 0.0076, 0.0051,  ..., 0.0099, 0.0046, 0.0190], device='cuda:0')\n",
            "Validation customized mean square loss after 19 epoch = 0.00054142\n",
            "Validation mean absolute loss after 19 epoch = 0.00970728\n",
            "Validation special loss after 19 epoch = 0.00021626\n",
            "Validation accuracy after 19 epoch = 0.52191673\n",
            "Step 0 train customized mean square loss = 0.000644\n",
            "Step 1000 train customized mean square loss = 0.000592\n",
            "Step 2000 train customized mean square loss = 0.000405\n",
            "Step 3000 train customized mean square loss = 0.000439\n",
            "Step 4000 train customized mean square loss = 0.000554\n",
            "tensor([ 8.5697e-05,  6.9458e-06, -5.9234e-04,  ...,  1.5829e-04,\n",
            "         3.9163e-04,  3.7281e-04], device='cuda:0')\n",
            "tensor([ 0.0078, -0.0026, -0.0030,  ...,  0.0055, -0.0031,  0.0040],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 20 epoch = 0.00054224\n",
            "Validation mean absolute loss after 20 epoch = 0.00970702\n",
            "Validation special loss after 20 epoch = 0.00021626\n",
            "Validation accuracy after 20 epoch = 0.52348782\n",
            "Step 0 train customized mean square loss = 0.000793\n",
            "Step 1000 train customized mean square loss = 0.001393\n",
            "Step 2000 train customized mean square loss = 0.000454\n",
            "Step 3000 train customized mean square loss = 0.001035\n",
            "Step 4000 train customized mean square loss = 0.000534\n",
            "tensor([ 4.5709e-04,  5.6796e-05,  8.1232e-05,  ...,  3.4918e-04,\n",
            "         3.9563e-04, -1.5124e-04], device='cuda:0')\n",
            "tensor([-0.0056, -0.0094,  0.0000,  ..., -0.0002, -0.0049, -0.0202],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 21 epoch = 0.00054562\n",
            "Validation mean absolute loss after 21 epoch = 0.00969648\n",
            "Validation special loss after 21 epoch = 0.00021606\n",
            "Validation accuracy after 21 epoch = 0.55019639\n",
            "Step 0 train customized mean square loss = 0.000572\n",
            "Step 1000 train customized mean square loss = 0.000515\n",
            "Step 2000 train customized mean square loss = 0.001060\n",
            "Step 3000 train customized mean square loss = 0.000619\n",
            "Step 4000 train customized mean square loss = 0.000760\n",
            "tensor([-4.8136e-05, -1.4581e-04, -5.3823e-05,  ...,  9.8411e-05,\n",
            "         2.3352e-04,  2.3136e-04], device='cuda:0')\n",
            "tensor([0.0091, 0.0004, 0.0000,  ..., 0.0116, 0.0145, 0.0100], device='cuda:0')\n",
            "Validation customized mean square loss after 22 epoch = 0.00054293\n",
            "Validation mean absolute loss after 22 epoch = 0.00970064\n",
            "Validation special loss after 22 epoch = 0.00021614\n",
            "Validation accuracy after 22 epoch = 0.54108405\n",
            "Step 0 train customized mean square loss = 0.000955\n",
            "Step 1000 train customized mean square loss = 0.000808\n",
            "Step 2000 train customized mean square loss = 0.000558\n",
            "Step 3000 train customized mean square loss = 0.000474\n",
            "Step 4000 train customized mean square loss = 0.000830\n",
            "tensor([4.0622e-05, 3.7774e-06, 3.6496e-04,  ..., 1.8173e-04, 3.4273e-04,\n",
            "        2.5120e-04], device='cuda:0')\n",
            "tensor([-0.0059,  0.0136,  0.0054,  ...,  0.0045, -0.0017,  0.0031],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 23 epoch = 0.00054708\n",
            "Validation mean absolute loss after 23 epoch = 0.00969934\n",
            "Validation special loss after 23 epoch = 0.00021612\n",
            "Validation accuracy after 23 epoch = 0.54155538\n",
            "Step 0 train customized mean square loss = 0.000510\n",
            "Step 1000 train customized mean square loss = 0.000632\n",
            "Step 2000 train customized mean square loss = 0.000802\n",
            "Step 3000 train customized mean square loss = 0.000312\n",
            "Step 4000 train customized mean square loss = 0.000584\n",
            "tensor([ 6.8691e-05, -3.6598e-04, -2.6546e-04,  ...,  2.2259e-05,\n",
            "        -2.8459e-04,  1.1585e-04], device='cuda:0')\n",
            "tensor([-0.0092,  0.0033, -0.0095,  ...,  0.0047, -0.0338,  0.0052],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 24 epoch = 0.00055189\n",
            "Validation mean absolute loss after 24 epoch = 0.00972809\n",
            "Validation special loss after 24 epoch = 0.00021664\n",
            "Validation accuracy after 24 epoch = 0.47117046\n",
            "Step 0 train customized mean square loss = 0.000414\n",
            "Step 1000 train customized mean square loss = 0.000674\n",
            "Step 2000 train customized mean square loss = 0.000532\n",
            "Step 3000 train customized mean square loss = 0.000780\n",
            "Step 4000 train customized mean square loss = 0.000435\n",
            "tensor([-5.1426e-05,  3.6089e-05,  2.9646e-04,  ...,  7.6972e-05,\n",
            "         3.3399e-05,  2.1590e-04], device='cuda:0')\n",
            "tensor([ 0.0024,  0.0092, -0.0105,  ...,  0.0271, -0.0294, -0.0141],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 25 epoch = 0.00054282\n",
            "Validation mean absolute loss after 25 epoch = 0.00971140\n",
            "Validation special loss after 25 epoch = 0.00021636\n",
            "Validation accuracy after 25 epoch = 0.50589159\n",
            "Step 0 train customized mean square loss = 0.000605\n",
            "Step 1000 train customized mean square loss = 0.000629\n",
            "Step 2000 train customized mean square loss = 0.000672\n",
            "Step 3000 train customized mean square loss = 0.000813\n",
            "Step 4000 train customized mean square loss = 0.000439\n",
            "tensor([ 1.1285e-04,  3.0866e-04,  4.9945e-05,  ...,  1.2570e-04,\n",
            "         7.4338e-05, -3.9908e-04], device='cuda:0')\n",
            "tensor([ 0.0003,  0.0069, -0.0226,  ..., -0.0145, -0.0074, -0.0064],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 26 epoch = 0.00054588\n",
            "Validation mean absolute loss after 26 epoch = 0.00969920\n",
            "Validation special loss after 26 epoch = 0.00021613\n",
            "Validation accuracy after 26 epoch = 0.54344069\n",
            "Step 0 train customized mean square loss = 0.000400\n",
            "Step 1000 train customized mean square loss = 0.000630\n",
            "Step 2000 train customized mean square loss = 0.000666\n",
            "Step 3000 train customized mean square loss = 0.000581\n",
            "Step 4000 train customized mean square loss = 0.000510\n",
            "tensor([2.2460e-04, 1.1672e-04, 4.3446e-04,  ..., 4.7068e-04, 4.1250e-05,\n",
            "        3.8824e-04], device='cuda:0')\n",
            "tensor([-0.0953,  0.0007,  0.0011,  ..., -0.0019,  0.0104, -0.0045],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 27 epoch = 0.00054614\n",
            "Validation mean absolute loss after 27 epoch = 0.00969872\n",
            "Validation special loss after 27 epoch = 0.00021612\n",
            "Validation accuracy after 27 epoch = 0.54548311\n",
            "Step 0 train customized mean square loss = 0.000723\n",
            "Step 1000 train customized mean square loss = 0.000674\n",
            "Step 2000 train customized mean square loss = 0.000782\n",
            "Step 3000 train customized mean square loss = 0.000826\n",
            "Step 4000 train customized mean square loss = 0.000535\n",
            "tensor([2.3660e-04, 4.6549e-05, 2.4772e-04,  ..., 1.1208e-04, 4.6044e-04,\n",
            "        1.7312e-04], device='cuda:0')\n",
            "tensor([-0.0020,  0.0007,  0.0100,  ..., -0.0012,  0.0018, -0.0003],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 28 epoch = 0.00054668\n",
            "Validation mean absolute loss after 28 epoch = 0.00969776\n",
            "Validation special loss after 28 epoch = 0.00021610\n",
            "Validation accuracy after 28 epoch = 0.54831108\n",
            "Step 0 train customized mean square loss = 0.000464\n",
            "Step 1000 train customized mean square loss = 0.000401\n",
            "Step 2000 train customized mean square loss = 0.000459\n",
            "Step 3000 train customized mean square loss = 0.000448\n",
            "Step 4000 train customized mean square loss = 0.000475\n",
            "tensor([-8.0602e-05,  1.2450e-04,  3.7946e-04,  ...,  1.4992e-04,\n",
            "        -3.8426e-05,  2.4360e-04], device='cuda:0')\n",
            "tensor([-0.0153, -0.0019,  0.0083,  ...,  0.0011, -0.0067,  0.0033],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 29 epoch = 0.00054692\n",
            "Validation mean absolute loss after 29 epoch = 0.00969924\n",
            "Validation special loss after 29 epoch = 0.00021613\n",
            "Validation accuracy after 29 epoch = 0.54296936\n",
            "Step 0 train customized mean square loss = 0.000332\n",
            "Step 1000 train customized mean square loss = 0.000448\n",
            "Step 2000 train customized mean square loss = 0.000493\n",
            "Step 3000 train customized mean square loss = 0.000872\n",
            "Step 4000 train customized mean square loss = 0.000688\n",
            "tensor([ 1.7475e-04,  6.9005e-05,  3.0436e-04,  ..., -7.6422e-05,\n",
            "         2.0845e-05,  2.4196e-04], device='cuda:0')\n",
            "tensor([ 0.0015, -0.0117, -0.0265,  ...,  0.0000,  0.0155, -0.0023],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 30 epoch = 0.00054459\n",
            "Validation mean absolute loss after 30 epoch = 0.00969752\n",
            "Validation special loss after 30 epoch = 0.00021610\n",
            "Validation accuracy after 30 epoch = 0.55113904\n",
            "Step 0 train customized mean square loss = 0.000463\n",
            "Step 1000 train customized mean square loss = 0.000464\n",
            "Step 2000 train customized mean square loss = 0.000417\n",
            "Step 3000 train customized mean square loss = 0.000779\n",
            "Step 4000 train customized mean square loss = 0.000570\n",
            "tensor([3.5027e-04, 2.7206e-04, 2.9909e-04,  ..., 1.2195e-05, 2.3322e-04,\n",
            "        1.9711e-04], device='cuda:0')\n",
            "tensor([-0.0037, -0.0046,  0.0009,  ...,  0.0100,  0.0266, -0.0079],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 31 epoch = 0.00054422\n",
            "Validation mean absolute loss after 31 epoch = 0.00969749\n",
            "Validation special loss after 31 epoch = 0.00021610\n",
            "Validation accuracy after 31 epoch = 0.55113904\n",
            "Step 0 train customized mean square loss = 0.000357\n",
            "Step 1000 train customized mean square loss = 0.000466\n",
            "Step 2000 train customized mean square loss = 0.000407\n",
            "Step 3000 train customized mean square loss = 0.000625\n",
            "Step 4000 train customized mean square loss = 0.000445\n",
            "tensor([ 1.9792e-04,  8.8198e-05, -8.2348e-06,  ..., -1.3818e-04,\n",
            "         2.4022e-04, -1.1283e-04], device='cuda:0')\n",
            "tensor([-0.0187,  0.0164,  0.0033,  ..., -0.0018,  0.0018, -0.0145],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 32 epoch = 0.00055965\n",
            "Validation mean absolute loss after 32 epoch = 0.00971791\n",
            "Validation special loss after 32 epoch = 0.00021649\n",
            "Validation accuracy after 32 epoch = 0.48970935\n",
            "Step 0 train customized mean square loss = 0.000220\n",
            "Step 1000 train customized mean square loss = 0.000446\n",
            "Step 2000 train customized mean square loss = 0.000437\n",
            "Step 3000 train customized mean square loss = 0.000453\n",
            "Step 4000 train customized mean square loss = 0.000700\n",
            "tensor([ 8.3771e-05,  2.4108e-04,  1.5510e-04,  ...,  1.7122e-04,\n",
            "        -3.8335e-05,  2.7282e-04], device='cuda:0')\n",
            "tensor([-0.0034, -0.0135, -0.0003,  ...,  0.0089,  0.0040,  0.0125],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 33 epoch = 0.00053832\n",
            "Validation mean absolute loss after 33 epoch = 0.00970182\n",
            "Validation special loss after 33 epoch = 0.00021619\n",
            "Validation accuracy after 33 epoch = 0.53794187\n",
            "Step 0 train customized mean square loss = 0.000546\n",
            "Step 1000 train customized mean square loss = 0.000968\n",
            "Step 2000 train customized mean square loss = 0.000685\n",
            "Step 3000 train customized mean square loss = 0.000466\n",
            "Step 4000 train customized mean square loss = 0.000632\n",
            "tensor([ 1.0422e-04,  2.0817e-04, -1.3184e-04,  ...,  1.0611e-04,\n",
            "        -1.1373e-04,  7.6639e-05], device='cuda:0')\n",
            "tensor([ 0.0008, -0.0145,  0.0020,  ...,  0.0175,  0.0141,  0.0035],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 34 epoch = 0.00054396\n",
            "Validation mean absolute loss after 34 epoch = 0.00970837\n",
            "Validation special loss after 34 epoch = 0.00021632\n",
            "Validation accuracy after 34 epoch = 0.51673213\n",
            "Step 0 train customized mean square loss = 0.000572\n",
            "Step 1000 train customized mean square loss = 0.000452\n",
            "Step 2000 train customized mean square loss = 0.000408\n",
            "Step 3000 train customized mean square loss = 0.000576\n",
            "Step 4000 train customized mean square loss = 0.000398\n",
            "tensor([ 4.4443e-05,  1.1170e-05,  9.8173e-05,  ...,  2.8523e-04,\n",
            "        -4.6847e-04, -1.4640e-05], device='cuda:0')\n",
            "tensor([-0.0052,  0.0021,  0.0058,  ..., -0.0317, -0.0037, -0.0103],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 35 epoch = 0.00054007\n",
            "Validation mean absolute loss after 35 epoch = 0.00970496\n",
            "Validation special loss after 35 epoch = 0.00021626\n",
            "Validation accuracy after 35 epoch = 0.52882954\n",
            "Step 0 train customized mean square loss = 0.000500\n",
            "Step 1000 train customized mean square loss = 0.000342\n",
            "Step 2000 train customized mean square loss = 0.000447\n",
            "Step 3000 train customized mean square loss = 0.000396\n",
            "Step 4000 train customized mean square loss = 0.000559\n",
            "tensor([ 1.3067e-04,  8.4490e-05, -2.2852e-04,  ...,  3.0849e-04,\n",
            "         3.0312e-04,  2.2850e-04], device='cuda:0')\n",
            "tensor([ 0.0028,  0.0131, -0.0125,  ...,  0.0015,  0.0119,  0.0008],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 36 epoch = 0.00053834\n",
            "Validation mean absolute loss after 36 epoch = 0.00969769\n",
            "Validation special loss after 36 epoch = 0.00021611\n",
            "Validation accuracy after 36 epoch = 0.55051060\n",
            "Step 0 train customized mean square loss = 0.000833\n",
            "Step 1000 train customized mean square loss = 0.000598\n",
            "Step 2000 train customized mean square loss = 0.000440\n",
            "Step 3000 train customized mean square loss = 0.000436\n",
            "Step 4000 train customized mean square loss = 0.000362\n",
            "tensor([ 3.3353e-05, -1.6406e-04,  4.4771e-05,  ..., -1.4875e-04,\n",
            "         1.7617e-04, -1.7570e-04], device='cuda:0')\n",
            "tensor([ 0.0073, -0.0040, -0.0035,  ...,  0.0039,  0.0059,  0.0165],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 37 epoch = 0.00055139\n",
            "Validation mean absolute loss after 37 epoch = 0.00972279\n",
            "Validation special loss after 37 epoch = 0.00021657\n",
            "Validation accuracy after 37 epoch = 0.47604085\n",
            "Step 0 train customized mean square loss = 0.001127\n",
            "Step 1000 train customized mean square loss = 0.000713\n",
            "Step 2000 train customized mean square loss = 0.000425\n",
            "Step 3000 train customized mean square loss = 0.000914\n",
            "Step 4000 train customized mean square loss = 0.000450\n",
            "tensor([-1.7740e-05,  1.4597e-04,  2.0761e-04,  ...,  2.4809e-04,\n",
            "         1.9454e-04,  2.7747e-04], device='cuda:0')\n",
            "tensor([ 0.0089,  0.0037,  0.0098,  ...,  0.0057, -0.0051, -0.0012],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 38 epoch = 0.00054414\n",
            "Validation mean absolute loss after 38 epoch = 0.00970560\n",
            "Validation special loss after 38 epoch = 0.00021628\n",
            "Validation accuracy after 38 epoch = 0.52757266\n",
            "Step 0 train customized mean square loss = 0.000463\n",
            "Step 1000 train customized mean square loss = 0.001209\n",
            "Step 2000 train customized mean square loss = 0.000430\n",
            "Step 3000 train customized mean square loss = 0.000343\n",
            "Step 4000 train customized mean square loss = 0.000316\n",
            "tensor([2.2404e-04, 2.6906e-04, 1.8791e-04,  ..., 3.5329e-04, 3.2559e-06,\n",
            "        9.0266e-05], device='cuda:0')\n",
            "tensor([-0.0188, -0.0076,  0.0077,  ...,  0.0102,  0.0151,  0.0122],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 39 epoch = 0.00054523\n",
            "Validation mean absolute loss after 39 epoch = 0.00969877\n",
            "Validation special loss after 39 epoch = 0.00021614\n",
            "Validation accuracy after 39 epoch = 0.54532600\n",
            "Step 0 train customized mean square loss = 0.000468\n",
            "Step 1000 train customized mean square loss = 0.000356\n",
            "Step 2000 train customized mean square loss = 0.000471\n",
            "Step 3000 train customized mean square loss = 0.000329\n",
            "Step 4000 train customized mean square loss = 0.000491\n",
            "tensor([-4.7348e-05, -2.2536e-04,  3.2518e-05,  ..., -1.2586e-04,\n",
            "        -1.7846e-05, -2.0542e-04], device='cuda:0')\n",
            "tensor([-0.0096,  0.0146, -0.0164,  ...,  0.0081, -0.0060,  0.0137],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 40 epoch = 0.00055901\n",
            "Validation mean absolute loss after 40 epoch = 0.00971493\n",
            "Validation special loss after 40 epoch = 0.00021645\n",
            "Validation accuracy after 40 epoch = 0.49332286\n",
            "Step 0 train customized mean square loss = 0.000278\n",
            "Step 1000 train customized mean square loss = 0.000482\n",
            "Step 2000 train customized mean square loss = 0.000550\n",
            "Step 3000 train customized mean square loss = 0.000412\n",
            "Step 4000 train customized mean square loss = 0.000539\n",
            "tensor([ 2.3649e-04,  3.1375e-04,  2.0756e-04,  ..., -6.7838e-06,\n",
            "        -2.1061e-05, -2.7493e-04], device='cuda:0')\n",
            "tensor([ 0.0231, -0.0081,  0.0077,  ..., -0.0290,  0.0078, -0.0304],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 41 epoch = 0.00054544\n",
            "Validation mean absolute loss after 41 epoch = 0.00969542\n",
            "Validation special loss after 41 epoch = 0.00021607\n",
            "Validation accuracy after 41 epoch = 0.55412412\n",
            "Step 0 train customized mean square loss = 0.000362\n",
            "Step 1000 train customized mean square loss = 0.000570\n",
            "Step 2000 train customized mean square loss = 0.000500\n",
            "Step 3000 train customized mean square loss = 0.000647\n",
            "Step 4000 train customized mean square loss = 0.000827\n",
            "tensor([ 0.0002, -0.0002, -0.0002,  ...,  0.0003,  0.0002,  0.0004],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0079,  0.0080, -0.0081,  ..., -0.0317, -0.0082,  0.0000],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 42 epoch = 0.00053741\n",
            "Validation mean absolute loss after 42 epoch = 0.00969770\n",
            "Validation special loss after 42 epoch = 0.00021612\n",
            "Validation accuracy after 42 epoch = 0.55208170\n",
            "Step 0 train customized mean square loss = 0.000960\n",
            "Step 1000 train customized mean square loss = 0.000314\n",
            "Step 2000 train customized mean square loss = 0.000680\n",
            "Step 3000 train customized mean square loss = 0.000714\n",
            "Step 4000 train customized mean square loss = 0.000363\n",
            "tensor([1.8297e-04, 2.4012e-04, 1.6218e-05,  ..., 2.2875e-04, 2.0052e-04,\n",
            "        3.2920e-04], device='cuda:0')\n",
            "tensor([-0.0033,  0.0105,  0.0134,  ..., -0.0023, -0.0169,  0.0066],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 43 epoch = 0.00054505\n",
            "Validation mean absolute loss after 43 epoch = 0.00969550\n",
            "Validation special loss after 43 epoch = 0.00021608\n",
            "Validation accuracy after 43 epoch = 0.55380990\n",
            "Step 0 train customized mean square loss = 0.000546\n",
            "Step 1000 train customized mean square loss = 0.000408\n",
            "Step 2000 train customized mean square loss = 0.000859\n",
            "Step 3000 train customized mean square loss = 0.000820\n",
            "Step 4000 train customized mean square loss = 0.001135\n",
            "tensor([-1.6998e-05,  2.3477e-04, -1.5152e-04,  ...,  8.9491e-05,\n",
            "        -1.4648e-04, -2.1618e-04], device='cuda:0')\n",
            "tensor([-0.0089, -0.0014,  0.0474,  ...,  0.0041, -0.0118,  0.0073],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 44 epoch = 0.00053674\n",
            "Validation mean absolute loss after 44 epoch = 0.00971016\n",
            "Validation special loss after 44 epoch = 0.00021637\n",
            "Validation accuracy after 44 epoch = 0.51076198\n",
            "Step 0 train customized mean square loss = 0.000492\n",
            "Step 1000 train customized mean square loss = 0.000428\n",
            "Step 2000 train customized mean square loss = 0.000419\n",
            "Step 3000 train customized mean square loss = 0.000450\n",
            "Step 4000 train customized mean square loss = 0.000457\n",
            "tensor([1.1200e-04, 1.0211e-04, 8.2517e-05,  ..., 1.2460e-04, 1.3571e-04,\n",
            "        7.0438e-05], device='cuda:0')\n",
            "tensor([ 0.0000, -0.0387,  0.0023,  ..., -0.0229, -0.0164,  0.0193],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 45 epoch = 0.00053866\n",
            "Validation mean absolute loss after 45 epoch = 0.00970263\n",
            "Validation special loss after 45 epoch = 0.00021623\n",
            "Validation accuracy after 45 epoch = 0.53794187\n",
            "Step 0 train customized mean square loss = 0.000541\n",
            "Step 1000 train customized mean square loss = 0.000448\n",
            "Step 2000 train customized mean square loss = 0.000520\n",
            "Step 3000 train customized mean square loss = 0.000626\n",
            "Step 4000 train customized mean square loss = 0.000699\n",
            "tensor([ 2.2054e-04, -1.3427e-04, -3.1502e-04,  ...,  3.4537e-05,\n",
            "         3.6670e-05, -1.0869e-04], device='cuda:0')\n",
            "tensor([-0.0185, -0.0019, -0.0202,  ...,  0.0038,  0.0019,  0.0007],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 46 epoch = 0.00055451\n",
            "Validation mean absolute loss after 46 epoch = 0.00971570\n",
            "Validation special loss after 46 epoch = 0.00021647\n",
            "Validation accuracy after 46 epoch = 0.49112333\n",
            "Step 0 train customized mean square loss = 0.000301\n",
            "Step 1000 train customized mean square loss = 0.000490\n",
            "Step 2000 train customized mean square loss = 0.000401\n",
            "Step 3000 train customized mean square loss = 0.000541\n",
            "Step 4000 train customized mean square loss = 0.000502\n",
            "tensor([ 1.6383e-04,  7.9336e-05, -6.7687e-05,  ..., -1.7533e-05,\n",
            "         4.8019e-05,  8.7308e-05], device='cuda:0')\n",
            "tensor([ 0.0043, -0.0011,  0.0084,  ..., -0.0077,  0.0003,  0.0151],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 47 epoch = 0.00054331\n",
            "Validation mean absolute loss after 47 epoch = 0.00970813\n",
            "Validation special loss after 47 epoch = 0.00021634\n",
            "Validation accuracy after 47 epoch = 0.51594658\n",
            "Step 0 train customized mean square loss = 0.000390\n",
            "Step 1000 train customized mean square loss = 0.000709\n",
            "Step 2000 train customized mean square loss = 0.000376\n",
            "Step 3000 train customized mean square loss = 0.000564\n",
            "Step 4000 train customized mean square loss = 0.000605\n",
            "tensor([ 2.0155e-04,  2.2862e-05,  3.2653e-04,  ...,  3.8850e-04,\n",
            "         1.2789e-04, -1.0474e-05], device='cuda:0')\n",
            "tensor([ 1.5888e-03,  5.7961e-05, -6.1162e-04,  ...,  2.9580e-03,\n",
            "        -4.6496e-03,  0.0000e+00], device='cuda:0')\n",
            "Validation customized mean square loss after 48 epoch = 0.00054229\n",
            "Validation mean absolute loss after 48 epoch = 0.00969621\n",
            "Validation special loss after 48 epoch = 0.00021610\n",
            "Validation accuracy after 48 epoch = 0.55600943\n",
            "Step 0 train customized mean square loss = 0.000708\n",
            "Step 1000 train customized mean square loss = 0.000773\n",
            "Step 2000 train customized mean square loss = 0.000421\n",
            "Step 3000 train customized mean square loss = 0.000475\n",
            "Step 4000 train customized mean square loss = 0.001074\n",
            "tensor([ 1.2551e-04,  1.5040e-04,  1.1580e-04,  ...,  8.6021e-05,\n",
            "         1.2983e-04, -2.0292e-04], device='cuda:0')\n",
            "tensor([ 0.0054,  0.0029,  0.0056,  ..., -0.0069,  0.0061, -0.0045],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 49 epoch = 0.00054273\n",
            "Validation mean absolute loss after 49 epoch = 0.00970139\n",
            "Validation special loss after 49 epoch = 0.00021621\n",
            "Validation accuracy after 49 epoch = 0.54234093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctDOc4GixbA7",
        "colab_type": "code",
        "outputId": "68bf2fb3-601e-4143-f510-347b8b176a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "plt.plot(train_loss_list)\n",
        "plt.title('MSE versus Epoch')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'MSE versus Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzPLzUnDzMxy+x9KusB34tM/owAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMlcfyyK1aHH",
        "colab_type": "code",
        "outputId": "d37a2a18-e87f-4b69-cf3f-fc3e810e083a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(val_loss_list)\n",
        "plt.title('LSTM with Sliding Window Validation Loss versus Epoch')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAEWCAYAAAAkUJMMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNaGxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA7SaLa3AYTq",
        "colab_type": "code",
        "outputId": "b2a8c954-d558-42ae-8aa8-5949ac283fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## If pretrained\n",
        "\n",
        "model_lstm.load_state_dict(torch.load('Best_LSTM.pt'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIIDah03CzB7",
        "colab_type": "code",
        "outputId": "2d4fbdd5-b268-4267-b6a2-819561b45706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "target_list = []\n",
        "prediction_list = []\n",
        "model_lstm.eval()\n",
        "with torch.no_grad():\n",
        "    for i, (inp, target) in enumerate(data_loaders['test']):\n",
        "        inp = inp.to(current_device)\n",
        "        target = target.to(current_device)\n",
        "        lr = model_lstm(inp.float())\n",
        "        prediction_list.append(lr.view(-1))\n",
        "        target_list.append(target.float().view(-1))\n",
        "\n",
        "    prediction_tensor = torch.cat(prediction_list)\n",
        "    target_tensor = torch.cat(target_list)\n",
        "            \n",
        "    val_loss = my_loss(prediction_tensor, target_tensor)\n",
        "    print('Test customized mean square loss = {:.{prec}f}'.format(val_loss, prec=8))\n",
        "\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "    val_loss_l1 = criterion_l1(prediction_tensor, target_tensor)\n",
        "    print('Test mean absolute loss = {:.{prec}f}'.format(val_loss_l1, prec=8))\n",
        "\n",
        "    val_loss_special = ((prediction_tensor - target_tensor) ** 2 / (torch.abs(target_tensor) + 1)).mean()\n",
        "    print('Test special loss = {:.{prec}f}'.format(val_loss_special, prec=8))\n",
        "\n",
        "    sign_prediction = torch.sign(prediction_tensor)\n",
        "    sign_prediction[sign_prediction == 0] = 1\n",
        "    sign_target = torch.sign(target_tensor)\n",
        "    sign_target[sign_target == 0] = 1\n",
        "    val_accuracy = ((torch.abs(sign_prediction + sign_target).sum()/2).tolist())/(sign_prediction.size()[0])\n",
        "    print('Test direction accuracy = {:.{prec}f}'.format(val_accuracy, prec=8))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test customized mean square loss = 0.00045973\n",
            "Test mean absolute loss = 0.00939494\n",
            "Test special loss = 0.00017422\n",
            "Test direction accuracy = 0.54046053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-smcOPe0H8l",
        "colab_type": "code",
        "outputId": "32397789-0789-4091-cbee-a6c1f4a33d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check unique values\n",
        "\n",
        "torch.unique(sign_prediction, return_counts = True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-1.,  1.], device='cuda:0'), tensor([ 672, 2368], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GXzTTYPOpwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Sharpe\n",
        "\n",
        "sharpe_table = ffill_test[['ticker','day']].drop_duplicates()\n",
        "sharpe_table = sharpe_table[sharpe_table['day'] != '2018-09-12']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92lGM9AyOtOA",
        "colab": {}
      },
      "source": [
        "sharpe_table['target'] = target_tensor.tolist() \n",
        "sharpe_table['price'] = prediction_tensor.tolist()\n",
        "sharpe_table['not_normal_return'] = sharpe_table['target'] * sharpe_table['price']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5VmTTHYNEc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "return_table = sharpe_table.groupby('day', as_index = False)['not_normal_return'].sum()\n",
        "return_table['normalization'] = sharpe_table.groupby('day', as_index = False)['price'].sum()['price']\n",
        "return_table['return'] = return_table['not_normal_return'] / return_table['normalization']\n",
        "sharpe = return_table['return'].mean() / return_table['return'].std() * np.sqrt(250)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SStt-NQQ14N",
        "colab_type": "code",
        "outputId": "6afbbda4-d0f7-4acc-bdec-d0d7aab64a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sharpe)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.020204781292402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SapfggWQhOvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "return_plot = (return_table['return'] + 1).cumprod().tolist()\n",
        "return_plot.insert(0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAsVD2SECy04",
        "colab_type": "code",
        "outputId": "6a79b4ef-deda-475c-96d9-86055e722582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "plt.title('LSTM Cumulative Return')\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('return')\n",
        "plt.plot(return_plot)\n",
        "plt.xticks(np.arange(0,160,16), return_table['day'][0:160:16], rotation = 45)\n",
        "plt.text(75, 0.98, 'Annual Sharpe ratio = 3.0202047')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(75, 0.98, 'Annual Sharpe ratio = 3.0202047')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAE8CAYAAADaGCZFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfqX0YRwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOEQgWfCi8gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(model_lstm.state_dict(), 'Best_LSTM.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}