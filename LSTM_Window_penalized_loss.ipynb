{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Window_penalized_loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfhwWQo2ikbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OZ_CsJHR7km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sX533lPQhuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link_news = 'https://drive.google.com/open?id=1m27dY61RYh3Dk9uxe_idITMI3uN32CHx'\n",
        "link_price = 'https://drive.google.com/open?id=1C_oMK5Gk1F_aiHxyNc0L-cQg51CqdwIV'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5dbXWs7R_rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, id_news = link_news.split('=')\n",
        "_, id_price = link_price.split('=')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET5X4lzLSBTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id_news}) \n",
        "downloaded.GetContentFile('unagg_ffill_news.csv')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdtDNcpqSD-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id_price}) \n",
        "downloaded.GetContentFile('unagg_ffill_price.csv')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjyQl8XMim1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news = pd.read_csv('unagg_ffill_news.csv', index_col = 0)\n",
        "price = pd.read_csv('unagg_ffill_price.csv', index_col = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti2t_r2BUzEM",
        "colab_type": "code",
        "outputId": "813f3113-f308-4e45-9d67-79eb5f5bb6b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "news.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>event_impact_gt_mu_pos_add_sigma_pos_avg</th>\n",
              "      <th>event_impact_gt_mu_pos_add_sigma_pos_sum</th>\n",
              "      <th>event_impact_gt_mu_pos_add_sigma_pos_min</th>\n",
              "      <th>event_impact_gt_mu_pos_add_sigma_pos_max</th>\n",
              "      <th>event_impact_lt_mu_sub_sigma_avg</th>\n",
              "      <th>event_impact_lt_mu_sub_sigma_sum</th>\n",
              "      <th>event_impact_lt_mu_sub_sigma_min</th>\n",
              "      <th>event_impact_lt_mu_sub_sigma_max</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_sigma_neg_avg</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_sigma_neg_sum</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_sigma_neg_min</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_sigma_neg_max</th>\n",
              "      <th>entity_source_republish_score_avg</th>\n",
              "      <th>entity_source_republish_score_sum</th>\n",
              "      <th>entity_source_republish_score_min</th>\n",
              "      <th>entity_source_republish_score_max</th>\n",
              "      <th>event_source_timeliness_score_avg</th>\n",
              "      <th>event_source_timeliness_score_sum</th>\n",
              "      <th>event_source_timeliness_score_min</th>\n",
              "      <th>event_source_timeliness_score_max</th>\n",
              "      <th>event_impact_pct_change_avg_avg</th>\n",
              "      <th>event_impact_pct_change_avg_sum</th>\n",
              "      <th>event_impact_pct_change_avg_min</th>\n",
              "      <th>event_impact_pct_change_avg_max</th>\n",
              "      <th>story_group_traffic_sum_avg</th>\n",
              "      <th>story_group_traffic_sum_sum</th>\n",
              "      <th>story_group_traffic_sum_min</th>\n",
              "      <th>story_group_traffic_sum_max</th>\n",
              "      <th>overall_source_timeliness_score_avg</th>\n",
              "      <th>overall_source_timeliness_score_sum</th>\n",
              "      <th>overall_source_timeliness_score_min</th>\n",
              "      <th>overall_source_timeliness_score_max</th>\n",
              "      <th>event_impact_lt_1pct_neg_avg</th>\n",
              "      <th>event_impact_lt_1pct_neg_sum</th>\n",
              "      <th>event_impact_lt_1pct_neg_min</th>\n",
              "      <th>event_impact_lt_1pct_neg_max</th>\n",
              "      <th>story_traffic_avg</th>\n",
              "      <th>story_traffic_sum</th>\n",
              "      <th>story_traffic_min</th>\n",
              "      <th>...</th>\n",
              "      <th>story_group_count_avg</th>\n",
              "      <th>story_group_count_sum</th>\n",
              "      <th>story_group_count_min</th>\n",
              "      <th>story_group_count_max</th>\n",
              "      <th>event_relevance_avg</th>\n",
              "      <th>event_relevance_sum</th>\n",
              "      <th>event_relevance_min</th>\n",
              "      <th>event_relevance_max</th>\n",
              "      <th>event_impact_gt_1pct_pos_avg</th>\n",
              "      <th>event_impact_gt_1pct_pos_sum</th>\n",
              "      <th>event_impact_gt_1pct_pos_min</th>\n",
              "      <th>event_impact_gt_1pct_pos_max</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_2sigma_neg_avg</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_2sigma_neg_sum</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_2sigma_neg_min</th>\n",
              "      <th>event_impact_lt_mu_neg_sub_2sigma_neg_max</th>\n",
              "      <th>event_author_republish_score_avg</th>\n",
              "      <th>event_author_republish_score_sum</th>\n",
              "      <th>event_author_republish_score_min</th>\n",
              "      <th>event_author_republish_score_max</th>\n",
              "      <th>event_source_republish_score_avg</th>\n",
              "      <th>event_source_republish_score_sum</th>\n",
              "      <th>event_source_republish_score_min</th>\n",
              "      <th>event_source_republish_score_max</th>\n",
              "      <th>overall_author_republish_score_avg</th>\n",
              "      <th>overall_author_republish_score_sum</th>\n",
              "      <th>overall_author_republish_score_min</th>\n",
              "      <th>overall_author_republish_score_max</th>\n",
              "      <th>event_sentiment_avg</th>\n",
              "      <th>event_sentiment_sum</th>\n",
              "      <th>event_sentiment_min</th>\n",
              "      <th>event_sentiment_max</th>\n",
              "      <th>entity_relevance_avg</th>\n",
              "      <th>entity_relevance_sum</th>\n",
              "      <th>entity_relevance_min</th>\n",
              "      <th>entity_relevance_max</th>\n",
              "      <th>count</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>dayofwork</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>44.081467</td>\n",
              "      <td>132.2444</td>\n",
              "      <td>41.8747</td>\n",
              "      <td>48.2883</td>\n",
              "      <td>0.0399</td>\n",
              "      <td>0.1197</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0576</td>\n",
              "      <td>1.826834e+11</td>\n",
              "      <td>5.480502e+11</td>\n",
              "      <td>3927884.0</td>\n",
              "      <td>5.459995e+11</td>\n",
              "      <td>50.182067</td>\n",
              "      <td>150.5462</td>\n",
              "      <td>49.0802</td>\n",
              "      <td>50.7330</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17420247.0</td>\n",
              "      <td>52260741.0</td>\n",
              "      <td>3927884.0</td>\n",
              "      <td>...</td>\n",
              "      <td>227.0</td>\n",
              "      <td>681.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>664.0</td>\n",
              "      <td>68.8</td>\n",
              "      <td>206.4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>99.9</td>\n",
              "      <td>11.111133</td>\n",
              "      <td>33.3334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.6667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.991267</td>\n",
              "      <td>2.9738</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.7946</td>\n",
              "      <td>1.4719</td>\n",
              "      <td>4.4157</td>\n",
              "      <td>1.0416</td>\n",
              "      <td>2.0318</td>\n",
              "      <td>0.985133</td>\n",
              "      <td>2.9554</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.2690</td>\n",
              "      <td>24.066667</td>\n",
              "      <td>72.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.8</td>\n",
              "      <td>96.666667</td>\n",
              "      <td>290.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>44.081467</td>\n",
              "      <td>132.2444</td>\n",
              "      <td>41.8747</td>\n",
              "      <td>48.2883</td>\n",
              "      <td>0.0399</td>\n",
              "      <td>0.1197</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0576</td>\n",
              "      <td>1.826834e+11</td>\n",
              "      <td>5.480502e+11</td>\n",
              "      <td>3927884.0</td>\n",
              "      <td>5.459995e+11</td>\n",
              "      <td>50.182067</td>\n",
              "      <td>150.5462</td>\n",
              "      <td>49.0802</td>\n",
              "      <td>50.7330</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17420247.0</td>\n",
              "      <td>52260741.0</td>\n",
              "      <td>3927884.0</td>\n",
              "      <td>...</td>\n",
              "      <td>227.0</td>\n",
              "      <td>681.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>664.0</td>\n",
              "      <td>68.8</td>\n",
              "      <td>206.4</td>\n",
              "      <td>38.0</td>\n",
              "      <td>99.9</td>\n",
              "      <td>11.111133</td>\n",
              "      <td>33.3334</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.6667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.991267</td>\n",
              "      <td>2.9738</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.7946</td>\n",
              "      <td>1.4719</td>\n",
              "      <td>4.4157</td>\n",
              "      <td>1.0416</td>\n",
              "      <td>2.0318</td>\n",
              "      <td>0.985133</td>\n",
              "      <td>2.9554</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.2690</td>\n",
              "      <td>24.066667</td>\n",
              "      <td>72.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43.8</td>\n",
              "      <td>96.666667</td>\n",
              "      <td>290.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>34.793300</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>48.244200</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344400</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>0.401200</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>-15.000000</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>34.793300</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>48.244200</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344400</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>0.401200</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>-15.000000</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>0.7061</td>\n",
              "      <td>34.793300</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>34.7933</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>1.471454e+07</td>\n",
              "      <td>48.244200</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>48.2442</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>14714537.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344400</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>0.3444</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>1.1012</td>\n",
              "      <td>0.401200</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>0.4012</td>\n",
              "      <td>-15.000000</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>-15.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 145 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  ticker  event_impact_gt_mu_pos_add_sigma_pos_avg  ...  hour  dayofwork\n",
              "0   AAPL                                       0.0  ...     0          5\n",
              "1   AAPL                                       0.0  ...     1          5\n",
              "2   AAPL                                       0.0  ...     2          5\n",
              "3   AAPL                                       0.0  ...     3          5\n",
              "4   AAPL                                       0.0  ...     4          5\n",
              "\n",
              "[5 rows x 145 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "93peXEd-VYsd",
        "colab": {}
      },
      "source": [
        "ffill = news.merge(price, how = 'left', on = ['ticker', 'day'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9u4_t4L5VYfk",
        "colab": {}
      },
      "source": [
        "ffill.drop(['date_x', 'date_y', 'open_price_change'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sGo4vr6vVXmP",
        "colab": {}
      },
      "source": [
        "ffill.fillna(method = 'ffill', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyGQ4LARmFHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ffill_train = ffill[pd.to_datetime(ffill['day']) <= datetime.datetime(2017,5,3)]\n",
        "ffill_validation = ffill[(pd.to_datetime(ffill['day']) >= datetime.datetime(2017,5,4)) & \\\n",
        "                                 (pd.to_datetime(ffill['day']) <= datetime.datetime(2018,4,4))]\n",
        "ffill_test = ffill[pd.to_datetime(ffill['day']) >= datetime.datetime(2018,4,5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SPPb3w8ztX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ffill_train.reset_index(drop = True, inplace = True)\n",
        "ffill_validation.reset_index(drop = True, inplace = True)\n",
        "ffill_test.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOo6MFKjwRNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "std = StandardScaler()\n",
        "std.fit(ffill_train.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1))\n",
        "std_train = pd.DataFrame(std.transform(ffill_train.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1)), \\\n",
        "                          columns = list(ffill_train.columns[1:142]) + list(ffill_train.columns[145:151]))\n",
        "std_val = pd.DataFrame(std.transform(ffill_validation.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1)),\\\n",
        "                        columns = list(ffill_train.columns[1:142]) + list(ffill_train.columns[145:151]))\n",
        "std_test = pd.DataFrame(std.transform(ffill_test.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1)), \\\n",
        "                         columns = list(ffill_train.columns[1:142]) + list(ffill_train.columns[145:151]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6YCuuYfwV6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_train = std_train.merge(ffill_train[['ticker','day', 'hour', 'dayofwork']], left_index = True, right_index = True)\n",
        "std_val = std_val.merge(ffill_validation[['ticker','day', 'hour', 'dayofwork']], left_index = True, right_index = True)\n",
        "std_test = std_test.merge(ffill_test[['ticker','day', 'hour', 'dayofwork']], left_index = True, right_index = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mowc2Qv0GEak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class TensoredDataset(Dataset):\n",
        "    def __init__(self, news, price):\n",
        "        self.input_tensors = []\n",
        "        self.target_tensors = []\n",
        "        \n",
        "        for ticker in news['ticker'].unique():\n",
        "            for i, day in enumerate(news['day'].unique()[:-1]):\n",
        "                second_day = str(datetime.datetime.strptime(day, '%Y-%m-%d').date() + datetime.timedelta(days=1))\n",
        "                third_day = str(datetime.datetime.strptime(day, '%Y-%m-%d').date() + datetime.timedelta(days=2)) \n",
        "                \n",
        "                input_array = news[(news['ticker'] == ticker) & (news['day'].isin([day, second_day]))].iloc[8:32]\n",
        "                self.input_tensors.append(torch.from_numpy(input_array.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1).values))\n",
        "                \n",
        "                if input_array['dayofwork'].unique()[0] <= 5:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == day)]['open_price_change']\n",
        "                    self.target_tensors.append(torch.from_numpy(target_array.values))\n",
        "                elif input_array['dayofwork'].unique()[0] == 6:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == third_day)]['open_price_change']\n",
        "                    self.target_tensors.append(torch.from_numpy(target_array.values))                    \n",
        "                elif input_array['dayofwork'].unique()[0] == 7:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == second_day)]['open_price_change']\n",
        "                    self.target_tensors.append(torch.from_numpy(target_array.values))                \n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.input_tensors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (self.input_tensors[idx], self.target_tensors[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Jwtu9Ktvz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WindowTensoredDataset(Dataset):\n",
        "    def __init__(self, news, price):\n",
        "        self.input_tensors = []\n",
        "        self.target_tensors = []\n",
        "        \n",
        "        for ticker in news['ticker'].unique():\n",
        "            for i, day in enumerate(news['day'].unique()[:-2]):\n",
        "                second_day = str(datetime.datetime.strptime(day, '%Y-%m-%d').date() + datetime.timedelta(days=1))\n",
        "                third_day = str(datetime.datetime.strptime(day, '%Y-%m-%d').date() + datetime.timedelta(days=2)) \n",
        "                fourth_day = str(datetime.datetime.strptime(day, '%Y-%m-%d').date() + datetime.timedelta(days=3))\n",
        "                \n",
        "                input_array = news[(news['ticker'] == ticker) & (news['day'].isin([day, second_day, third_day]))].iloc[9:56]\n",
        "                input_tensor = torch.from_numpy(input_array.drop(['ticker', 'day', 'hour', 'dayofwork'], axis = 1).values)\n",
        "                input_window_array = input_tensor.unfold(0,24,1)\n",
        "                for window_array in input_window_array:\n",
        "                    self.input_tensors.append(window_array.T)\n",
        "                \n",
        "                if input_array['dayofwork'].unique()[1] <= 5:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == second_day)]['open_price_change']\n",
        "                    self.target_tensors += [torch.from_numpy(target_array.values)] * 24\n",
        "                elif input_array['dayofwork'].unique()[1] == 6:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == fourth_day)]['open_price_change']\n",
        "                    self.target_tensors += [torch.from_numpy(target_array.values)] * 24                   \n",
        "                elif input_array['dayofwork'].unique()[1] == 7:\n",
        "                    target_array = price[(price['ticker'] == ticker) & (price['day'] == third_day)]['open_price_change']\n",
        "                    self.target_tensors += [torch.from_numpy(target_array.values)] * 24               \n",
        "                \n",
        "    def __len__(self):\n",
        "        return len(self.input_tensors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return (self.input_tensors[idx], self.target_tensors[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY60LIkdvaZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTM_dataset = {}\n",
        "LSTM_dataset['train'] = WindowTensoredDataset(std_train, price)\n",
        "LSTM_dataset['val'] = TensoredDataset(std_val, price)\n",
        "LSTM_dataset['test'] = TensoredDataset(std_test, price)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPCCDahl9pBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loaders = {}\n",
        "batch_size = 128\n",
        "\n",
        "for split, dataset in LSTM_dataset.items():\n",
        "    if split != 'test':\n",
        "        data_loaders[split] = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    else:\n",
        "        data_loaders[split] = DataLoader(dataset, batch_size=batch_size, shuffle=False)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAFMIVMjNuBA",
        "colab_type": "text"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXLB07ISmKpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def my_loss(output, target):\n",
        "    output_sign = torch.sign(output)\n",
        "    output_sign[output_sign == 0] = 1.0\n",
        "\n",
        "    target_sign = torch.sign(target)\n",
        "    target_sign[target_sign == 0] = 1.0\n",
        "\n",
        "    sign = -((torch.abs(output_sign + target_sign) - 2) / 2 - 1)\n",
        "\n",
        "    loss = torch.mean(((output - target) *sign) **2)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CkSLUjSrvyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, options):\n",
        "        super().__init__()\n",
        "        \n",
        "        # create each LM part here \n",
        "        self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], dropout=options['lstm_dropout'], batch_first=True)\n",
        "        # self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], batch_first=True)\n",
        "        self.projection = nn.Linear(options['hidden_size'], 1)\n",
        "        \n",
        "    def forward(self, inp):\n",
        "\n",
        "        lstm_outputs = self.lstm(inp)\n",
        "        \n",
        "        batch_size, sequence_size, input_size = lstm_outputs[0].size()[0], lstm_outputs[0].size()[1], lstm_outputs[0].size()[2]\n",
        "        lstm_output = lstm_outputs[0][:,-1,:].reshape(batch_size, 1, input_size)\n",
        "        \n",
        "        lr = self.projection(lstm_output)\n",
        "        \n",
        "        return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6aqdIqGPIN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "num_gpus = torch.cuda.device_count()\n",
        "if num_gpus > 0:\n",
        "    current_device = 'cuda'\n",
        "else:\n",
        "    current_device = 'cpu'\n",
        "\n",
        "dimen = 147\n",
        "hidden_size = 32\n",
        "num_layers = 5\n",
        "lstm_dropout = 0.1\n",
        "\n",
        "options = {\n",
        "    'input_size': dimen,\n",
        "    'hidden_size': hidden_size,\n",
        "    'num_layers': num_layers,\n",
        "    'lstm_dropout': lstm_dropout,\n",
        "}\n",
        "\n",
        "    \n",
        "model_lstm = LSTM(options).to(current_device)\n",
        "\n",
        "\n",
        "model_parameters = [p for p in model_lstm.parameters() if p.requires_grad]\n",
        "optimizer = optim.SGD(model_parameters, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx8LBCKPsN1I",
        "colab_type": "code",
        "outputId": "56ccc9e7-c2e5-4ff3-d983-d5e74e547fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model_lstm"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(147, 32, num_layers=5, batch_first=True, dropout=0.1)\n",
              "  (projection): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPtCQbkFsOX4",
        "colab_type": "code",
        "outputId": "c21dcf4f-17cc-4bf7-94ef-6a93edf3e8b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "for epoch_number in range(50):\n",
        "    train_loss_cache = 10000\n",
        "    val_loss_cache = 0\n",
        "\n",
        "    model_lstm.train()\n",
        "        \n",
        "\n",
        "    for i, (inp, target) in enumerate(data_loaders['train']):\n",
        "        optimizer.zero_grad()\n",
        "        inp = inp.to(current_device)\n",
        "        target = target.to(current_device)\n",
        "        lr = model_lstm(inp.float())\n",
        "        loss = my_loss(lr.view(-1), target.float().view(-1))\n",
        "\n",
        "        if loss < train_loss_cache:\n",
        "            train_loss_cache = loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print('Step {} train customized mean square loss = {:.{prec}f}'.format(i, loss, prec=6))\n",
        "\n",
        "    train_loss_list.append(round(train_loss_cache.item(), 8))       \n",
        "    #do valid\n",
        "\n",
        "    target_list = []\n",
        "    prediction_list = []\n",
        "    \n",
        "#     valid_loss_cache = valid_loss_cache_l1 = valid_loss_cache_special = valid_accuracy_cache = 0\n",
        "#     n = 0\n",
        "    model_lstm.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inp, target) in enumerate(data_loaders['val']):\n",
        "            inp = inp.to(current_device)\n",
        "            target = target.to(current_device)\n",
        "            lr = model_lstm(inp.float())\n",
        "            prediction_list.append(lr.view(-1))\n",
        "            target_list.append(target.float().view(-1))\n",
        "#             val_loss = criterion(lr.view(-1), target.float().view(-1)) \n",
        "#             valid_loss_cache += val_loss\n",
        "            \n",
        "#             criterion_l1 = nn.L1Loss()\n",
        "#             valid_loss_l1 = criterion_l1(lr.view(-1), target.float().view(-1)) \n",
        "#             valid_loss_cache_l1 += valid_loss_l1\n",
        "            \n",
        "#             valid_loss_special = ((lr.view(-1) - target.float().view(-1)) ** 2 / (torch.abs(target.float().view(-1)) + 1)).sum()\n",
        "#             valid_loss_cache_special += valid_loss_special\n",
        "            \n",
        "#             sign_prediction = torch.sign(lr.view(-1))\n",
        "#             sign_prediction[sign_prediction == 0] = 1\n",
        "#             sign_target = torch.sign(target.float().view(-1))\n",
        "#             sign_target[sign_target == 0] = 1\n",
        "#             valid_accuracy = (((sign_prediction + sign_target).sum()/2).tolist())/(sign_prediction.size()[0])\n",
        "#             valid_accuracy_cache += valid_accuracy\n",
        "            \n",
        "#             n += 1\n",
        "        prediction_tensor = torch.cat(prediction_list)\n",
        "        target_tensor = torch.cat(target_list)\n",
        "\n",
        "        print(prediction_tensor)\n",
        "        print(target_tensor)\n",
        "            \n",
        "#         avg_val_loss = valid_loss_cache / n\n",
        "        val_loss = my_loss(prediction_tensor, target_tensor)\n",
        "        val_loss_list.append(val_loss)\n",
        "        print('Validation customized mean square loss after {} epoch = {:.{prec}f}'.format(epoch_number, val_loss, prec=8))\n",
        "        \n",
        "#         avg_val_loss_l1 = valid_loss_cache_l1 / n\n",
        "        criterion_l1 = nn.L1Loss()\n",
        "        val_loss_l1 = criterion_l1(prediction_tensor, target_tensor)\n",
        "        print('Validation mean absolute loss after {} epoch = {:.{prec}f}'.format(epoch_number, val_loss_l1, prec=8))\n",
        "    \n",
        "#         avg_val_loss_special = valid_loss_cache_special / n\n",
        "        val_loss_special = ((prediction_tensor - target_tensor) ** 2 / (torch.abs(target_tensor) + 1)).mean()\n",
        "        print('Validation special loss after {} epoch = {:.{prec}f}'.format(epoch_number, val_loss_special, prec=8))\n",
        "        \n",
        "#         avg_val_accuracy = valid_accuracy_cache / n\n",
        "        sign_prediction = torch.sign(prediction_tensor)\n",
        "        sign_prediction[sign_prediction == 0] = 1\n",
        "        sign_target = torch.sign(target_tensor)\n",
        "        sign_target[sign_target == 0] = 1\n",
        "        val_accuracy = ((torch.abs(sign_prediction + sign_target).sum()/2).tolist())/(sign_prediction.size()[0])\n",
        "        print('Validation accuracy after {} epoch = {:.{prec}f}'.format(epoch_number, val_accuracy, prec=8))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0 train customized mean square loss = 0.077577\n",
            "Step 1000 train customized mean square loss = 0.000822\n",
            "Step 2000 train customized mean square loss = 0.001018\n",
            "Step 3000 train customized mean square loss = 0.000865\n",
            "Step 4000 train customized mean square loss = 0.000389\n",
            "tensor([0.0009, 0.0009, 0.0002,  ..., 0.0005, 0.0007, 0.0004], device='cuda:0')\n",
            "tensor([ 0.0037, -0.0020,  0.0179,  ..., -0.0223,  0.0492, -0.0071],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 0 epoch = 0.00055310\n",
            "Validation mean absolute loss after 0 epoch = 0.00969680\n",
            "Validation special loss after 0 epoch = 0.00021582\n",
            "Validation accuracy after 0 epoch = 0.54831108\n",
            "Step 0 train customized mean square loss = 0.000661\n",
            "Step 1000 train customized mean square loss = 0.000496\n",
            "Step 2000 train customized mean square loss = 0.000781\n",
            "Step 3000 train customized mean square loss = 0.000677\n",
            "Step 4000 train customized mean square loss = 0.000890\n",
            "tensor([ 3.2625e-04,  7.5344e-04, -9.3807e-05,  ..., -7.2103e-05,\n",
            "         3.7122e-04,  3.4712e-04], device='cuda:0')\n",
            "tensor([-0.0052, -0.0313, -0.0437,  ..., -0.0030, -0.0265,  0.0054],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 1 epoch = 0.00055734\n",
            "Validation mean absolute loss after 1 epoch = 0.00969703\n",
            "Validation special loss after 1 epoch = 0.00021586\n",
            "Validation accuracy after 1 epoch = 0.54454046\n",
            "Step 0 train customized mean square loss = 0.000746\n",
            "Step 1000 train customized mean square loss = 0.000558\n",
            "Step 2000 train customized mean square loss = 0.000391\n",
            "Step 3000 train customized mean square loss = 0.000513\n",
            "Step 4000 train customized mean square loss = 0.000586\n",
            "tensor([-8.1630e-04, -1.9580e-05,  7.9518e-04,  ...,  7.9877e-04,\n",
            "         5.6279e-04, -6.4635e-04], device='cuda:0')\n",
            "tensor([ 0.0118,  0.0096, -0.0001,  ..., -0.0053, -0.0068, -0.0042],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 2 epoch = 0.00055537\n",
            "Validation mean absolute loss after 2 epoch = 0.00969855\n",
            "Validation special loss after 2 epoch = 0.00021592\n",
            "Validation accuracy after 2 epoch = 0.54108405\n",
            "Step 0 train customized mean square loss = 0.000331\n",
            "Step 1000 train customized mean square loss = 0.000636\n",
            "Step 2000 train customized mean square loss = 0.000722\n",
            "Step 3000 train customized mean square loss = 0.000511\n",
            "Step 4000 train customized mean square loss = 0.000456\n",
            "tensor([ 4.9548e-04, -9.3423e-05, -4.6939e-06,  ..., -4.6606e-04,\n",
            "         3.0241e-04,  5.7881e-04], device='cuda:0')\n",
            "tensor([ 0.0086,  0.0096,  0.0000,  ...,  0.0085, -0.0126,  0.0015],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 3 epoch = 0.00055533\n",
            "Validation mean absolute loss after 3 epoch = 0.00969717\n",
            "Validation special loss after 3 epoch = 0.00021592\n",
            "Validation accuracy after 3 epoch = 0.54155538\n",
            "Step 0 train customized mean square loss = 0.000522\n",
            "Step 1000 train customized mean square loss = 0.000743\n",
            "Step 2000 train customized mean square loss = 0.000528\n",
            "Step 3000 train customized mean square loss = 0.000590\n",
            "Step 4000 train customized mean square loss = 0.000627\n",
            "tensor([0.0003, 0.0005, 0.0004,  ..., 0.0001, 0.0001, 0.0007], device='cuda:0')\n",
            "tensor([ 0.0338, -0.0050,  0.0174,  ...,  0.0060,  0.0086,  0.0114],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 4 epoch = 0.00055456\n",
            "Validation mean absolute loss after 4 epoch = 0.00969233\n",
            "Validation special loss after 4 epoch = 0.00021584\n",
            "Validation accuracy after 4 epoch = 0.55051060\n",
            "Step 0 train customized mean square loss = 0.000662\n",
            "Step 1000 train customized mean square loss = 0.001027\n",
            "Step 2000 train customized mean square loss = 0.000474\n",
            "Step 3000 train customized mean square loss = 0.000497\n",
            "Step 4000 train customized mean square loss = 0.000558\n",
            "tensor([-8.7636e-05,  3.9035e-04,  3.2674e-04,  ...,  8.5320e-04,\n",
            "         5.9464e-04,  8.4724e-04], device='cuda:0')\n",
            "tensor([-0.0140,  0.0105,  0.0046,  ...,  0.0208,  0.0106, -0.0061],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 5 epoch = 0.00055268\n",
            "Validation mean absolute loss after 5 epoch = 0.00969080\n",
            "Validation special loss after 5 epoch = 0.00021582\n",
            "Validation accuracy after 5 epoch = 0.55223881\n",
            "Step 0 train customized mean square loss = 0.000409\n",
            "Step 1000 train customized mean square loss = 0.000271\n",
            "Step 2000 train customized mean square loss = 0.000882\n",
            "Step 3000 train customized mean square loss = 0.000779\n",
            "Step 4000 train customized mean square loss = 0.000648\n",
            "tensor([ 3.8870e-04,  2.6369e-04,  5.4806e-04,  ...,  4.4545e-05,\n",
            "        -8.9215e-04, -2.1022e-04], device='cuda:0')\n",
            "tensor([ 0.0088, -0.0061, -0.0048,  ...,  0.0038,  0.0298, -0.0003],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 6 epoch = 0.00054413\n",
            "Validation mean absolute loss after 6 epoch = 0.00971666\n",
            "Validation special loss after 6 epoch = 0.00021635\n",
            "Validation accuracy after 6 epoch = 0.51264729\n",
            "Step 0 train customized mean square loss = 0.000592\n",
            "Step 1000 train customized mean square loss = 0.000487\n",
            "Step 2000 train customized mean square loss = 0.000525\n",
            "Step 3000 train customized mean square loss = 0.000523\n",
            "Step 4000 train customized mean square loss = 0.000832\n",
            "tensor([-0.0001, -0.0005,  0.0007,  ...,  0.0006,  0.0007,  0.0002],\n",
            "       device='cuda:0')\n",
            "tensor([-0.0003,  0.0683,  0.0100,  ...,  0.0025, -0.0045,  0.0051],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 7 epoch = 0.00055192\n",
            "Validation mean absolute loss after 7 epoch = 0.00968866\n",
            "Validation special loss after 7 epoch = 0.00021580\n",
            "Validation accuracy after 7 epoch = 0.55648075\n",
            "Step 0 train customized mean square loss = 0.000384\n",
            "Step 1000 train customized mean square loss = 0.000416\n",
            "Step 2000 train customized mean square loss = 0.000827\n",
            "Step 3000 train customized mean square loss = 0.000522\n",
            "Step 4000 train customized mean square loss = 0.000616\n",
            "tensor([ 9.6771e-04,  5.0948e-04,  2.1632e-04,  ...,  5.5381e-04,\n",
            "         4.2137e-04, -1.9034e-05], device='cuda:0')\n",
            "tensor([ 0.0086, -0.0110,  0.0075,  ...,  0.0840, -0.0077,  0.0076],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 8 epoch = 0.00054995\n",
            "Validation mean absolute loss after 8 epoch = 0.00969005\n",
            "Validation special loss after 8 epoch = 0.00021585\n",
            "Validation accuracy after 8 epoch = 0.55161037\n",
            "Step 0 train customized mean square loss = 0.000483\n",
            "Step 1000 train customized mean square loss = 0.000633\n",
            "Step 2000 train customized mean square loss = 0.000646\n",
            "Step 3000 train customized mean square loss = 0.000526\n",
            "Step 4000 train customized mean square loss = 0.000451\n",
            "tensor([ 1.0563e-04, -3.5083e-05,  4.5172e-04,  ..., -1.9524e-04,\n",
            "         3.8018e-04,  5.3371e-04], device='cuda:0')\n",
            "tensor([-0.0026,  0.0039,  0.0151,  ...,  0.0024, -0.0143,  0.0079],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 9 epoch = 0.00054633\n",
            "Validation mean absolute loss after 9 epoch = 0.00969341\n",
            "Validation special loss after 9 epoch = 0.00021593\n",
            "Validation accuracy after 9 epoch = 0.55066771\n",
            "Step 0 train customized mean square loss = 0.000417\n",
            "Step 1000 train customized mean square loss = 0.000567\n",
            "Step 2000 train customized mean square loss = 0.000559\n",
            "Step 3000 train customized mean square loss = 0.000789\n",
            "Step 4000 train customized mean square loss = 0.001303\n",
            "tensor([ 3.3157e-05,  1.3882e-04,  7.0941e-05,  ..., -6.9547e-05,\n",
            "         2.2782e-04,  1.3509e-04], device='cuda:0')\n",
            "tensor([ 0.0042,  0.0055,  0.0221,  ..., -0.0031,  0.0028, -0.0029],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 10 epoch = 0.00054004\n",
            "Validation mean absolute loss after 10 epoch = 0.00970538\n",
            "Validation special loss after 10 epoch = 0.00021618\n",
            "Validation accuracy after 10 epoch = 0.52521603\n",
            "Step 0 train customized mean square loss = 0.000391\n",
            "Step 1000 train customized mean square loss = 0.001156\n",
            "Step 2000 train customized mean square loss = 0.000494\n",
            "Step 3000 train customized mean square loss = 0.001730\n",
            "Step 4000 train customized mean square loss = 0.000501\n",
            "tensor([0.0006, 0.0005, 0.0009,  ..., 0.0007, 0.0003, 0.0005], device='cuda:0')\n",
            "tensor([-0.0287,  0.0043, -0.0182,  ...,  0.0127, -0.0123, -0.0037],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 11 epoch = 0.00055354\n",
            "Validation mean absolute loss after 11 epoch = 0.00968618\n",
            "Validation special loss after 11 epoch = 0.00021578\n",
            "Validation accuracy after 11 epoch = 0.55962294\n",
            "Step 0 train customized mean square loss = 0.000520\n",
            "Step 1000 train customized mean square loss = 0.000879\n",
            "Step 2000 train customized mean square loss = 0.000511\n",
            "Step 3000 train customized mean square loss = 0.000410\n",
            "Step 4000 train customized mean square loss = 0.000452\n",
            "tensor([-1.2693e-04,  2.1979e-04,  9.5807e-05,  ...,  2.6541e-04,\n",
            "        -5.7155e-05,  4.0126e-04], device='cuda:0')\n",
            "tensor([ 0.0075,  0.0000, -0.0026,  ...,  0.0041, -0.0147, -0.0022],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 12 epoch = 0.00054503\n",
            "Validation mean absolute loss after 12 epoch = 0.00971466\n",
            "Validation special loss after 12 epoch = 0.00021636\n",
            "Validation accuracy after 12 epoch = 0.51076198\n",
            "Step 0 train customized mean square loss = 0.000395\n",
            "Step 1000 train customized mean square loss = 0.000475\n",
            "Step 2000 train customized mean square loss = 0.000647\n",
            "Step 3000 train customized mean square loss = 0.000569\n",
            "Step 4000 train customized mean square loss = 0.000344\n",
            "tensor([3.5614e-06, 3.5881e-04, 5.2693e-04,  ..., 5.3050e-05, 6.6292e-04,\n",
            "        4.7167e-04], device='cuda:0')\n",
            "tensor([-0.0265,  0.0065,  0.0074,  ...,  0.0202, -0.0096,  0.0042],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 13 epoch = 0.00054961\n",
            "Validation mean absolute loss after 13 epoch = 0.00968916\n",
            "Validation special loss after 13 epoch = 0.00021586\n",
            "Validation accuracy after 13 epoch = 0.55365279\n",
            "Step 0 train customized mean square loss = 0.000572\n",
            "Step 1000 train customized mean square loss = 0.000373\n",
            "Step 2000 train customized mean square loss = 0.000518\n",
            "Step 3000 train customized mean square loss = 0.000897\n",
            "Step 4000 train customized mean square loss = 0.000422\n",
            "tensor([-2.7016e-04,  9.2069e-05, -1.1777e-04,  ...,  1.1044e-04,\n",
            "        -5.7105e-05, -3.9912e-04], device='cuda:0')\n",
            "tensor([-0.0005, -0.0005, -0.0015,  ...,  0.0042,  0.0061,  0.0187],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 14 epoch = 0.00054024\n",
            "Validation mean absolute loss after 14 epoch = 0.00971003\n",
            "Validation special loss after 14 epoch = 0.00021629\n",
            "Validation accuracy after 14 epoch = 0.51484682\n",
            "Step 0 train customized mean square loss = 0.000704\n",
            "Step 1000 train customized mean square loss = 0.000581\n",
            "Step 2000 train customized mean square loss = 0.000539\n",
            "Step 3000 train customized mean square loss = 0.000435\n",
            "Step 4000 train customized mean square loss = 0.000458\n",
            "tensor([-1.0725e-04,  1.8483e-04,  8.3175e-05,  ...,  5.2088e-04,\n",
            "         2.7419e-04,  4.9681e-04], device='cuda:0')\n",
            "tensor([ 0.0002,  0.0207,  0.0041,  ...,  0.0025, -0.0033,  0.0077],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 15 epoch = 0.00054950\n",
            "Validation mean absolute loss after 15 epoch = 0.00968862\n",
            "Validation special loss after 15 epoch = 0.00021586\n",
            "Validation accuracy after 15 epoch = 0.55506677\n",
            "Step 0 train customized mean square loss = 0.000322\n",
            "Step 1000 train customized mean square loss = 0.000600\n",
            "Step 2000 train customized mean square loss = 0.000364\n",
            "Step 3000 train customized mean square loss = 0.000606\n",
            "Step 4000 train customized mean square loss = 0.000773\n",
            "tensor([4.1051e-04, 1.3718e-04, 1.7753e-04,  ..., 5.7308e-04, 2.2418e-04,\n",
            "        7.2777e-05], device='cuda:0')\n",
            "tensor([ 0.0003,  0.0015, -0.0006,  ...,  0.0007,  0.0338, -0.0012],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 16 epoch = 0.00054916\n",
            "Validation mean absolute loss after 16 epoch = 0.00969817\n",
            "Validation special loss after 16 epoch = 0.00021607\n",
            "Validation accuracy after 16 epoch = 0.54469756\n",
            "Step 0 train customized mean square loss = 0.000885\n",
            "Step 1000 train customized mean square loss = 0.000867\n",
            "Step 2000 train customized mean square loss = 0.001011\n",
            "Step 3000 train customized mean square loss = 0.000849\n",
            "Step 4000 train customized mean square loss = 0.000458\n",
            "tensor([ 2.3512e-04,  1.7856e-04, -4.2558e-05,  ...,  7.4623e-05,\n",
            "        -1.1433e-04,  1.4905e-04], device='cuda:0')\n",
            "tensor([ 0.0340,  0.0059,  0.0082,  ...,  0.0054,  0.0348, -0.0004],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 17 epoch = 0.00053455\n",
            "Validation mean absolute loss after 17 epoch = 0.00970067\n",
            "Validation special loss after 17 epoch = 0.00021613\n",
            "Validation accuracy after 17 epoch = 0.54202671\n",
            "Step 0 train customized mean square loss = 0.000337\n",
            "Step 1000 train customized mean square loss = 0.000477\n",
            "Step 2000 train customized mean square loss = 0.000456\n",
            "Step 3000 train customized mean square loss = 0.000575\n",
            "Step 4000 train customized mean square loss = 0.000565\n",
            "tensor([ 3.1301e-04,  9.1327e-05, -1.0252e-04,  ...,  1.4348e-04,\n",
            "         1.2140e-04,  8.8159e-05], device='cuda:0')\n",
            "tensor([-0.0096,  0.0049, -0.0055,  ...,  0.0094,  0.0064,  0.0146],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 18 epoch = 0.00054513\n",
            "Validation mean absolute loss after 18 epoch = 0.00969561\n",
            "Validation special loss after 18 epoch = 0.00021603\n",
            "Validation accuracy after 18 epoch = 0.55161037\n",
            "Step 0 train customized mean square loss = 0.000483\n",
            "Step 1000 train customized mean square loss = 0.000961\n",
            "Step 2000 train customized mean square loss = 0.000748\n",
            "Step 3000 train customized mean square loss = 0.000604\n",
            "Step 4000 train customized mean square loss = 0.000447\n",
            "tensor([-4.0497e-04,  2.4792e-05,  4.1209e-04,  ...,  8.4203e-05,\n",
            "        -3.6854e-05,  1.4413e-04], device='cuda:0')\n",
            "tensor([0.0045, 0.0076, 0.0051,  ..., 0.0099, 0.0046, 0.0190], device='cuda:0')\n",
            "Validation customized mean square loss after 19 epoch = 0.00054142\n",
            "Validation mean absolute loss after 19 epoch = 0.00970728\n",
            "Validation special loss after 19 epoch = 0.00021626\n",
            "Validation accuracy after 19 epoch = 0.52191673\n",
            "Step 0 train customized mean square loss = 0.000644\n",
            "Step 1000 train customized mean square loss = 0.000592\n",
            "Step 2000 train customized mean square loss = 0.000405\n",
            "Step 3000 train customized mean square loss = 0.000439\n",
            "Step 4000 train customized mean square loss = 0.000554\n",
            "tensor([ 8.5697e-05,  6.9458e-06, -5.9234e-04,  ...,  1.5829e-04,\n",
            "         3.9163e-04,  3.7281e-04], device='cuda:0')\n",
            "tensor([ 0.0078, -0.0026, -0.0030,  ...,  0.0055, -0.0031,  0.0040],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 20 epoch = 0.00054224\n",
            "Validation mean absolute loss after 20 epoch = 0.00970702\n",
            "Validation special loss after 20 epoch = 0.00021626\n",
            "Validation accuracy after 20 epoch = 0.52348782\n",
            "Step 0 train customized mean square loss = 0.000793\n",
            "Step 1000 train customized mean square loss = 0.001393\n",
            "Step 2000 train customized mean square loss = 0.000454\n",
            "Step 3000 train customized mean square loss = 0.001035\n",
            "Step 4000 train customized mean square loss = 0.000534\n",
            "tensor([ 4.5709e-04,  5.6796e-05,  8.1232e-05,  ...,  3.4918e-04,\n",
            "         3.9563e-04, -1.5124e-04], device='cuda:0')\n",
            "tensor([-0.0056, -0.0094,  0.0000,  ..., -0.0002, -0.0049, -0.0202],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 21 epoch = 0.00054562\n",
            "Validation mean absolute loss after 21 epoch = 0.00969648\n",
            "Validation special loss after 21 epoch = 0.00021606\n",
            "Validation accuracy after 21 epoch = 0.55019639\n",
            "Step 0 train customized mean square loss = 0.000572\n",
            "Step 1000 train customized mean square loss = 0.000515\n",
            "Step 2000 train customized mean square loss = 0.001060\n",
            "Step 3000 train customized mean square loss = 0.000619\n",
            "Step 4000 train customized mean square loss = 0.000760\n",
            "tensor([-4.8136e-05, -1.4581e-04, -5.3823e-05,  ...,  9.8411e-05,\n",
            "         2.3352e-04,  2.3136e-04], device='cuda:0')\n",
            "tensor([0.0091, 0.0004, 0.0000,  ..., 0.0116, 0.0145, 0.0100], device='cuda:0')\n",
            "Validation customized mean square loss after 22 epoch = 0.00054293\n",
            "Validation mean absolute loss after 22 epoch = 0.00970064\n",
            "Validation special loss after 22 epoch = 0.00021614\n",
            "Validation accuracy after 22 epoch = 0.54108405\n",
            "Step 0 train customized mean square loss = 0.000955\n",
            "Step 1000 train customized mean square loss = 0.000808\n",
            "Step 2000 train customized mean square loss = 0.000558\n",
            "Step 3000 train customized mean square loss = 0.000474\n",
            "Step 4000 train customized mean square loss = 0.000830\n",
            "tensor([4.0622e-05, 3.7774e-06, 3.6496e-04,  ..., 1.8173e-04, 3.4273e-04,\n",
            "        2.5120e-04], device='cuda:0')\n",
            "tensor([-0.0059,  0.0136,  0.0054,  ...,  0.0045, -0.0017,  0.0031],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 23 epoch = 0.00054708\n",
            "Validation mean absolute loss after 23 epoch = 0.00969934\n",
            "Validation special loss after 23 epoch = 0.00021612\n",
            "Validation accuracy after 23 epoch = 0.54155538\n",
            "Step 0 train customized mean square loss = 0.000510\n",
            "Step 1000 train customized mean square loss = 0.000632\n",
            "Step 2000 train customized mean square loss = 0.000802\n",
            "Step 3000 train customized mean square loss = 0.000312\n",
            "Step 4000 train customized mean square loss = 0.000584\n",
            "tensor([ 6.8691e-05, -3.6598e-04, -2.6546e-04,  ...,  2.2259e-05,\n",
            "        -2.8459e-04,  1.1585e-04], device='cuda:0')\n",
            "tensor([-0.0092,  0.0033, -0.0095,  ...,  0.0047, -0.0338,  0.0052],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 24 epoch = 0.00055189\n",
            "Validation mean absolute loss after 24 epoch = 0.00972809\n",
            "Validation special loss after 24 epoch = 0.00021664\n",
            "Validation accuracy after 24 epoch = 0.47117046\n",
            "Step 0 train customized mean square loss = 0.000414\n",
            "Step 1000 train customized mean square loss = 0.000674\n",
            "Step 2000 train customized mean square loss = 0.000532\n",
            "Step 3000 train customized mean square loss = 0.000780\n",
            "Step 4000 train customized mean square loss = 0.000435\n",
            "tensor([-5.1426e-05,  3.6089e-05,  2.9646e-04,  ...,  7.6972e-05,\n",
            "         3.3399e-05,  2.1590e-04], device='cuda:0')\n",
            "tensor([ 0.0024,  0.0092, -0.0105,  ...,  0.0271, -0.0294, -0.0141],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 25 epoch = 0.00054282\n",
            "Validation mean absolute loss after 25 epoch = 0.00971140\n",
            "Validation special loss after 25 epoch = 0.00021636\n",
            "Validation accuracy after 25 epoch = 0.50589159\n",
            "Step 0 train customized mean square loss = 0.000605\n",
            "Step 1000 train customized mean square loss = 0.000629\n",
            "Step 2000 train customized mean square loss = 0.000672\n",
            "Step 3000 train customized mean square loss = 0.000813\n",
            "Step 4000 train customized mean square loss = 0.000439\n",
            "tensor([ 1.1285e-04,  3.0866e-04,  4.9945e-05,  ...,  1.2570e-04,\n",
            "         7.4338e-05, -3.9908e-04], device='cuda:0')\n",
            "tensor([ 0.0003,  0.0069, -0.0226,  ..., -0.0145, -0.0074, -0.0064],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 26 epoch = 0.00054588\n",
            "Validation mean absolute loss after 26 epoch = 0.00969920\n",
            "Validation special loss after 26 epoch = 0.00021613\n",
            "Validation accuracy after 26 epoch = 0.54344069\n",
            "Step 0 train customized mean square loss = 0.000400\n",
            "Step 1000 train customized mean square loss = 0.000630\n",
            "Step 2000 train customized mean square loss = 0.000666\n",
            "Step 3000 train customized mean square loss = 0.000581\n",
            "Step 4000 train customized mean square loss = 0.000510\n",
            "tensor([2.2460e-04, 1.1672e-04, 4.3446e-04,  ..., 4.7068e-04, 4.1250e-05,\n",
            "        3.8824e-04], device='cuda:0')\n",
            "tensor([-0.0953,  0.0007,  0.0011,  ..., -0.0019,  0.0104, -0.0045],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 27 epoch = 0.00054614\n",
            "Validation mean absolute loss after 27 epoch = 0.00969872\n",
            "Validation special loss after 27 epoch = 0.00021612\n",
            "Validation accuracy after 27 epoch = 0.54548311\n",
            "Step 0 train customized mean square loss = 0.000723\n",
            "Step 1000 train customized mean square loss = 0.000674\n",
            "Step 2000 train customized mean square loss = 0.000782\n",
            "Step 3000 train customized mean square loss = 0.000826\n",
            "Step 4000 train customized mean square loss = 0.000535\n",
            "tensor([2.3660e-04, 4.6549e-05, 2.4772e-04,  ..., 1.1208e-04, 4.6044e-04,\n",
            "        1.7312e-04], device='cuda:0')\n",
            "tensor([-0.0020,  0.0007,  0.0100,  ..., -0.0012,  0.0018, -0.0003],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 28 epoch = 0.00054668\n",
            "Validation mean absolute loss after 28 epoch = 0.00969776\n",
            "Validation special loss after 28 epoch = 0.00021610\n",
            "Validation accuracy after 28 epoch = 0.54831108\n",
            "Step 0 train customized mean square loss = 0.000464\n",
            "Step 1000 train customized mean square loss = 0.000401\n",
            "Step 2000 train customized mean square loss = 0.000459\n",
            "Step 3000 train customized mean square loss = 0.000448\n",
            "Step 4000 train customized mean square loss = 0.000475\n",
            "tensor([-8.0602e-05,  1.2450e-04,  3.7946e-04,  ...,  1.4992e-04,\n",
            "        -3.8426e-05,  2.4360e-04], device='cuda:0')\n",
            "tensor([-0.0153, -0.0019,  0.0083,  ...,  0.0011, -0.0067,  0.0033],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 29 epoch = 0.00054692\n",
            "Validation mean absolute loss after 29 epoch = 0.00969924\n",
            "Validation special loss after 29 epoch = 0.00021613\n",
            "Validation accuracy after 29 epoch = 0.54296936\n",
            "Step 0 train customized mean square loss = 0.000332\n",
            "Step 1000 train customized mean square loss = 0.000448\n",
            "Step 2000 train customized mean square loss = 0.000493\n",
            "Step 3000 train customized mean square loss = 0.000872\n",
            "Step 4000 train customized mean square loss = 0.000688\n",
            "tensor([ 1.7475e-04,  6.9005e-05,  3.0436e-04,  ..., -7.6422e-05,\n",
            "         2.0845e-05,  2.4196e-04], device='cuda:0')\n",
            "tensor([ 0.0015, -0.0117, -0.0265,  ...,  0.0000,  0.0155, -0.0023],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 30 epoch = 0.00054459\n",
            "Validation mean absolute loss after 30 epoch = 0.00969752\n",
            "Validation special loss after 30 epoch = 0.00021610\n",
            "Validation accuracy after 30 epoch = 0.55113904\n",
            "Step 0 train customized mean square loss = 0.000463\n",
            "Step 1000 train customized mean square loss = 0.000464\n",
            "Step 2000 train customized mean square loss = 0.000417\n",
            "Step 3000 train customized mean square loss = 0.000779\n",
            "Step 4000 train customized mean square loss = 0.000570\n",
            "tensor([3.5027e-04, 2.7206e-04, 2.9909e-04,  ..., 1.2195e-05, 2.3322e-04,\n",
            "        1.9711e-04], device='cuda:0')\n",
            "tensor([-0.0037, -0.0046,  0.0009,  ...,  0.0100,  0.0266, -0.0079],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 31 epoch = 0.00054422\n",
            "Validation mean absolute loss after 31 epoch = 0.00969749\n",
            "Validation special loss after 31 epoch = 0.00021610\n",
            "Validation accuracy after 31 epoch = 0.55113904\n",
            "Step 0 train customized mean square loss = 0.000357\n",
            "Step 1000 train customized mean square loss = 0.000466\n",
            "Step 2000 train customized mean square loss = 0.000407\n",
            "Step 3000 train customized mean square loss = 0.000625\n",
            "Step 4000 train customized mean square loss = 0.000445\n",
            "tensor([ 1.9792e-04,  8.8198e-05, -8.2348e-06,  ..., -1.3818e-04,\n",
            "         2.4022e-04, -1.1283e-04], device='cuda:0')\n",
            "tensor([-0.0187,  0.0164,  0.0033,  ..., -0.0018,  0.0018, -0.0145],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 32 epoch = 0.00055965\n",
            "Validation mean absolute loss after 32 epoch = 0.00971791\n",
            "Validation special loss after 32 epoch = 0.00021649\n",
            "Validation accuracy after 32 epoch = 0.48970935\n",
            "Step 0 train customized mean square loss = 0.000220\n",
            "Step 1000 train customized mean square loss = 0.000446\n",
            "Step 2000 train customized mean square loss = 0.000437\n",
            "Step 3000 train customized mean square loss = 0.000453\n",
            "Step 4000 train customized mean square loss = 0.000700\n",
            "tensor([ 8.3771e-05,  2.4108e-04,  1.5510e-04,  ...,  1.7122e-04,\n",
            "        -3.8335e-05,  2.7282e-04], device='cuda:0')\n",
            "tensor([-0.0034, -0.0135, -0.0003,  ...,  0.0089,  0.0040,  0.0125],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 33 epoch = 0.00053832\n",
            "Validation mean absolute loss after 33 epoch = 0.00970182\n",
            "Validation special loss after 33 epoch = 0.00021619\n",
            "Validation accuracy after 33 epoch = 0.53794187\n",
            "Step 0 train customized mean square loss = 0.000546\n",
            "Step 1000 train customized mean square loss = 0.000968\n",
            "Step 2000 train customized mean square loss = 0.000685\n",
            "Step 3000 train customized mean square loss = 0.000466\n",
            "Step 4000 train customized mean square loss = 0.000632\n",
            "tensor([ 1.0422e-04,  2.0817e-04, -1.3184e-04,  ...,  1.0611e-04,\n",
            "        -1.1373e-04,  7.6639e-05], device='cuda:0')\n",
            "tensor([ 0.0008, -0.0145,  0.0020,  ...,  0.0175,  0.0141,  0.0035],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 34 epoch = 0.00054396\n",
            "Validation mean absolute loss after 34 epoch = 0.00970837\n",
            "Validation special loss after 34 epoch = 0.00021632\n",
            "Validation accuracy after 34 epoch = 0.51673213\n",
            "Step 0 train customized mean square loss = 0.000572\n",
            "Step 1000 train customized mean square loss = 0.000452\n",
            "Step 2000 train customized mean square loss = 0.000408\n",
            "Step 3000 train customized mean square loss = 0.000576\n",
            "Step 4000 train customized mean square loss = 0.000398\n",
            "tensor([ 4.4443e-05,  1.1170e-05,  9.8173e-05,  ...,  2.8523e-04,\n",
            "        -4.6847e-04, -1.4640e-05], device='cuda:0')\n",
            "tensor([-0.0052,  0.0021,  0.0058,  ..., -0.0317, -0.0037, -0.0103],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 35 epoch = 0.00054007\n",
            "Validation mean absolute loss after 35 epoch = 0.00970496\n",
            "Validation special loss after 35 epoch = 0.00021626\n",
            "Validation accuracy after 35 epoch = 0.52882954\n",
            "Step 0 train customized mean square loss = 0.000500\n",
            "Step 1000 train customized mean square loss = 0.000342\n",
            "Step 2000 train customized mean square loss = 0.000447\n",
            "Step 3000 train customized mean square loss = 0.000396\n",
            "Step 4000 train customized mean square loss = 0.000559\n",
            "tensor([ 1.3067e-04,  8.4490e-05, -2.2852e-04,  ...,  3.0849e-04,\n",
            "         3.0312e-04,  2.2850e-04], device='cuda:0')\n",
            "tensor([ 0.0028,  0.0131, -0.0125,  ...,  0.0015,  0.0119,  0.0008],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 36 epoch = 0.00053834\n",
            "Validation mean absolute loss after 36 epoch = 0.00969769\n",
            "Validation special loss after 36 epoch = 0.00021611\n",
            "Validation accuracy after 36 epoch = 0.55051060\n",
            "Step 0 train customized mean square loss = 0.000833\n",
            "Step 1000 train customized mean square loss = 0.000598\n",
            "Step 2000 train customized mean square loss = 0.000440\n",
            "Step 3000 train customized mean square loss = 0.000436\n",
            "Step 4000 train customized mean square loss = 0.000362\n",
            "tensor([ 3.3353e-05, -1.6406e-04,  4.4771e-05,  ..., -1.4875e-04,\n",
            "         1.7617e-04, -1.7570e-04], device='cuda:0')\n",
            "tensor([ 0.0073, -0.0040, -0.0035,  ...,  0.0039,  0.0059,  0.0165],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 37 epoch = 0.00055139\n",
            "Validation mean absolute loss after 37 epoch = 0.00972279\n",
            "Validation special loss after 37 epoch = 0.00021657\n",
            "Validation accuracy after 37 epoch = 0.47604085\n",
            "Step 0 train customized mean square loss = 0.001127\n",
            "Step 1000 train customized mean square loss = 0.000713\n",
            "Step 2000 train customized mean square loss = 0.000425\n",
            "Step 3000 train customized mean square loss = 0.000914\n",
            "Step 4000 train customized mean square loss = 0.000450\n",
            "tensor([-1.7740e-05,  1.4597e-04,  2.0761e-04,  ...,  2.4809e-04,\n",
            "         1.9454e-04,  2.7747e-04], device='cuda:0')\n",
            "tensor([ 0.0089,  0.0037,  0.0098,  ...,  0.0057, -0.0051, -0.0012],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 38 epoch = 0.00054414\n",
            "Validation mean absolute loss after 38 epoch = 0.00970560\n",
            "Validation special loss after 38 epoch = 0.00021628\n",
            "Validation accuracy after 38 epoch = 0.52757266\n",
            "Step 0 train customized mean square loss = 0.000463\n",
            "Step 1000 train customized mean square loss = 0.001209\n",
            "Step 2000 train customized mean square loss = 0.000430\n",
            "Step 3000 train customized mean square loss = 0.000343\n",
            "Step 4000 train customized mean square loss = 0.000316\n",
            "tensor([2.2404e-04, 2.6906e-04, 1.8791e-04,  ..., 3.5329e-04, 3.2559e-06,\n",
            "        9.0266e-05], device='cuda:0')\n",
            "tensor([-0.0188, -0.0076,  0.0077,  ...,  0.0102,  0.0151,  0.0122],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 39 epoch = 0.00054523\n",
            "Validation mean absolute loss after 39 epoch = 0.00969877\n",
            "Validation special loss after 39 epoch = 0.00021614\n",
            "Validation accuracy after 39 epoch = 0.54532600\n",
            "Step 0 train customized mean square loss = 0.000468\n",
            "Step 1000 train customized mean square loss = 0.000356\n",
            "Step 2000 train customized mean square loss = 0.000471\n",
            "Step 3000 train customized mean square loss = 0.000329\n",
            "Step 4000 train customized mean square loss = 0.000491\n",
            "tensor([-4.7348e-05, -2.2536e-04,  3.2518e-05,  ..., -1.2586e-04,\n",
            "        -1.7846e-05, -2.0542e-04], device='cuda:0')\n",
            "tensor([-0.0096,  0.0146, -0.0164,  ...,  0.0081, -0.0060,  0.0137],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 40 epoch = 0.00055901\n",
            "Validation mean absolute loss after 40 epoch = 0.00971493\n",
            "Validation special loss after 40 epoch = 0.00021645\n",
            "Validation accuracy after 40 epoch = 0.49332286\n",
            "Step 0 train customized mean square loss = 0.000278\n",
            "Step 1000 train customized mean square loss = 0.000482\n",
            "Step 2000 train customized mean square loss = 0.000550\n",
            "Step 3000 train customized mean square loss = 0.000412\n",
            "Step 4000 train customized mean square loss = 0.000539\n",
            "tensor([ 2.3649e-04,  3.1375e-04,  2.0756e-04,  ..., -6.7838e-06,\n",
            "        -2.1061e-05, -2.7493e-04], device='cuda:0')\n",
            "tensor([ 0.0231, -0.0081,  0.0077,  ..., -0.0290,  0.0078, -0.0304],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 41 epoch = 0.00054544\n",
            "Validation mean absolute loss after 41 epoch = 0.00969542\n",
            "Validation special loss after 41 epoch = 0.00021607\n",
            "Validation accuracy after 41 epoch = 0.55412412\n",
            "Step 0 train customized mean square loss = 0.000362\n",
            "Step 1000 train customized mean square loss = 0.000570\n",
            "Step 2000 train customized mean square loss = 0.000500\n",
            "Step 3000 train customized mean square loss = 0.000647\n",
            "Step 4000 train customized mean square loss = 0.000827\n",
            "tensor([ 0.0002, -0.0002, -0.0002,  ...,  0.0003,  0.0002,  0.0004],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.0079,  0.0080, -0.0081,  ..., -0.0317, -0.0082,  0.0000],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 42 epoch = 0.00053741\n",
            "Validation mean absolute loss after 42 epoch = 0.00969770\n",
            "Validation special loss after 42 epoch = 0.00021612\n",
            "Validation accuracy after 42 epoch = 0.55208170\n",
            "Step 0 train customized mean square loss = 0.000960\n",
            "Step 1000 train customized mean square loss = 0.000314\n",
            "Step 2000 train customized mean square loss = 0.000680\n",
            "Step 3000 train customized mean square loss = 0.000714\n",
            "Step 4000 train customized mean square loss = 0.000363\n",
            "tensor([1.8297e-04, 2.4012e-04, 1.6218e-05,  ..., 2.2875e-04, 2.0052e-04,\n",
            "        3.2920e-04], device='cuda:0')\n",
            "tensor([-0.0033,  0.0105,  0.0134,  ..., -0.0023, -0.0169,  0.0066],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 43 epoch = 0.00054505\n",
            "Validation mean absolute loss after 43 epoch = 0.00969550\n",
            "Validation special loss after 43 epoch = 0.00021608\n",
            "Validation accuracy after 43 epoch = 0.55380990\n",
            "Step 0 train customized mean square loss = 0.000546\n",
            "Step 1000 train customized mean square loss = 0.000408\n",
            "Step 2000 train customized mean square loss = 0.000859\n",
            "Step 3000 train customized mean square loss = 0.000820\n",
            "Step 4000 train customized mean square loss = 0.001135\n",
            "tensor([-1.6998e-05,  2.3477e-04, -1.5152e-04,  ...,  8.9491e-05,\n",
            "        -1.4648e-04, -2.1618e-04], device='cuda:0')\n",
            "tensor([-0.0089, -0.0014,  0.0474,  ...,  0.0041, -0.0118,  0.0073],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 44 epoch = 0.00053674\n",
            "Validation mean absolute loss after 44 epoch = 0.00971016\n",
            "Validation special loss after 44 epoch = 0.00021637\n",
            "Validation accuracy after 44 epoch = 0.51076198\n",
            "Step 0 train customized mean square loss = 0.000492\n",
            "Step 1000 train customized mean square loss = 0.000428\n",
            "Step 2000 train customized mean square loss = 0.000419\n",
            "Step 3000 train customized mean square loss = 0.000450\n",
            "Step 4000 train customized mean square loss = 0.000457\n",
            "tensor([1.1200e-04, 1.0211e-04, 8.2517e-05,  ..., 1.2460e-04, 1.3571e-04,\n",
            "        7.0438e-05], device='cuda:0')\n",
            "tensor([ 0.0000, -0.0387,  0.0023,  ..., -0.0229, -0.0164,  0.0193],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 45 epoch = 0.00053866\n",
            "Validation mean absolute loss after 45 epoch = 0.00970263\n",
            "Validation special loss after 45 epoch = 0.00021623\n",
            "Validation accuracy after 45 epoch = 0.53794187\n",
            "Step 0 train customized mean square loss = 0.000541\n",
            "Step 1000 train customized mean square loss = 0.000448\n",
            "Step 2000 train customized mean square loss = 0.000520\n",
            "Step 3000 train customized mean square loss = 0.000626\n",
            "Step 4000 train customized mean square loss = 0.000699\n",
            "tensor([ 2.2054e-04, -1.3427e-04, -3.1502e-04,  ...,  3.4537e-05,\n",
            "         3.6670e-05, -1.0869e-04], device='cuda:0')\n",
            "tensor([-0.0185, -0.0019, -0.0202,  ...,  0.0038,  0.0019,  0.0007],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 46 epoch = 0.00055451\n",
            "Validation mean absolute loss after 46 epoch = 0.00971570\n",
            "Validation special loss after 46 epoch = 0.00021647\n",
            "Validation accuracy after 46 epoch = 0.49112333\n",
            "Step 0 train customized mean square loss = 0.000301\n",
            "Step 1000 train customized mean square loss = 0.000490\n",
            "Step 2000 train customized mean square loss = 0.000401\n",
            "Step 3000 train customized mean square loss = 0.000541\n",
            "Step 4000 train customized mean square loss = 0.000502\n",
            "tensor([ 1.6383e-04,  7.9336e-05, -6.7687e-05,  ..., -1.7533e-05,\n",
            "         4.8019e-05,  8.7308e-05], device='cuda:0')\n",
            "tensor([ 0.0043, -0.0011,  0.0084,  ..., -0.0077,  0.0003,  0.0151],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 47 epoch = 0.00054331\n",
            "Validation mean absolute loss after 47 epoch = 0.00970813\n",
            "Validation special loss after 47 epoch = 0.00021634\n",
            "Validation accuracy after 47 epoch = 0.51594658\n",
            "Step 0 train customized mean square loss = 0.000390\n",
            "Step 1000 train customized mean square loss = 0.000709\n",
            "Step 2000 train customized mean square loss = 0.000376\n",
            "Step 3000 train customized mean square loss = 0.000564\n",
            "Step 4000 train customized mean square loss = 0.000605\n",
            "tensor([ 2.0155e-04,  2.2862e-05,  3.2653e-04,  ...,  3.8850e-04,\n",
            "         1.2789e-04, -1.0474e-05], device='cuda:0')\n",
            "tensor([ 1.5888e-03,  5.7961e-05, -6.1162e-04,  ...,  2.9580e-03,\n",
            "        -4.6496e-03,  0.0000e+00], device='cuda:0')\n",
            "Validation customized mean square loss after 48 epoch = 0.00054229\n",
            "Validation mean absolute loss after 48 epoch = 0.00969621\n",
            "Validation special loss after 48 epoch = 0.00021610\n",
            "Validation accuracy after 48 epoch = 0.55600943\n",
            "Step 0 train customized mean square loss = 0.000708\n",
            "Step 1000 train customized mean square loss = 0.000773\n",
            "Step 2000 train customized mean square loss = 0.000421\n",
            "Step 3000 train customized mean square loss = 0.000475\n",
            "Step 4000 train customized mean square loss = 0.001074\n",
            "tensor([ 1.2551e-04,  1.5040e-04,  1.1580e-04,  ...,  8.6021e-05,\n",
            "         1.2983e-04, -2.0292e-04], device='cuda:0')\n",
            "tensor([ 0.0054,  0.0029,  0.0056,  ..., -0.0069,  0.0061, -0.0045],\n",
            "       device='cuda:0')\n",
            "Validation customized mean square loss after 49 epoch = 0.00054273\n",
            "Validation mean absolute loss after 49 epoch = 0.00970139\n",
            "Validation special loss after 49 epoch = 0.00021621\n",
            "Validation accuracy after 49 epoch = 0.54234093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctDOc4GixbA7",
        "colab_type": "code",
        "outputId": "68bf2fb3-601e-4143-f510-347b8b176a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "plt.plot(train_loss_list)\n",
        "plt.title('MSE versus Epoch')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'MSE versus Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOy9eZxkdXnv/35q76V6md5nX2EWhgEc\nUQwqiAZQw0SjV9CgSeCaGExyY+4vwSQXE3JJ4k1uzC8JREkkQcUgUZRRWVxQwMg2wMwwCzM0s/be\nPdNdvVRXVVfV9/5xzqmurq7l1Npd3d/369WvqTp71XSf5zzb5xGlFBqNRqPR2MGx0Beg0Wg0mupB\nGw2NRqPR2EYbDY1Go9HYRhsNjUaj0dhGGw2NRqPR2EYbDY1Go9HYRhsNjUaTNyKyXkSUiLgW+lo0\nlUUbDc2iR0ROiUhERFpTlr9i3rjWm+9Xi8i3RGRERAIickhEfs1cZ93kJlN+PlLxD1QGzM82lfLZ\n/nChr0uz9NBPCZpq4SRwE/CPACKyE6hN2earwAFgHRAGdgKdKds0KaWi5b3UWUTEVcHz7VJKdVfo\nXJplivY0NNXCV4GPJ73/BPCVlG3eDPy7UmpKKRVVSr2ilHos3xOJyEdEZF/Kst8Xkb3ma6+I/K2I\nnBGRQRH5oojUmOuuEpEeEfkjERkA/k1EWkXkeyIyJiLnReQZEXGY2ysR2Zx0nn8Xkf9tvs64X56f\n589E5Jsi8g0RmRCRl0VkV9L6bSLyU/M8h0XkhqR1NSLyf0XktOm9/cz6rCYfM7+HERH5k3yvTVN9\naKOhqRaeAxrMG5wTuBH4Wppt7haRG0VkbRHn+i5woYhsSVr2UeDr5uu/Bi4ALgE2A6uAO5K27QRW\nYHg8nwT+AOgB2oAO4I8BO/o9he6Xjj3Af5rX9XXgOyLiFhE3xuf9AdAO/A7wgIhcaO73t8CbgLeZ\n+/4hEE867pXAhcA1wB0isq3A69NUCdpoaKoJy9t4D3AU6E1Z/2HgGeB/ASdFZL+IvDllmxHzidr6\nmXeTU0oFgUcwwmGYxmMrsFdEBMMQ/L5S6rxSagL4SwwjZhEHPqeUCiulpoEZoAtYp5SaUUo9o+yJ\nvuW738spn+3apHUvKaW+qZSaAf4O8AFvNX/qgb9WSkWUUk8C3wNuMr2a3wB+TynVq5SKKaV+rpQK\nJx33z5VS00qpAxihwV1oljTaaGiqia9iPPH/GvNDUyilRpVStyuldmA8me/HeKKWpM1alVJNST9H\nM5zr65hGwzznd0xj0oaRS3nJujkDj5vLLYaVUqGk938DdAM/EJETInK7zc+b736XpXy2J5LWnbVe\nKKXiGB7MSvPnrLnM4jSG99SKYVzeyHLOgaTXQQwDpFnCaKOhqRqUUqcxEuLvBR7Ose0IRmhlJUZY\nJV9+CLSJyCUYxsMKTY0A08COpJtzo1Iq+WY5xxtQSk0opf5AKbURuAH4jIhcY64OMjeh32lzv3xZ\nY70wPYjVQJ/5syYlV7IWw4sbAULApgLPqVmCaKOhqTZuAd6llJpKXSEinxeRi0TEJSJ+4FNAt1Lq\nXL4nMcM4/4nxtL8Cw4hYT+n/AnxBRNrN865KCQWlXtf7RWSz6fEEgBizeYH9wEdFxCki1wHvtLlf\nvrxJRD4oRl/F/8CoLnsOeB7DcP2hmeO4Cvgl4EHzs94H/J2IrDSv8QoR8RZ4DZolgDYamqpCKfWG\nUmpfhtW1wLeBMeAERiL6hpRtxlJ6GT6T5XRfB94N/GdK2ewfYYSNnhORceBHGMngTGwxt5kEngXu\nUUr9xFz3exg36THgY8B3bO6XjgMpn+3vk9Y9AnwEGAVuBj5o5kki5vmvx/As7gE+rpR6zdzvfwKv\nAi8C54HPo+8byxrRQ5g0mqWNiPwZsFkp9asLfS2a6kc/MWg0Go3GNtpoaDQajcY2Ojyl0Wg0Gtto\nT0Oj0Wg0tlnSgoWtra1q/fr1C30ZGo1GU1W89NJLI0qptnTrlrTRWL9+Pfv2ZarO1Gg0Gk06ROR0\npnU6PKXRaDQa22ijodFoNBrbaKOh0Wg0Gttoo6HRaDQa22ijodFoNBrb2DIaInKdiBwTke50mv7m\n+MtvmOufF5H1Ses+ay4/lqwEmumYIvKAufyQiNxnThaz1l1lDtY5LCJPFfqhNRqNRlMYOY2GOVrz\nbgwVzO0YE722p2x2CzCqlNoMfAFDCRNzuxuBHcB1wD2mvHK2Yz6AMSVtJ1AD3GoeqwlDgfMGc8jO\nhwv90BqNRqMpDDuexuUYMwlOmDLKD2LMG05mD3C/+fqbwDXmDIA9GLr8YaXUSQw56cuzHVMp9agy\nAV7AGBYDxvS0h5VSZ8zthgr7yJXlwNkxnj+R9zgHjUajWZTYMRqrSBoViTEmclWmbcy5AwGgJcu+\nOY9phqVuxhilCXAB0CwiPxWRl0Tk4+kuVkQ+KSL7RGTf8PCwjY9XPibDUW65fx93PHJ4Qa9Do9Fo\nSsVi7gi/B3haKfWM+d4FvAm4BiNs9ayIPKeUOp68k1LqXuBegN27dy+oGuOXnnqDkckwsXihw9Y0\nGo1mcWHHaPSSNF8YI1zUm2GbHnOcZCNwLse+GY8pIp8D2oDfTNqmBzhnjvmcEpGngV3AHKOxWOgb\nm+bep0/gdgqjwRlmYnHcTl2sptFoqhs7d7EXgS0iskFEPBiJ7b0p2+wFPmG+/hDwpJmT2AvcaFZX\nbcAYX/lCtmOKyK3AtcBN5oxii0eAK835z7XAW4Cj+X/kyvC3TxxDAbe+fSMA56ciC3tBGo1GUwJy\nehpKqaiIfBp4AnAC9ymlDovIncA+pdRe4MvAV0WkG2OO8I3mvodF5CHgCBAFblNKxQDSHdM85ReB\n0xjhJzCS33cqpY6KyOPAQSAO/KtS6lBpvobScrBnjIdf6eW3r9rExaubABieCNPR4FvgK9NoNJri\nsJXTUEo9CjyasuyOpNchMpTAKqXuAu6yc0xzecZrUkr9DfA3dq55oVBK8b+/f5TWeg+fumoTxwcn\nABieDC/wlWk0Gk3x6CB7iXni8CAvnDzP77/nAvw+N631XgBGJrTR0Gg01Y82GiUkEo3z148dZUt7\nPR/ZbeT5E0ZjUuc0NBpN9aONRgn56nOnOXUuyB+/bxsus1Kqzuuixu1kRIenNBrNEkAbjRIxFozw\nDz9+nbdvaeWqC+ZOSWzzexnW4SmNRrME0EajRPzDj7uZCM3wJ+/bhln1laC13qM9DY1GsyTQRqNE\n7D3Qy/U7u9ja2TBvXWu9VxsNjUazJNBGo0RMhKKsbq5Ju67V79WJcI1GsyTQRqMERGNxwtE4dZ70\nLSZt9V5GgxFmYlqDSqPRVDfaaJSA4EwMgFqPM+36Vr8XpbSUiEajqX600SgB0xHLaGTyNDwAuoJK\no9FUPdpolICpcBSAOm8GTyPR4KeNhkajqW600SgBwVyehl93hWs0mqWBNholIOFpZMppmJ6GDk9p\nNJpqRxuNEpDwNLzpPQ0tJaLRaJYK2miUgKlIdk8DoNWvu8I1Gk31o41GCQiGDU+jJovRaNNd4RqN\nZgmgjUYJCCY8jcwzrVrrtWihRqOpfmwZDRG5TkSOiUi3iNyeZr1XRL5hrn9eRNYnrfusufyYiFyb\n65gi8oC5/JCI3CcibnP5VSISEJH95s8dLBKmEjmNbOEpLSWi0Wiqn5xGQ0ScwN3A9cB24CYR2Z6y\n2S3AqFJqM/AF4PPmvtsx5oXvAK4D7hERZ45jPgBsBXYCNcCtSed5Ril1iflzZyEfuBwEI1FcDsHj\nzPx1tppSIlEtJaLRaKoYO57G5UC3UuqEUioCPAjsSdlmD3C/+fqbwDVi6IPvAR5USoWVUieBbvN4\nGY+plHpUmQAvAKuL+4jlZyoco9bjnCeJnkyblhLRaDRLADtGYxVwNul9j7ks7TZKqSgQAFqy7Jvz\nmGZY6mbg8aTFV4jIARF5TER2pLtYEfmkiOwTkX3Dw8M2Pl7xBCNR6jKU21pYUiJDOq+h0WiqmMWc\nCL8HeFop9Yz5/mVgnVJqF/CPwHfS7aSUulcptVsptbutrS3dJiVnKhLLWjkFWkpEo9EsDewYjV5g\nTdL71eaytNuIiAtoBM5l2TfrMUXkc0Ab8BlrmVJqXCk1ab5+FHCLSKuN6y8705FY1sopSDYaOjyl\n0WiqFztG40Vgi4hsEBEPRmJ7b8o2e4FPmK8/BDxp5iT2Ajea1VUbgC0YeYqMxxSRW4FrgZuUUoms\nsYh0mnkSRORy89rPFfKhS81UOJpRFt1iVn9KexoajaZ6yf54jJGjEJFPA08ATuA+pdRhEbkT2KeU\n2gt8GfiqiHQD5zGMAOZ2DwFHgChwm1IqBpDumOYpvwicBp41bcTDZqXUh4BPiUgUmAZuNA3TghOM\nxBJGIRMJKRGd09BoNFVMTqMBiXDQoynL7kh6HQI+nGHfu4C77BzTXJ72mpRS/wT8k53rrTRTkSjr\nPLU5t2v1exjWnoZGo6liFnMivGoIhnPnNMDIa+jwlEajqWa00SgBU5Fo1m5wi9Z6LyMTOhGu0Wiq\nF200ikQpRTASy5kIByMZrj0NjUZTzWijUSSRWJxYXGWc2pdMa72X81pKRKPRVDHaaBSJJYuebZaG\nRVu9R0uJaDSaqkYbjSKxBjBlmtqXTGLsqw5RaTSaKkUbjSKxRr3aqZ6abfDTnoZGo6lOtNEokqmw\n5WnYq54C9DAmjUZTtWijUSSWp1HrtmE0tJSIRqOpcrTRKBLL08gljQ5GstzndmgpEY1GU7Voo1Ek\n0zOmp2GjekpEdK+GRqOparTRKJIpq+TWhqcBRl5DV09pNJpqRRuNIglaJbc2PA3QUiIajaa60Uaj\nSCxPw05HOGjRQo1GU91oo1EkwUgUr8uB0yG2tm/zaykRjUZTvWijUSRTkajtfAZoKRGNRlPd2DIa\nInKdiBwTkW4RuT3Neq+IfMNc/7yIrE9a91lz+TERuTbXMUXkAXP5IRG5T0TcKed6s4hEReRDhXzg\nUmNX4dZCS4loNJpqJqfREBEncDdwPbAduElEtqdsdgswqpTaDHwB+Ly573aM0a87gOuAe0TEmeOY\nDwBbgZ1ADXBryrV8HvhBQZ+2DNgdwGTRqqVENBpNFWPH07gc6FZKnVBKRYAHgT0p2+wB7jdffxO4\nRowB33uAB5VSYaXUSaDbPF7GYyqlHlUmwAvA6qTz/A7wLWCogM9aFuwOYLJoMz0N3eCn0WiqETtG\nYxVwNul9j7ks7TZKqSgQAFqy7JvzmGZY6mbgcfP9KuADwD9nu1gR+aSI7BORfcPDwzY+XnEEI4V6\nGtpoaDSa6mMxJ8LvAZ5WSj1jvv974I+UUlnLjpRS9yqldiuldre1tZX9IqfC0bxyGpaUiBYt1Gg0\n1YidR+ReYE3S+9XmsnTb9IiIC2gEzuXYN+MxReRzQBvwm0nb7AYeNKJetALvFZGoUuo7Nj5D2cg3\nES4iuldDo9FULXY8jReBLSKyQUQ8GIntvSnb7AU+Yb7+EPCkmZPYC9xoVldtALZg5CkyHlNEbgWu\nBW5K9iqUUhuUUuuVUusx8ia/vdAGA4w+DTsDmJIxjIZOhGs0muoj591OKRUVkU8DTwBO4D6l1GER\nuRPYp5TaC3wZ+KqIdAPnMYwA5nYPAUeAKHCbUioGkO6Y5im/CJwGnjW9ioeVUneW7BOXGCOnYd/T\nAKPB7+z5YJmuSKPRaMqHrUdkpdSjwKMpy+5Ieh0CPpxh37uAu+wc01xux5D9Ws6LrgDxuDLDU/l7\nGi+fHi3TVWk0Gk35WMyJ8EWPJYtel0fJLRhd4VpKRKPRVCPaaBTBVELhNk9Pw+81pESCOq+hyUwg\nOJNQUdZoFgvaaBRBMGx/AFMysw1+2mhoMnPzfc/zuUcO595Qo6kg+T0ia+ZQjKcBWn9Kk5nQTIxD\nvQGiMbXQl6LRzEF7GmnoG5vmkf29TIazhwamI4XlNFqzSIn86MggV37+SfrGpvM6pmZpcXxwgriC\n0+emMKrXNZrFgTYaaXjlzBi/9+B+ekazl8VORfIbwGTRWu8B5kuJ7Dt1ntu+/jI9o9OcHJnK65ia\npcVr/ROA8Tume3o0iwltNNLQXGuosY9OzWTdLmh6Ivl6GvVeFz63Y47ROD44wS3378PrMv5LJkI6\nAbqcOdI/nnh9+px+gNAsHrTRSENTreEJjOWobrI8jXwEC2FWSsTSn+obm+YT972Ax+Xgi7/6JoCc\noTHN0ua1gXFa6ozfw1PndCOoZvGgjUYamutMTyOYw9NIJMLz8zRgVkpkLBjhE/e9wGQoyv2/fjnb\nuhoAmAhlP7dm6aKU4mj/BFdvbcfpEM5oT0OziNBGIw3NpqcxmsvTCBeW0wDDaPSOTXPL/fs4fS7I\nvR/fzfaVDYnRsZM6PLVsGRgPEZie4eLVjaxqqtGehmZRoY1GGnxuJzVuJ6M55ngHI1FEwOfO/2ts\n83s5OTLFy2dG+fsbL+GKTS0AeFwOvC6HDk8tY6wk+LauBta11OqchmZRoY1GBppr3TbCU8YAJlNY\nMS86G3wA/PkNO3jvzq456/w+FxPaaCxbrCT4hZ1+1rXUak9Ds6jQzX0ZaKr15EyEByP5DWBK5uNX\nrOOydU28fcv8QVH1XpcOTy1jXhuYYFVTDQ0+N+tb6ghMzzAWjCQKNDSahUR7GhlornPbymnU5TlL\nY/b4nrQGA6De59LhqWXM0f7xREHEupY6QFdQaRYP2mhkwPA0cldPFeppZGOxeRpKKf7uh8c51Bso\n2znC0Rife+QQg+Ohsp2jGgjNxDgxPMm2Lj8A61tqAd2roVk8aKORASOnkdvTKI/RcC+qnEbv2DT/\n8OPXufsn3WU7x+G+ce5/9jRPHB4o2zmqgdcHJ4krEp7GmhW1iMCpEe1paBYHtoyGiFwnIsdEpFtE\nbk+z3isi3zDXPy8i65PWfdZcfkxErs11TBF5wFx+SETuExG3uXyPiBwUkf0isk9Erizmg+eiudZD\nYHqGeDyz7o/haZQ+LdTgczEZXjx9GvvPjgHw02PDCb2tUmNpbb0xNFmW41cLRweMJPjWTsPT8Lmd\ndDX4tKehWTTkNBoi4gTuBq4HtgM3icj2lM1uAUaVUpuBLwCfN/fdjjH6dQdwHXCPiDhzHPMBYCuw\nE6gBbjWX/xjYpZS6BPgN4F8L+sQ2aar1EFcwnqXJbioSy1tCxA71vsUVnnrljGE0pmdiPHV8qCzn\nSBiN4eV9c3ytf4IatzORywAjr3FKGw3NIsGOp3E50K2UOqGUigAPAntSttkD3G++/iZwjRh1qHuA\nB5VSYaXUSaDbPF7GYyqlHlUmwAvAanP5pJqV+6wDyir9ucLsCj+fpVdjuoBRr3ao9xqJ8MWibvrK\nmVEuXdtEc62bxw6VJ3zUN2bkMt4YXuaeRv84F3T6cTpmy7jXt9ZyRs+U1ywS7BiNVcDZpPc95rK0\n2yilokAAaMmyb85jmmGpm4HHk5Z9QEReA76P4W2UjaZEV3g2TyNKXTlyGj4XMzFFOLrw42Aj0TiH\n+sbZva6Z92zv4MmjQ4SjpQ9R9ZqeRn8gtGwrx5RSvDYwzjYzNGWxdkUdI5MRLS2jWRQs5kT4PcDT\nSqlnrAVKqW8rpbYCvwz8RbqdROSTZs5j3/DwcMEnb7YhWhgMx6gtsOQ2G37zmItB6fZo/ziRaJxL\n1zZz/UVdTISj/Ff3SMnP0zc2jdtpPF2fXKYhqsHxMKPBmUQS3GK2gkp7G5qFx47R6AXWJL1fbS5L\nu42IuIBG4FyWfbMeU0Q+B7QBn0l3QUqpp4GNItKaZt29SqndSqndbW3p+yDskJBHz+BpRKJxIrE4\nte7yeBqwOJRuXzkzCsCla5t42+YW/F4Xj71a+hBV39g0l61tBpZviCo1CW5h5Te00dAsBuwYjReB\nLSKyQUQ8GIntvSnb7AU+Yb7+EPCkmX/YC9xoVldtALZg5CkyHlNEbgWuBW5SSiXiMyKy2cyTICKX\nAV4Mw1QWcsmjW1VE5fA06r2GwVoMyfBXzo7R2eCjq7EGr8vJNdva+eHRQWZipQudBSNRRoMzXLGp\nBadDlq3RsDSntqZ4GutMT0MnwzWLgZxGw8xRfBp4AjgKPKSUOiwid4rIDeZmXwZaRKQbwzu43dz3\nMPAQcAQjN3GbUiqW6Zjmsb4IdADPmuW1d5jLfwU4JCL7MSqvPqLKmClu8LlwOiRjr4Y1H7wsOQ0r\nPLUIym5fOTPGJWuaEu+vu6iLseAMz584X7JzWEnwDa11rF1RS/cyLbs92j/OqqYaGmvcc5bXeV20\n+b267LaEjE5FylY+vtSx9ZislHoUeDRl2R1Jr0PAhzPsexdwl51jmsvTXpNS6vOYpbyVQERoqsks\nWhgso6fh9y0OefRzk2HOnA/ysbesTSx75wVt1LidPHaonyu3zIsOFoRVbruyqYZNbXXL19MYGJ8X\nmrJYr4ULS8pN//Icb93Ywp/dsGOhL6XqWMyJ8AWnqdadMTwVrICnsdA5Daup71Iz1wBQ43Fy9dY2\nnjg8SCxL42M+zDUa9ZwaCRItYfirGgjNxHhjeGpeEtxiXUud9jRKhFKKkyNTnBjR32chaKORhRV1\nnoxzwosZwJSLxZIIf+XMGE6HsHNV45zl113UxchkmJdOj5bkPH1j0zgEOvxeNrXXE4nF6RmdLsmx\nq4XuoUliccXWrvSexroVtQyOhxMPK8uRnxwb4lNfe6no40yGo4SjcUbMccua/NBGIwtNtZ6MOY2E\np1GOjvBFUnL7ytlRtnb6qUnxpt61tR2Py8Fjh/pLcp7esRCdDT5cTgeb2uqB5VdB9drA7OCldKxr\nNSqolnOT35NHh3js0AChmeJyESOTEfNfbTQKQRuNLGQTLZyychplCE95XQ7cTllQTyMWVxw4G+DS\ntU3z1tV7XbxjSytPHBooSdd639g0K5tqANjUZtwcl5vRONo/js/tYH2SfEgyulfDGIML2aV97GAZ\ni3NTkazacpr0aKORheZaD6PBmbQ3xqB5Qy9HeEpE8PvcC5oIf2N4kslwlEvXNKddf91FXfQFQhzo\nKV4uvS8wazSaaj201nt4Y2h5xZtfGxjnwo658iHJrFth9Wosr+8lGUs2f3y6uL8LKywViyvGphe+\nQrHa0EYjC021HiLRONNp3GHL06grg9GAWf2phSK5qS8d79nWgcshRYeo4nFF/1goYTQANrbVLytP\nQynF0f4JtnamD00BNNa6aa51L+sKqoFAaT0NMCoENfmhjUYWsnWFT5s5jdR4f6mo97oWNKfxypkx\nGmvcbGhNHy5prHVzxaYWHi8yRDUyFSYSi7OqyZdYtmmZGY3hiTDnpyIZk+AWy7mCKhqLJ27240V6\nB8NJCfBhbTTyRhuNLCREC9Mo3U5FYnicDjyu8nyF9Qs8U8Nq6jOb8NNy/UVdnD4X5KjZyVwIVmNf\nsqexqa2O0eBMVoXhpcTRHElwi/Uttct2GNPwZBgr/RAo1mhMzv5ejUwuj9+xUqKNRhYsTyPd2Ndg\nOEptGSqnLPwL6GlMhqMcH5rIGJqy+MUdHTgE7v5pN//VPVJQNUpyj4bFpvblVUF1tN/QnNqWJTwF\nhqfRF5gui8rwYscKTQGMF/l3MTIZprPB8Gx12W3+lCcgv0RYUWfJo6f3NMohVmhR73MxObwwRuPg\n2TGUmtvUl47Wei/XXdTJ9w/28/2D/YllWzv9XNjp5+oL23N2jaczGputstuhSd68fkUxH6UqeK1/\nnJWNPhpr3Vm3W9dSi1Jw9vw0m03DulxInh1fbHhqZDLMpvY6RibDuuy2ALTRyMLsTI35RiMYiZZF\nQsSi3rtw0/teMTvBL1md3dMAuPujlzE8GebYwATHBiZ4zfz3a8+d5j9eOMOrf3ZtxoogMOZo1Htd\nNPhmv8uVTTV4XY5l5GlMzBMpTMes2u3UsjMacz2N4o3Gm9Y201Lv0UajALTRyEKTlQhP0xU+FY6V\nRULEot7nYmKBqqdeOTPKxra6nE++YJQHt/t9tPt9vH3LrBT9f+47y//3zYOcHMl+gzN6NHxzcidO\nh7ChtW5ZjH4NR2O8MTzJNdvac267PqF2u/zyGgPjYdxOocHnLkHJbYTWei8tdV6d0ygAndPIgtvp\nwO91ZfY0ylRuC0ZOIxKNVzx+rZRi/9mxjP0Zdtm+0nhyPmLG6zPRl1Jua7GpfXlUUL3WP0E0rrgo\nRaolHSvqPPi9Ls4swwqqwfEQ7X4jhFeMpzEVjjI9E6PV76XV79WeRgFoo5GDprr0ooXBSKwsEiIW\nlpSIpXFVKXpGpxmZjORMgudiS7sft1M43Je9+S+5GzyZTW31nD0fLFoyYrFzsNf4fi5endtoiAjr\nWpen2u1AIERHg9f0NAo3GpaRaK330lrv0YnwAtBGIwdWV3gqwUisrJ5GvW9hBjG9nKOpzy4el4Mt\n7X6O9GX2NEIzMc5NRViV1mjUEVdLXzbj1Z4xVtR50n4H6ViuvRqD4yE6G3001LiLqp6aNRoe2uqN\n8FQZx/IsSbTRyEFTrSetpzEVjlbE06j0IKZXzoxR43ZyYUf2RjM77FjZwJG+8Yx/lLOVU75565aL\ncOHBngA7VzVm7YdJZn1LLT2j0yWdnLjYUUoxMB6io8FHg8/FRBGexvCE8bdseBpeIrF40SW8yw1t\nNHJgiBam9zRq3GXMaSzQIKb9Z8fYuboRl7P4X40dKxs4NxVhKEMIINHY1zj/KXujJVy4hKf4TUdi\nHB+cYJeN0JTFuhV1ROMqYXCXAxPhKMFIjM4Gy9MoPjzV5vfS6vfMWaaxh607g4hcJyLHRKRbRG5P\ns94rIt8w1z8vIuuT1n3WXH5MRK7NdUwRecBcfkhE7hMRt7n8YyJyUEReFZGfi8iuYj64XZrTyKMr\npZiKlNfT8C/ATI1wNMaRvvGiQ1MW21caN8NMeY10PRoWtR4Xq5pqlrSncbgvQFzBThulzRbrlmEF\n1ZDZo9HZ6EtUTxUaUrIMxIo6D631XmOZzmvkRU6jISJOjJnc1wPbgZtEZHvKZrcAo0qpzcAXMMey\nmtvdCOwArgPuERFnjmM+AGwFdgI1wK3m8pPAO5VSO4G/AO4t6BPnSXOth4lQdE44IDQTR6nyKNxa\nLMT0vmMDE0RicVv9GXbYZhdy/SYAACAASURBVGopHe5Nn9foHZtGxLgZpGNj29Iuuz3YYz8JbrG+\ndfmp3Q4EjJt6R4OPhhoXkViccLSw8NzIZJjmWjdupyNhNM4tE7maUmHH07gc6FZKnVBKRYAHgT0p\n2+wB7jdffxO4Rowg7R7gQaVUWCl1Eug2j5fxmEqpR5UJ8AKw2lz+c6WUNSruOWt5uWmumy8lUs4B\nTBbW9L5KSolY0/LWZZjpkC9+n5t1LbUZy277xqbp8PtwZwiFWcKFSzVR+WpvgI4GLx0N6Y1mOtr9\nXnxux7LSoLLmaHQ2GJ4GFN4VPjwRThiLhKehw1N5YcdorALOJr3vMZel3UYpFQUCQEuWfXMe0wxL\n3Qw8nuaabgEeS3exIvJJEdknIvuGh4ezfjA7WF3hycnwYKR8o14t/F6zeqqCnkZ/wBIPtH8Ty8WO\nlQ0czlBBZczRyHyuze31BCOxxE1jqXGgZ4ydq/Lz6kSE9Yuwguq1gXE+8qVnixYTTMdgcniqxjQa\nBeY1RiYjtPkNY7GizoNDdHgqXxZzIvwe4Gml1DPJC0Xkagyj8UfpdlJK3auU2q2U2t3W1pZuk7xI\nJ48+ZXkaZewI97kdOB3CRJGSCfnQPzZNjdtJY03uTnC77FjZyJnzwbR/5Jka+ywSFVQVGMj0+KH+\nin7XE6EZTgxP5ZUEt1jXUsvJRWY0fnh4kOdPnucnrw2V/NgDgRCNNW58bmdCbiZQYFf4yOSsp+F0\nCCvqPHNUbzW5sWM0eoE1Se9Xm8vSbiMiLqAROJdl36zHFJHPAW3AZ5JPIiIXA/8K7FFKnbNx7UXT\nnEZ/ymq4K9csDTCeKCutP9UfCNHV6LNd/mmH7aam0tEUb0MpRe/YdNb+hE3t2Ue/fv9gPz88Mlj0\nNfaOTfNbX3uZP//ukaKPZZdXzaa+nQUYjS3tfk6fW1yNj1YI8qfHymA0xkMJVdqiPY2k8BQYIapK\nh6fuffoNvvlST0XPWUrsGI0XgS0iskFEPBiJ7b0p2+wFPmG+/hDwpJmT2AvcaFZXbQC2YOQpMh5T\nRG4FrgVuUkolsl0ishZ4GLhZKXW8sI+bP00JefTk8JSV0yivdFe9t7L6U32BabpKGJoCIzwFzAtR\nnZuKEInGs3oabfVe/D5XWqPx0Itnue3rL/PZh18tes7zQMDI5Xzr5R4O9RY/vtYOryaS4PkXHWzr\naiAWV7w+uHgqyyx596eODxMr8dztwfEQHWaxRDE5jelIjKlILFFqCwtjNL7+/Bnu+9nJip6zlOQ0\nGmaO4tPAE8BR4CGl1GERuVNEbjA3+zLQIiLdGN7B7ea+h4GHgCMYuYnblFKxTMc0j/VFoAN4VkT2\ni8gd5vI7MPIk95jL9xX74e0wK4+eFJ4KWzmN8nkaYJTdVtTTGAvRlaZnohja/IZcQ2oyPFu5rYWI\npJ3i99ir/dz+8EE6G3yMTIbZ3zNW1DUOjhs3DZdDuPN7RyqSeD/YG2B1c03i9ysfrKq0ozl0vSrF\nZDjKqXNBLuioZzQ4w8Ei/z9SGQiE6GwwvIOGGuNBrZCGvGQJEYvWBVC6DUzPcHxwYlF5ivlgK6dh\nVjRdoJTapJS6y1x2h1Jqr/k6pJT6sFJqs1LqcqXUiaR97zL3u1Ap9Vi2Y5rLXeayS8yfO83ltyql\nmpOW7y7Vl5CNGrcTj8sxJzyV8DTKmAiHys4Jj8biDE2EWJmh/LVQRITtKxvneRrZusGT2dRWPyen\n8czrw/zeg/u5ZE0T377tbTgdwo+KDFFZidbffdcWXjh5nicOFx/yysXBnrG8Sm2TWddSR63HmVMM\nslIcGzCu45Pv2IRD4CfHii9AsbDGvCbCU0V4GtZo17bU8NRE5XIaSinGQ1GiccWxgcInXi4kizkR\nvigQEaMrfCpN9VQZS27BGvlaGaMxNGGM0+wssacBRoiqe2iCSFJtfa/ZDZ5Lc2lTex0D4yEmw1Fe\nOj3KJ7/yEhvb6vi3X7ucrsYa3rJhBT86WqzRMGS3f+uqTVzQUc9fPXa0rOrCo1MRzp6fLig0BUYC\n98JO/6IxGpa+2Ns2tXDJmiaeKmFewxrzaoWnfOZDXCE5DatKKtnTaKn3Mj0TY6pCf2eT4WgifPdq\nhUKhpUYbDRukihZW1NOoUHiq34zrlzqnAUYyfCamOD44+2TVNzZNrSd3pZZVQfXowX5+/d9eoKPB\ny1duuTwx6+Pd2zo4PjhZVAnqkCm77XY6+JP3bef0uSBf+fnpjNtPhqPcev+L3PbAywWdL6Fsa0MO\nPRPbuho42p9Z16uSHOmfoLHGTVejj6svbOdAT6BkIR9r+FJnUi9LY01hMzWs2RlzcxqVlRJJLkmu\nVP6s1GijYYOm2rny6InqqTKOewUjp1GpRHg2Hahi2ZFmtoYliZ6rUssyGn/08EFqPS6+estbaPfP\n3kDeva0DoKgqqqGJMB1mzPydF7Txzgva+IcnX+dcmhvJ0ESIj3zpWX50dIjnT54v6HyvmjH/HUUY\nje1dDUyEoomGzIXkSP8427saEBGuutAYJvX08dKEqKzQYXIDZIPPVZinYf5/ttQlhaf8lW3ws4yG\n0yEJRYBqQxsNG6TzNGrcThxZxpiWgqXiaay3YvB9841GLta11OJyCE01br526+WsWVE7Z/3allou\n7PAXFaKyBvxY/On7thGMxPj7H70+Z7s3hif54D0/58TwFFdubmVkMjwn5GaXgz0BNrbWFdUPs80q\nZV7gEFUsrjg2MJ4YurVjZQOt9V5+WqK8RsLTSMq1NdQUNlNjZDJMY40bj2v2tmflN4YrlNcImPeR\nXasbqzYZro2GDVLl0afKPIDJwu9zMz0TI1oBGez+QMic1V26xj4Lh0PY1tUwR7iwdyzEKhsGyu10\n8Pc3XsI3fvMKNrenl2t/z/YOXjw1mlbC3g6D46GEpwGwpcPPRy9fy9dfOMPrZkjtpdOj/Mo//5zQ\nTIxv/OZbuWHXysS++XKwJ1BQf0YyWzv9iBjzxReSkyNThGbiCSPmcAjvvKCNp18vTemtNeZ1Re1s\nSKnBV9hMDaOxb261WqWlRCxP48otbVWbDNdGwwbNtW7GgjOJ+HEwXN5RrxaVnN7XPxbKKBxYCrZ3\nNXC0f4J4XBGaiTEyGbYdCnv/xSu5IMt8j3dv7yAWVwU93U5HYoyHorSn6D/9/nsuoNbj5K5Hj/KD\nwwN89F+eo6nGzbc+9TYuXt2U+K7ylTgZGg8xMB4qOAluUed1sb6lbsE9DSvkaDVxAlx1YRtjwRn2\nny2+9NbyApO9+oYad0EzNYZTGvsAWkwjcq5CXeEJo7G5FajOZLg2GjZYUechGleJ/MJUJFb2Hg1I\nEi2swCCm/sA0XWU0GjtWNjAZjnLmfDARcrATnrLDxasaafN7+WEBIaqhifkxczD+z3/3XVv46bFh\nfvNrL7G1q4FvfeptCTFH67uy9LrsUoiybSa2ddmroIrFFQ+9eJae0dKLHB7tH8ftFDa31yeWvWNL\nGw4pTXf4QGD+w0zhOY1IIodh4XY6aKp1V9zT2L6ygaZad1Umw7XRsEFCtHDK+A+fjsTK3g0O4PdW\nTum2LxAqSxLcYoc5W+NI/zi9Nhr78sHhEN69rZ2njg3nnWOwBkS1p9xMAD7+tnXsWNnAL27v4D/+\n+1toSXpKTXgagfwS0Qd7AzhktjigGLZ1NnDmfDCnZtZPjw3xh986yNV/+1PueORQQSG1TBzpG2dz\nu39OnqCx1s1la5tLktcYTJIQsWioKWymxshEeE6PhkUlu8ID0zM4HUKdx8nOVY1VmQzXRsMGs6KF\nhgs7FYlW1NMod69GJGo0UJUjCW6xpaMep0M43BdIGA27c7Ht8O5tHUyGozx3Ij9JsnTVORZel5Pv\n/c6VfOnm3fPCkX6fm3qvK29P49WeMba0+0sS3rSSz7ni4k8dH6bG7eRDb1rD158/wzv+z0/4y0eP\npq0OyxerciqVq7e282pvIOHJFULymNdkGnzuvGdqhGZiTISj83IaUNmu8MD0DI01bkSEnauqMxmu\njYYNLE/jvGk0guEKhae89ka+/o8HX+GLT71R8HkGx0MoVZ5yWwuf28mW9noO943TZw5f6mic/9RX\nKL+wuZUatzPvKipLQiQ5EZ5MtpLgzkZfItRmB6VUSZLgFlbyOVeI6qnjw1yxqYW/+uBOnvyDq3jf\nxV386zMneMf/+Qn/9wfHEn1H+TI8EWZ4IpyQNUnmnRcYCtNPHx8p6NiQNOY15fckISWSR14jecxr\nKoanUbmchlU1t3NVY1Umw7XRsEFzimjhVCRa9sY+mB35mqtX48evDfHM64WHAvrTlDWWg+1dDRwx\njUZbvRevq3SG1+d28vYtrfzoyGBeYYuh8RAel6Og8teuRl9enkZfIMS5qUhJ8hnW+Rtr3FmT4adG\npjh9Lpi4ia9tqeXv/tsl/OD338FVW9v5xye7+acnuws6v3Xe7WlCbTtWNtDm9xaV1xgMpPcCE1Ii\neeQ1Eo19mcJTFZqpEZieSSj1XmT26VRbMlwbDRsk5NHNnEYwEiu7hAhAvTWIKYunMRmOMhGK5h0m\nScbq0Sjl8KV0bF/ZwNBEmIM9gZLlM5J59/YO+gKhvOQ1rMa+QuTgOxvy8zQOmtVExVZOWYiIYYiz\nlN0+bT5MWEbDYnO7n7s/ehmXb1jBz7oL8waOpqmcSr62qy5o4+njwwWXjCdP7EvGuunmM1MjnYSI\nRZvfy0Q4WpEw0fj0DE3m9a9urqnKZLg2GjZoqHEjkuRphCvjaczmNDI/UVk3rf6xUMGSElY3eKkV\nblOxkuGvDUyUNJ9h8a6t7YjAj47Yf7pNbezLh65GH0MTIds3xYO9AVwOYWtn5vLhfNnW1cCxgfGM\nPRFPHRtm7YraxGzxVN66YQWHegMFVSMd6R9nZaMvEb5N5aoL2xkPRQsuvR3I6GlYSrf5h6dSq6eg\nslIiY0nhKSuvUW3JcG00bOB0CI01bkaDM8TiinA0XpE+jVq3E5Hsnob1hzU9EytIjwcMT6PB5yp7\nRVjyE2k5vJrWei+XrW3mh0cHbO+T2tiXD52NNcTVrHpqLl7tCbC1y4+vhPIz21c2EJqJc3JkvvZW\nOBrj52+cm+dlJPPWjS3EFbx0ajTvcx/tH08bmrK4cksrTofwkwJDVMljXpNJDGIqIKfRkkaKfrbB\nr/x5jeScBhghqmpLhmujYZMVtR5Gg5GkAUzlD085HEK9J7v+VH9SyWdfnuWfs8co/RyNdDTWulnd\nbJynHOEpMLrDD/WOz/lesjE0Hi7K0wB7vRpGEjz/meC5yDZb46VTo0zPxLIajUvXNuNxOvKuOgvN\nxHhjeCqRjE9HY42bNxVRejs4Hk6MeU1mNqeRR3hqMoLf50prsBNGo8x5jXhcMZ5iNC6uwmS4Nho2\naTK7wi1Z9HKOek2mPscgpuSa+3zi68n0l2FiXyYsb6NcRsMSMPzR0dxPt8FIlIlwNG25rR1mezVy\nf++nzwUZD0VLlgS32Nxej8shafM4Tx0fxu0UrtjUknH/Go+TS9Y05W00jg9OEIurtPmMZN55YRuH\n+8YZKqA3ZCBNjwbMFojk42kMT6bv0YDZrvByh6cmI1HiinmeBlRXMtyW0RCR60TkmIh0i8jtadZ7\nReQb5vrnRWR90rrPmsuPici1uY4pIg+Yyw+JyH0i4jaXbxWRZ0UkLCL/s5gPXQjNpqdh6e5XIqcB\nuQcx9QdCWAoLBXsaZZjYlwkrr1GOnAbAprY6NrTW2RrMNDSeubHPDvl4Gq+Zg4pK0dSXjNflZHN7\nfVpP46njw+xetyJn2PGtG1fwam8gZ5NgMtkqp5K52lS9tWPEU0ke85qMz+3Em+dMjdTZ4MlUSn/K\nEitMNhrVmAzPaTRExAncDVwPbAduEpHtKZvdAowqpTYDXwA+b+67HWP+9w7gOoxRrc4cx3wA2Ars\nBGqAW83l54HfBf62sI9aHE21HkanIrMDmCrkafhzDGIaCITY0u7HIYV5GqGZGOemIiWf2JeJ9+/q\n4n0Xd82RnSglIsLVF7bz7IlzORPU2Rr77GCEThy2usJPjhgSHhsyJKSLYbs5WyOZgUCI1wYmeOeF\nmUNTFm8x8xr78shrHOkbp87jZE1zbdbttnX52dhWx3f299o+tkXymNdUGvKcqTE8GZ4zRyMZn9uJ\n3+sqe07DkhBpSDIa1ZgMt+NpXA50K6VOKKUiwIPAnpRt9gD3m6+/CVwjRg3jHuBBpVRYKXUS6DaP\nl/GY5hhYpYxSoBeA1ebyIaXUi0D5hZjS0FxrJMITnkYFZEQA6n3urDIi/YEQq5traPf7ElVQ+WDd\nOLvK9OSfyqa2eu7+6GUlTQansq3LTyQazzlrYnAie2NfLkSErsYaW57GyZFJWuu9+MugIrytq4HB\n8fCcDu9MpbbpuGxtM26n5BWiOto/wbauhpzjAUSED1yyihdOns9L+yp1zGsq+epPZfM0wKiqKren\nYYXTUnuCypEMf/zQgO28Xr7YMRqrgLNJ73vMZWm3UUpFgQDQkmXfnMc0w1I3A4/buMay01znYXom\nlpASqZinkSM8NWC68F1NPgbG8/8lmS23rYynUQk2moOb3hiezLqdFWdPVbjNB7u9GqdGgmxozf5U\nXihWiChZJv2p48O0+722ynsTeQ2bQ6XicWXIh9gMtf3ypcaf9iP7+2xtD/PHvKaSz0yNcNRQMs5q\nNCogJRLIYDRK2RkejcX5y0eP8ltfe4m7f1JY02YuFnMi/B7gaaXUM/nsJCKfFJF9IrJveLh0A+6b\nzK5wa7Z1xTwNrytjrDk0E+P8VISuBp/RnVyAp5EYvrSEjMamNiMEdGI4+wjYoYkwXpcjUfdfCHa7\nwk+MTJUlNAXzBzJFY3F+9voI77igzXbT4ls3tnDIZl6jZ3SayXA0a+VUMmtW1PLm9c18+5Ve271E\n6ca8JpPPTI1zWbrBLSohJZIwGrXzjQYUnwwfngjzq19+nnufPsHNb13H/3p/ahahNNgxGr3AmqT3\nq81labcRERfQCJzLsm/WY4rI54A24DN2PkQySql7lVK7lVK729pyu+Z2sbrCe82QR6U8jWzVU8l1\n7FaYJN8GP+uGV6lEeCVoqvWwos7DiZHsnsagKYZXSDe4RWejj8HxEPEsA4cmQjOMTIYzNtgVy4o6\nDx0N3kQF1YGeAIHpGVuhKYu3bmwhFlfsO507r5FuhkYufvnSVXQPTXK4z163fq58Uz4zNRKNfWnE\nCi0qoXQ7Zl5vU4qnUYpk+Eunz/P+f3yG/WfH+Lv/tou/+OWLSirTk4wdo/EisEVENoiIByOxvTdl\nm73AJ8zXHwKeNHMSe4EbzeqqDcAWjDxFxmOKyK3AtcBNSqnyj6yzScJojBlx2Uo094HhaUxFYmk7\nfpNv+F2NPqZnYnMG19uhb2ya5lp3xUqIK8WmtjreyOFpFNPYZ9HV6CMaV4xMZb7hnDKT4BvLZDRg\nbjL86ePDOGR20I8d8slrHOkfxyFwYR6d7e/b2YXbKXz7FXsJ8XRjXpNp8Lls/65n6wa3aK33Mhac\nYaaMUzID0zO4HDLvgbOYZLhSivt/foqPfOk5fG4nD3/qF/jgZatLdclpyWk0zBzFp4EngKPAQ0qp\nwyJyp4jcYG72ZaBFRLoxvIPbzX0PAw8BRzByE7cppWKZjmke64tAB/CsiOwXkTsARKRTRHrM4/+p\niPSISGnrF7PQXGeFpyrraVg16VNplEiT/7AsTyFfDaqBCjX2VZqNrfWcyJnTCBeVzwCjKxyyV65Z\nHs+G1vJUjIERouoemiQcjfHU8WF2rWmiOU33cyZqPE52rW7iuRO58xpH+8fZ2FafVzFDU62Hqy9s\nZ++BPluyK+nGvCbTUONmPDRjy7MeMed/Z+rTABKVVZkm+Cmlik5UJ8uip1JIMjwai/OZhw7wub2H\nuerCNvZ++krbeaZisJXTMCuaLlBKbVJK3WUuu0Mptdd8HVJKfVgptVkpdblS6kTSvneZ+12olHos\n2zHN5S5z2SXmz53m8gGl1GqlVINSqsl8XbFZl8nhKadD8Loqkw7KJo+erE7bmegZyC8Z3hcILal8\nhsXGtjpGJiNZn0YN3aniPQ3IbqwtT2NdS3kS4WAYjWhc8eLJUQ70jPGOLfmHZq28Rq75LUf60s/Q\nyMUHLl3F8ESYn7+R25tJN+Y1mQafm5mYIjST2wANT2YWK7TI1avxwPNnePNdPyoqhJUqIZJMIcnw\nH782xLdf6eV33rWZe2/eXZBScyEs5kT4oqIpMYhphlqPs6g4eD5kG8Q0OB7C73NR73UltJzy9TQq\n2Q1eSawKqkzexmQ4ylQkVnCPhkWXja7wkyOTrGqqKWuZsfWE+S/PnEApbPVnpJLIa5zK7G0EgjP0\njk3bToInc/XWdvw+F9+xEaJKN+Y1mcRMDRuJ+5HJMPVeV9YQrGU0MumI/ee+s0yEonzjxbNp19th\nPEkWPZVCkuHfPdBnjCW+ZkvO0udSoo2GTbwuZyIkValucJj1NNL1aiTP9W6r9+IQ8qqgmo7EGAvO\nLMnwVK4KqqFEorU4T2NFnQeP05HVWJ88F2R9mcptLda31OFzO3jq+DCNNW52FSC/ftm6JjOvkdlo\nHB2w1wmeDp/byfsv7uLxwwM5Bz+lG/OaTEJ/ykZeY2QykjUJDrOhq3T6U2fOBTnQE8DtFL723OmC\npd6zeRr5JsODkSg/PjrE9Rd14nZW9jaujUYeWCGqSszSsPBn8TSMpzHjhu9yOuhoyHcoUGXmaCwE\na1bU4nJIxgqqxMS+AsUKLUSEzkZfxrCgUoqTw5NlK7e1cDqErZ3GjfztprpsvtR6XFy8OrsO1ZG+\n/CunkvnlS1YRjMT4weHMMi+Zxrwmk1C6teNp5Gjsg9mcRrqy2+8eNPpL/vi92+gPhAqSRIHsRsNK\nhh+wmQz/0dEhpmdi3LBrZUHXUgzaaOSBFaKqVBIcsg9i6g+E6Er6w8p280rHbC380vM03E4Ha1tq\neWMog6cxUXxjn0Vnll6N0eAM46FoWZPgFlbI6B15lNqmYulQpXtI6Rub5ktPv8HG1rq0Y1Pt8Ob1\nK1jVVJO1iirTmNdkEjM1bEiJjEzmNhq1Hhe1HmfanMX3DvZz6domPn7FelY11fCVZ0/lPGc6shkN\nMKrdjvaPJ3TKsrF3fx8dDV7evH5FQddSDNpo5EHC06hkeCrDIKaZWJzhyfCcuO/Kxpq89Kf6xpau\npwFmBVVGT8MyGsXPKe/KMiv8ZKJyqrzhKYDLNzTjczu4qiijYeQ1Xkrp1xgPzfAb//4iwXCMe371\nsoKP73AIey5ZyTOvDzOcQYo805jXZPLxNLLpTiWTrlfjjeFJjvaP8/6LV+J0CB9761p+/sY5Xh/M\nr3s7nSx6Kh958xp8bgf//l+nsh4rEJzhqeNDvP/ilRXNZVhoo5EHVgljXQU9jcSc8BRPY2gijFJz\n69g7G330BaZtN/hVajb4QrGprY5T54Jpe1yGxsPUmEJ1xdJpGo1037uVU6mEp7Fn1yqevf2aoryn\nN61rxuWY268Ricb57a+9TPfQJF+8+U2JMFihfODSVcSVkchNR6Yxr8nYzWnMxOKMBWdyehpgNP+l\nltx+70A/IkafCcBHdq/B43LwlWdP5zxeMpYselNtZqPRVOvhg5et5uFXeufoiKXyxJEBZmJqQUJT\noI1GXjRb4akKSYjAbNI9NVxgKasm3/C7Gn2EZuK2m576A9O01nvK1jm60GxqqycSjSe6+JMZLGI2\neCpdDT4isTjnp+bHw0+dm8LpkMTwqXLicEhevRnpqPW42JU0X0MpxWcffpWfdY/w179yMb+QR8Ng\nJrZ0+NmxsiFjiCpXYx8kzdTIISViR0LEoiWNp/G9g328ed2KxLW01Hv5pYtX8vDLPXlJyVuy6Jmq\npyx+/W3riUTj/McLZzJu890DfaxdUVvy2Sx20UYjD6xZyJX0NJwOoc7jnOdpzHaDJxsN48ZkV+22\nr4JzNBaCjWYFVTrhwsHxUEnyGTDb4Jcur3FyZIq1K2orXuFSDG/ZsIKDPQGmwlH+/kev862Xe/j9\nd1/Ah95Uuk7jD1y6ild7A3QPzQ/z2JGsT8zUyPGANGKjR8MiNTx1bGCC14cmef+urjnbfeJt65iK\nxHj4Zfty75nEClPZ0uHn7Vta+epzp4lE51dpjUwafS6/tKurYmX/qVTPb/IiIOFpVDCnAen1p6yn\nsa6kJLbVb2FX7TZXLXy1k03tdqgEjX0W2Xo1To4Ey145VWqsvMaffucQ//+PX+dDb1rN716zuaTn\nuGHXShwCH/vX57nl31/krx97jYdf7uFQb4Az54M01c4f85qK1RWeDavvos1GTqOt3sP5qUginPm9\ng304BK6/aK7RuHh1E7vWNHH/s6dsh4LtGg2A37hyA4PjYR471D9v3WOv9hOLK27YlSo0Xjkqe/er\ncqxEeCXmgyeTbnpffyBEjduZaHKC2ZuXbU8jMM1bN1a++qJSrKjz0FTr5sTI3AoqpRRDE+GiG/ss\nEl3hKSNNlVKcGpniio2Zx60uRqy8xrdf6eXtW1r5qw/uLPlTbXuDj3+86TIePdTP64MTPHV8mGhS\n7smOpHuDz5Wzesrqu7Dlafi9xBWcnzL6Or57oI8rNrWkrRT7xBXr+MxDB/iv7nNcuSV3yC4fo/HO\nLW1sbKvjvp+d5IZdK+d899890M8FHfV56X6VGm008qBpwTwNNxPzchqG/EfyL1S734fTIbYqqCbD\nUSZC0YoNX1ooNrbWzesKnzRLOott7LNoqfficsi8CX6D42GmZ2JsaKsuT6PO6+ItG1dwfmqGez52\nWdlCa++72JjiCEbC+tTIFMcHJzk+OMEla3I3J9rxNEbyyGkkS4kMjoc4dS7Ib75zU9pt37uzi7u+\nf5T7nz1VcqPhcAi//rb1/K9HDvPymTHetK4ZMHKQL5w6zx+854Kcxygn2mjkwWzJbWU9Db/XxWTK\nH8fA+PzQktMhtPu9BjtF1AAAFZBJREFUtmaF948tvTka6djUVs9Tx+fOVUk09pXI03A6JG1jZUKo\nsKW6jAbAfb/2ZoCKFUm4nQ62dPjZ0uHnfXTl3gGjgmosmH0GxsikUSVnZ/5NstH4WfcILodw3Y7O\ntNv63E5uvHwN//zTN+gZDbI6x9jbfIwGwAcvW83fPHGM+/7rZMJofO+AEa76pQWqmrLQOY086Gz0\nIWI8WVaSdOGpTPmIbD0DyVg3uJVL3dNoq2doIjyn0sWSECm0QS0dnWm+d0uosNo8DTCMxWKvqjM8\njRzhKZs9GjA7b2N4Isz3D/bzC5tbs1ajfewt6wBDzDAXmWTRM1HndXHj5Wt5/NBAop/quwf7uHh1\nY9nmsthFG4086Gjw8d1PX8n1F6V/+igXqYnwWFwxOJ5endbuzGqrczxbLfxSYGMaDarBidzVOfmS\nzmicHJnE63LM6drXlA4jp5G7espOaApm5238+LUhekanef/F2T2elU01vGd7Bw++cCanpHk2WfRM\nfPyKdSil+Mqzpzk1MsXBngC/dPHCehmgjUbeXLSqseLlk/Ve15ycxrnJMNG4SpR6JtNlSonkquro\nGwshsnQb+ywSwoVJneFDJQ5PgdGrkTo58eTIFOtb6haka3c5YGemxshExLbR8HtdeFwOHj80gMfp\n4BczhKaSufHytYwGZ3g+x3z1wPTMvDGvuVjdXMt1F3XyHy+c4aF9hrru+3IYskqgjUYV4PcZ4Snr\njyPRo5HmptdpNviNBbM/gfUHpmmr91ZV/0AhrF1Rh9Mhcz2N8TB1HmdCQbgUdJqTE5OreU6WcS64\nxt5MjZHJsO0wpIjQVu8lFle844I2W/kHq8rr7Plg1u0CwewSIpn49V/YQGB6hi89fYLL169YFOHk\npX3HWCLUe10oBcGI4QJnk/+wfqlyhaj6A6ElXzkF4HE5WLuidk6vxuBEdgXVQkhMTjR7ZKKxOGfO\nBxc8/ryUyTVTIxqLcz5o39OA2bzGL+2y90Tf7vfhckhiomcmcokVZmL3umZ2rmokFle2r6nc2DIa\nInKdiBwTkW4RuT3Neq+IfMNc/7yIrE9a91lz+TERuTbXMUXkAXP5IRG5T0Tc5nIRkX8wtz8oIoWr\nplUZqYOY0kmIWNid4JeqkLuUMcpuZz2NofFQSZPgkPy9G8a6byzETEyVdS74cieX/tSgqc+WTxNn\na70Xr8vBNds6bG3vdAgrm2roSSNVk0yhRkNE+PS7NtPu9/LenVViNETECdwNXA9sB24Ske0pm90C\njCqlNgNfAD5v7rsduBHYAVwH3CMizhzHfADYCuwEaoBbzeXXA1vMn08C/1zIB65G/OYfhyUl0j8e\nwuN0pJ2fvNLGrHClFP1jS3NiXzo2ttVxcmSKuNk8NjheusY+i9SucCuHoj2N8pFL6faoOftjW5f9\nRrhb376Rv/6VnXmFLlc11dA7miM8VaDRALh2Rycv/Mm7K161mQk7nsblQLdS6oRSKgI8COxJ2WYP\ncL/5+pvANWKUCewBHlRKhZVSJ4Fu83gZj2nODlfKCOC/AKxOOsdXzFXPAU0isjhMb5mxlFhnPY0Q\nHY3etAnWNr8Xp0OyehrjIWPU6colrDuVzMa2esLROL1j02Y3eKhkjX0WbX5zcqJpNE6NWOq22miU\ni1wzNQ73jSNCXqq8V2xq4QOX5qextbo5u6cRjyvGQ4UbjcWGHaOxCkgejNtjLku7jVIqCgSAliz7\n5jymGZa6GXg8j+tARD4pIvtEZN/w8HDq6qqkPiGPbjxRGaGl9Dd8p0Po8HuzehqWQVkunsamJA2q\n8VCU0Ey85J6G2+mgze9NhA5Pjkzh97pyjhnVFE4uT+NIf4ANLXW2GvuKYVVzDUMTYcLR9GW3E+Eo\nStlv7FvsLOZE+D3A00qpZ/LZSSl1r1Jqt1Jqd1tb4cNoFhOWq2z1auQSGuxs9GWdFW6tW8oKt8kk\n92qUo7HPojOpR+bEyBTrW+sWTIl0OZArp3G4b7ygWeb5YnWDZ/qbs64vlyx6tWDHaPQCa5LerzaX\npd1GRFxAI3Auy75ZjykinwPagM/keR1LEstoTJhltwMZGvssuppqEoNs0tFjxl+XuoSIRUudhwaf\nixMjkyWXEEmmq2G2we/UOV1uW26yzdQIBGfoGZ2uiNFYZVYhZgpR5SshstixYzReBLaIyAYR8WAk\ntvembLMX+IT5+kPAk2ZOYi9wo1ldtQEjif1CtmOKyK3AtcBNSql4yjk+blZRvRUIKKXmawcvQaw/\njslQlNHgDJFoPKun0dXgo28sc4Pfj18bYlVTzZLvBrcQETa21RueRhm6wS26mgyjEY7G6B2d1knw\nMpNtpsaRfiMJvmNl+QcVWQO2esfSJ8Mto9G0RIxGzmCfUioqIp8GngCcwH1KqcMiciewTym1F/gy\n8FUR6QbOYxgBzO0eAo4AUeA2pVQMIN0xzVN+ETgNPGu69g8rpe4EHgXei5FMDwK/XoovoBqoS0qE\nJ/IROTyNcNRo8EvVzjk3GeaZ10f472/fuKw6lTe11fNf3SMJT6NUszSS6Wr0MRGOcqRvnLhCl9tW\ngExKt4f7AgBs7yq/p9HZ6MMhNjyNPDvCFyu2MkRKqUcxbtrJy+5Ieh0CPpxh37uAu+wc01ye9ppM\nz+U2O9e71HA7HfjcDibD0aRRmJnzEYm5GoHpeUbj0UMDxOKKPZcsvIZNJdnYVse3Xu7hxPAk9V5X\nWZKj1v/Js+aoVB2eKj+ZZmoc6Run3e8tS+4qFbfTQVdjTdqxwkBCnWE5hac0i4B6r5uJUHS2GzxL\neCXbJLm9+3u5oKPe1pCbpYSlQfXcyXO0l7jc1sL63p99wzAaOjxVfjJ5Gkf6x9lRgXyGxaosDX7L\nMaehWQRY+lMDgRBOh2R9gkrMCk8xGr1j07x4anTeNLDlgDX69ez5aTr85cnlWIb8xVPnaanzLJmb\nxGKmweeel9MIzcR4fWiyIvkMi9XNNRmlRALTM7idQk2O8bXVgjYaVUK9OYipP2DMtnZmyUdYDX6p\nk+S+e6APYEHnCy8U61pqsb6yUjf2WVjJ9dBMXHsZFaIxzUyN44MTxOKqIpVTFquaa+gPTDMTmy+e\nWIgs+mJGG40qwRrENDA+nVPOPNHgl1I3vnd/H5esaWJtS/YpY0sRr8vJmhXG524vU9WYx+VIiOPp\nfEZlaKiZP1PjSJ9VOVU5o7G6uYa4Sh8SHp+eWTI9GqCNRtVQ73Mlchp2+iu6muYOY+oemuBI//iy\nS4AnY1UzlaNyysL6v9FGozI0+ObP1DjcN47f62JNjhGspWRVk3GudHmNYnSnFiPaaFQJftNoDARC\ndGaQEEmm0xzGZLF3fx8OWRxDXBYKK69Rjh4Ni05tNCpKQ838mRqH+wJs62qoaEn5bK+GNhqaRYLf\n62J4IkwwErPlaaxsnJ0kp5TikQN9vG1TK+1lSgJXA5acSDmNhvY0KktCSsSsoIrFFa8NTFQ0nwGz\nOm49adRuA9MzS6axD2z2aWgWnnqfi4iZZLMzorWz0WjwGw3OcPZ8kNPngtx29eZyX+ai5j3bOth/\nZoydq8pXVbOlvZ46j5P1LdpoVILEIKbpGToafJw6N0UwEqtoPgOMnFlHgzdtr8ZS8zS00agS6r2z\nv3R2PQ0wFG0f2d+Hx+ngWhszj5cy7Q0+/ubDu8p6jhsvX8u1F3VS41ka5ZWLnVRP47CZBK+0pwHp\nezWWmiw66PBU1WDJo4NdT8Nyl6f57sE+rt5qb+axpjjcTseyDgFWmoQ8utkVfqRvHLdT2NJe+ebV\nVc2183IaEyFDFl1XT2kqjjWISQRbNyVrVvgj+3sZnggvy94MzdInMYgp4WkEuKDDj8dV+VvbarNX\nIxafreRaat3goI1G1WDJo7fUeW39QbTWGw1+jx0aoM7j5Jpt7eW+RI2m4sx6GkbZ7ZG+8YqIFKZj\nVVMNMzGVUFIGbTQ0C4gVnrI7A8Nq8FPKmDHsWyISBhpNMtbYgMD0DEMTYc5NRSqeBLdIlN0m5TW0\n0dAsGJanYSefYdFlhqhuWMYNfZqljdflxOd2MB6KJuTQd5SxOi4bltHoSWc0logsOmijUTX48/Q0\nwNBbaq338AubW8t1WRrNgmOJFh7uNSqnFkrB2eoKT06GL0VPQ5fcVglWaWE+c73/+L3b+N13bcHt\n1M8GmqWLJY8e6J9hfUstft/C3KBrPE5a6jxzGvxmp/Z5Mu1Wddi6m4jIdSJyTES6ReT2NOu9IvKN\n/9fevcVYVd1xHP/+AgMOIDPjMMU6QwUrtY6NxYQSbX1AsYW2RprGNtg2JUTDC1SaXtWHNrUhqQ8t\n1agPRI2maaXESksbU2vExMY04FDwAkg6BVTQyoBcVCgE/Pdhr2MPZ27buR1mn98nMXP2Onsv1l+3\n/Gfvtfd/pe83Sppe9t3tqX2npPn99SlpeWoLSVPK2pskrZP0oqRNkj410KBHo6aJ47j3G1ew6DPT\n+t85mTJpvKutWuGVFmLa9sbRES2H3pO2pvput6fGpUXUiqLfSCSNAe4Dvgi0AzdJaq/Y7WbgUERc\nDKwC7krHtpMt/XoZsAC4X9KYfvp8DriObMnXcncAWyPicuDbwN0fMtZR7/rLL+i2Ep9ZrZtcX8e+\nw8d57e1jVXmpr1xrU323ifDJBSqLDvmuNOYAnRGxKyJOAmuAhRX7LAQeSZ8fA+Yp+7e0EFgTESci\nYjfZ+t5z+uozIrZExJ4extEObEj7vAJMlzQ1f6hmVkSTz6lj94H3gOq8CV6uLb3gV6q6e+T4SRrq\nizULkCdptAKvl23vTW097hMRp4AjQHMfx+bps9ILwFcBJM0BLgTacozfzApsctlfytV63LaktTGr\n+db17gmgeHWnYHQ9PfULoFHSVuA7wBbgdOVOkpZK6pDU0dXVNdJjNLMRVnpIZMqk8VUv4VL5rkat\nJo19QPnsa1tq63EfSWOBBuBgH8fm6fMMEXE0IpZExCyyOY0WYFcP+62OiNkRMbulpaX/6MxsVCu9\nFV7tqwzI5jTg/+9q1GrSeB6YKWmGpHFkE9vrK/ZZDyxOn28ENkR2U289sCg9XTUDmAlsytnnGSQ1\npn0BbgGejYijOcZvZgVWutI4K5JG45mLMR05VoNJI81RLAeeBHYAayNim6Q7Jd2QdnsQaJbUCXwP\nuC0duw1YC2wH/gosi4jTvfUJIOlWSXvJrj5elPRA+jMuBV6WtJPsqasVgw/fzEa70pxGtSfBAc49\np46G+jr2HjrG++8H75w4VbikkWtaPyKeAJ6oaPtJ2ef/Al/r5diVwMo8fab2e4B7emj/B/CJPOM1\ns9oxa1ojV13UzGc/fnZUPmhLj92WyqI3TCjWY/LFehbMzGpOW9MEHl16ZbWH8YHWxnp2H3ivkCVE\nYHQ9PWVmdtYrvatx+PhJwEnDzMz60NpUz7GTp9lzMKtB5aRhZma9Kr2rsT2tV+6kYWZmvSo9dlta\n38NJw8zMeuUrDTMzy62hvo5J48dy8L2ThSuLDk4aZmZDStIHt6iKVhYdnDTMzIZc6RZVY4HWBi9x\n0jAzG2KlwoVFm88AJw0zsyHX5qRhZmZ5tTZOAJw0zMwsB19pmJlZbqU5jckFTBqucmtmNsSaJ47j\nh/MvYf5l51d7KEPOScPMbIhJYtk1F1d7GMPCt6fMzCy3XElD0gJJOyV1Srqth+/HS/p9+n6jpOll\n392e2ndKmt9fn5KWp7aQNKWsvUHSnyW9IGmbpCUDDdrMzAam36QhaQxwH9m63O3ATZLaK3a7GTgU\nERcDq4C70rHtwCLgMmABcL+kMf30+RxwHfBqxZ+xDNgeEZ8G5gK/lFSsdRTNzM5yea405gCdEbEr\nIk4Ca4CFFfssBB5Jnx8D5ikruLIQWBMRJyJiN9CZ+uu1z4jYEhF7ehhHAOemficBbwOn8odqZmaD\nlSdptAKvl23vTW097hMRp4AjQHMfx+bps9K9wKXAG8BLwIqIeL9yJ0lLJXVI6ujq6uqnSzMz+zBG\n00T4fGArcAEwC7hX0uTKnSJidUTMjojZLS0tIz1GM7NCy5M09gHTyrbbUluP+0gaCzQAB/s4Nk+f\nlZYAj0emE9gNfDLH+M3MbIjkSRrPAzMlzUgTz4uA9RX7rAcWp883AhsiIlL7ovR01QxgJrApZ5+V\nXgPmAUiaClwC7MoxfjMzGyL9vtwXEackLQeeBMYAD0XENkl3Ah0RsR54EPiNpE6yCepF6dhtktYC\n28kmrZdFxGnIHq2t7DO13wr8CDgfeFHSExFxC/Bz4GFJLwECfhwRB/oa++bNmw9IqnwKK68pQJ/9\nF1itxu64a4vj7t2FvX2h7ILAKknqiIjZ1R5HNdRq7I67tjjugRlNE+FmZlZlThpmZpabk0bvVld7\nAFVUq7E77triuAfAcxpmZpabrzTMzCw3Jw0zM8vNSaMH/ZWCLwpJD0naL+nlsrbzJD0l6V/pZ1M1\nxzgcJE2T9Iyk7anM/orUXujYJZ0jaVPZ8gI/S+0z0pIGnWmJg0JWj04VtrdI+kvaLnzckvZIeknS\nVkkdqW1Q57mTRoWcpeCL4mGykvXlbgOejoiZwNNpu2hOAd+PiHbgSmBZ+m9c9NhPANem5QVmAQsk\nXUm2lMGqtLTBIbKlDopoBbCjbLtW4r4mImaVvZsxqPPcSaO7PKXgCyEiniV7g79ceZn7R4CvjOig\nRkBEvBkR/0yf3yH7i6SVgsee6ra9mzbr0j8BXEu2pAEUMG4ASW3Al4EH0raogbh7Majz3Emju4GU\nbS+SqRHxZvr8H2BqNQcz3NIqk1cAG6mB2NMtmq3AfuAp4N/A4bSkART3fP81WXmi0nIKzdRG3AH8\nTdJmSUtT26DO835rT1ntioiQVNhnsiVNAv4AfDcijma/fGaKGnuq/TZLUiOwjhqoFC3pemB/RGyW\nNLfa4xlhV0fEPkkfAZ6S9Er5lwM5z32l0d1AyrYXyVuSPgqQfu6v8niGhaQ6soTx24h4PDXXROwA\nEXEYeAa4CmhMSxpAMc/3zwE3SNpDdrv5WuBuih83EbEv/dxP9kvCHAZ5njtpdDeQsu1FUl7mfjHw\npyqOZVik+9kPAjsi4ldlXxU6dkkt6QoDSfXA58nmc54hW9IAChh3RNweEW0RMZ3s/+cNEfFNCh63\npImSzi19Br4AvMwgz3O/Ed4DSV8iuwdaKtu+sspDGhaSHgXmkpVKfgv4KfBHYC3wMeBV4OsRUTlZ\nPqpJuhr4O9mywaV73HeQzWsUNnZJl5NNfI4h+4VxbUTcKekist/AzwO2AN+KiBPVG+nwSbenfhAR\n1xc97hTfurQ5FvhdRKyU1MwgznMnDTMzy823p8zMLDcnDTMzy81Jw8zMcnPSMDOz3Jw0zMwsNycN\nMzPLzUnDzMxy+x9KusB34tM/owAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMlcfyyK1aHH",
        "colab_type": "code",
        "outputId": "d37a2a18-e87f-4b69-cf3f-fc3e810e083a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.plot(val_loss_list)\n",
        "plt.title('LSTM with Sliding Window Validation Loss versus Epoch')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.xlabel('Epoch')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAEWCAYAAAAkUJMMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNaGxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA7SaLa3AYTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f258a7a6-e1f5-40c9-83d8-50a3599a5d76"
      },
      "source": [
        "## If pretrained\n",
        "\n",
        "# model_lstm.load_state_dict(torch.load('Best_LSTM.pt'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIIDah03CzB7",
        "colab_type": "code",
        "outputId": "30a3571f-93ac-4ba8-cac3-63a2696378aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "target_list = []\n",
        "prediction_list = []\n",
        "model_lstm.eval()\n",
        "with torch.no_grad():\n",
        "    for i, (inp, target) in enumerate(data_loaders['test']):\n",
        "        inp = inp.to(current_device)\n",
        "        target = target.to(current_device)\n",
        "        lr = model_lstm(inp.float())\n",
        "        prediction_list.append(lr.view(-1))\n",
        "        target_list.append(target.float().view(-1))\n",
        "\n",
        "    prediction_tensor = torch.cat(prediction_list)\n",
        "    target_tensor = torch.cat(target_list)\n",
        "            \n",
        "    val_loss = my_loss(prediction_tensor, target_tensor)\n",
        "    print('Test customized mean square loss = {:.{prec}f}'.format(val_loss, prec=8))\n",
        "\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "    val_loss_l1 = criterion_l1(prediction_tensor, target_tensor)\n",
        "    print('Test mean absolute loss = {:.{prec}f}'.format(val_loss_l1, prec=8))\n",
        "\n",
        "    val_loss_special = ((prediction_tensor - target_tensor) ** 2 / (torch.abs(target_tensor) + 1)).mean()\n",
        "    print('Test special loss = {:.{prec}f}'.format(val_loss_special, prec=8))\n",
        "\n",
        "    sign_prediction = torch.sign(prediction_tensor)\n",
        "    sign_prediction[sign_prediction == 0] = 1\n",
        "    sign_target = torch.sign(target_tensor)\n",
        "    sign_target[sign_target == 0] = 1\n",
        "    val_accuracy = ((torch.abs(sign_prediction + sign_target).sum()/2).tolist())/(sign_prediction.size()[0])\n",
        "    print('Test direction accuracy = {:.{prec}f}'.format(val_accuracy, prec=8))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test customized mean square loss = 0.00045973\n",
            "Test mean absolute loss = 0.00939494\n",
            "Test special loss = 0.00017422\n",
            "Test direction accuracy = 0.54046053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-smcOPe0H8l",
        "colab_type": "code",
        "outputId": "a292024d-3b26-4c2b-d4eb-bc7c4b507cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check unique values\n",
        "\n",
        "torch.unique(sign_prediction, return_counts = True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-1.,  1.], device='cuda:0'), tensor([ 672, 2368], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GXzTTYPOpwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute Sharpe\n",
        "\n",
        "sharpe_table = ffill_test[['ticker','day']].drop_duplicates()\n",
        "sharpe_table = sharpe_table[sharpe_table['day'] != '2018-09-12']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92lGM9AyOtOA",
        "colab": {}
      },
      "source": [
        "sharpe_table['target'] = target_tensor.tolist() \n",
        "sharpe_table['price'] = prediction_tensor.tolist()\n",
        "sharpe_table['not_normal_return'] = sharpe_table['target'] * sharpe_table['price']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5VmTTHYNEc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "return_table = sharpe_table.groupby('day', as_index = False)['not_normal_return'].sum()\n",
        "return_table['normalization'] = sharpe_table.groupby('day', as_index = False)['price'].sum()['price']\n",
        "return_table['return'] = return_table['not_normal_return'] / return_table['normalization']\n",
        "sharpe = return_table['return'].mean() / return_table['return'].std() * np.sqrt(250)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SStt-NQQ14N",
        "colab_type": "code",
        "outputId": "adfbc3ae-318d-4991-84b5-39093530b2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sharpe)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.020204781292402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAsVD2SECy04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "1949b2e0-b9d6-4882-e6af-cbd6493e2e08"
      },
      "source": [
        "plt.title('LSTM Cumulative Return')\n",
        "plt.xlabel('date')\n",
        "plt.ylabel('return')\n",
        "plt.plot(return_table['return'].cumsum())\n",
        "plt.xticks(np.arange(0,160,16), return_table['day'][0:160:16], rotation = 45)\n",
        "plt.text(75, 0, 'Annual Sharpe ratio = 3.0202047')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(75, 0, 'Annual Sharpe ratio = 3.0202047')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAE8CAYAAADaGCZFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeXhU5dn48e+dnZCEhCUEEkICBMIW\nAgQQFAWVxdqCWtyLS7UW99a61Vaq9rXta/vDqpVXsQKugKIoKoogLiBrCGELexKyQvaN7Jnn98dM\nYhIGspBJMnB/riuXM+c855x7Ejz3PMt5HjHGoJRSSjXm0tEBKKWU6pw0QSillLJLE4RSSim7NEEo\npZSySxOEUkopuzRBKKWUsksThFIOIiLJInJlK4+dLCKH2jompVpCE4Q6J2e7CYrIUyKSJCIlIpIm\nIits2/fbtpWISI2IlNd7/5SI3CEiRkRebHS+2bbtS88Sj5+I/FtEUmznO2Z737NNP3gbs32uQbXv\njTEbjTFDHHCdZ0Skyva7KRCRzSIysQXHtzrpKeejCUI5hIjcDswFrjTG+AAxwDcAxpjhxhgf2/aN\nwAO1740xf7Od4hhwg4i41Tvt7cDhs1zTw3aN4cBMwA+YCOQC49v0Azq3FbbffU/gW+DD9rpwo7+n\n6uQ0QShHGQesNcYcAzDGnDDGLGrB8SeAvcAMABHpDkwCVp/lmNuAUOBaY0yCMcZijMkyxvzVGLPG\ndp4G39RFZKmI/I/t9RRbTedxEckSkUwRuUZEfiYih0UkT0Sesnds/ePtBSYi40Vki+1be6aI/MeW\n0BCRH2zFdtu+2d9Y/1wi8oSIrGx0vpdE5GXb624i8qbtvOki8j8i4trUL9gYUw28BwSLSK965/65\niMTXq2FE2ba/Y/v9fmaL83F7n7l+LcNWY1kpIu+KSBFwh23bByLytogU22qUMU3Fq9qfJgjlKFuB\n20TkMRGJac4Ny463sd70AW4CPgUqzlL+SuArY0xJK65VKwjwAoKB+cAbwK+AscBk4GkRCW/FeWuA\n32P91j4RuAK4D8AYc6mtzChbLWpFo2OXAz8TEV8A2+/yBuB92/6lQDUwCBgNTAfubiogW4K6DWsN\nK9+2bTSwGPgt0AN4HVgtIp7GmLlACvALW5wvNPOzzwZWAv5YExLALNvn8sea9P/TzHOpdqQJQjmE\nMeZd4EGsNYDvgSwReaKFp1kFTBGRblhvZG83Ub4HkNnSWBupAp43xlRhvYH1BF4yxhQbY/YDCcCo\nlp7UGLPTGLPVGFNtjEnGeuO9rJnHHgfigGttmy4HSo0xW0WkN/Az4HfGmFPGmCzgRawJ9UxuEJEC\noAz4DTDHVpsAuAd43RizzRhTY4x5C2tSvqhFH7ihLcaYT2w1ujLbtk3GmDXGmBrgHVrxO1WOpwlC\nOYwx5j1jzJVYvyXOA/4qIjNacHwZ8AXwZ6CHMebHJg7JBfq0Nt7ac9huWmC9gQKcrLe/DPBp6UlF\nZLCIfC4iJ2xNLX/Dmnya633gZtvrW/ip9tAfcAcybU1CBViTT+BZzvWBMcYf6A3sw1o7qtUf+EPt\nuWzn6wf0bUGsjaXa2Xai3utSwEv7JzofTRDK4YwxVcaYD4E9wIgWHv428Afg3WaUXQ/MEJGuZylT\nCnjXex/UwnjqO9WCc/0fcBCIMMb4AU8B0oJrfYi1NhWCtSZRmyBSsX7D72mM8bf9+Bljhjd1QmNM\nDtYawzMiUptYU7HWoPzr/XgbY5bVHtboNA1+B7bmr16NyuiU0U5KE4RqC+4i4lXvx802VPVqEfEV\nERcRuQrr6KJtLTz398A04JVmlH0H6w3uIxGJtF23h1iHzv7MViYeuEVEXEVkJs1s5jmDeKx9A91F\nJAj43VnK+gJFQImIRAL3Ntp/EhhwpoONMdnAd8ASIMkYc8C2PRP4Gvh/Yh3i6yIiA0Wkuc1Xh4C1\nwOO2TW8A80Rkglh1rf07niHOw1i//V8tIu5Ya3uezbm26vw0Qai2sAZr00vtzzNYb4ZPYe3ULABe\nAO41xmxqyYmN1TfGmLxmlK3A2lF9EFhni2E71qac2sT0MPALW0y3Ap+0JJ5G3gF2A8lYb9KNO5fr\nexRr01Ax1ptw47LPAG/ZmnVuOMM53sf6+d5vtP02wANr/0g+1g7hljS1/RO4R0QCjTGxWPsl/mM7\n11Hgjnpl/w782Rbno8aYQqyd7f8F0rHWKOyO5FLOR3TBIKWUUvZoDUIppZRdmiCUUkrZpQlCKaWU\nXZoglFJK2XXePJjSs2dPExYW1tFhKKWUU9m5c2eOMabxsyvAeZQgwsLCiI2N7egwlFLKqYjI8TPt\n0yYmpZRSdmmCUEopZZcmCKWUUnZpglBKKWWXJgillFJ2aYJQSilllyYIpZRSdmmCUEopJ/ZxXBof\nxNpbtO/caYJQSikn9sbGJD7Zle6Qc2uCUEopJ5VdXMGBzCIuHtSS5c2bTxOEUko5qc3HcgC4RBOE\nUkqp+n48moOflxsjgrs55PwOTRAiMlNEDonIURF50s7+eSKyV0TiRWSTiAyrt++PtuMOicgMR8ap\nlFLOxhjDpiM5TBrYE1cXccg1HJYgRMQVeBW4ChgG3Fw/Adi8b4wZaYyJxrqo/QLbscOAm4DhwExg\noe18SimlgOTcUjIKy7kkwjHNS+DY6b7HA0eNMYkAIrIcmA0k1BYwxhTVK98VMLbXs4HlxpgKIElE\njtrOt8WB8SqlVKe38Ug2729LodpivV06qv8BHJsggoH6g3PTgAmNC4nI/cAjgAdweb1jtzY6NtjO\nsfcA9wCEhoa2SdBKKdVRtiflMapfNzzdztxg8v++PkxCRhGVNRYG9OpK/x7eDounwzupjTGvGmMG\nAk8Af27hsYuMMTHGmJhevewuiKSUUk5hT1oBN7y+hVe+OXrGMseyS4hPLeCxGUOInz+NVfddjIhj\n+h/AsQkiHehX732IbduZLAeuaeWxSinl1D6Os97i3tqcTGFZFUezinn0w90UlFbWK5OGi8Ds6L74\ne3vQrYu7Q2NyZILYAUSISLiIeGDtdF5dv4CIRNR7ezVwxPZ6NXCTiHiKSDgQAWx3YKxKKdVhKqst\nrN6dwfC+fhRXVPOfDUe4+61YVu5Mq3tK2mIxrIpL59LBvQj082qXuByWIIwx1cADwFrgAPCBMWa/\niDwnIrNsxR4Qkf0iEo+1H+J227H7gQ+wdmh/BdxvjKlxVKxKKdWRvj+cTd6pSh6dPoTLIwN5Y2MS\n6QVl9Pbz5Iu9mQBsScwlo7CcX44Jabe4HNlJjTFmDbCm0bb59V4/fJZjnweed1x0SinVsbKKyyks\nrWL59hR6+ngwOaInAV092JaYy/xfDCOrqIL/t+4wmYVlvLLhCN27ejBtWO92i8+hCUIppdTptibm\n8uq3R9l0NAdjG9z/64vDcXN1IbqfP7vmT8fDzYVj2SX8v3WHefKjvWxNzOPZWcPxcm+/R8I0QSil\nVDuqqrFwz9uxeHu48dDlEQwK9MFiDFMjA+vKeLhZW/8H9vJhaB8/vj+cTXjPrtwyoX2H82uCUEqp\ndrQtMY+i8mr+df0opg8ParL8z6P6cCCziCdmDsHdtX2fTNAEoZRS7Whdwgm83F2YHNG8Z7d+fXE4\nQ3r7csXQwKYLtzFNEEop1U6MMaxLOMklg3rRxaN5fQldPFy5sh07puvr8CeplVLK2WUVlxOfWtBk\nuYTMIjIKy5k2rP1rA62hNQillGqFGoth1a50/rsxkYMnigH4+L5JjAkNOOMx6xJOIgKXR3ZMjaCl\ntAahlFItdPBEEVe/vJFHP9yNq4vw+MwhdHF35cPYtLMety7hJGNCA+jl69lOkZ4brUEopRRQVllD\nQmYRx3NPkVNSQVmlhamRvYgK8W9Q7rPdGTy+cg8+Xm68essYfjYyCBHhaFYJn+/J4C+/GGb3WYX0\ngjL2ZxTx5FWR7fWRzpkmCKXUBS2npII3NiayfHsqhWVVDfZ9tf8EXz48ue790awSHlq+i7GhASy8\ndUyDOZHmjAnh47h0vk44yaxRfU+7zvqEkwDt+iT0udIEoZS6YGUUlHHzG1tJzStl5oggrokOZmCg\nD4G+nny0M41nPktgf0Yhw/ta13z+IDYVVxEW/moMgb4NJ8y7aEAPgv278NHONLsJYl3CSQb06srA\nXj7t8tnagvZBKKUuSJmFZdy0aCt5JZV8OG8SC28dy/ThQQzs5YOvlzvXjA7Gw9WFlTut/QqV1RY+\n2pnGFUMDT0sOAC4uwpyxIXx/OJvbFm9ny7Hcun2FZVVsTcx1qtoDaIJQSl2ALBbDw8vjyTtVydt3\njWds/9NHHvl7e3DlsEA+jc+gstrCNwdOknuqkpvGnXm6i/umDuSxGUNIyCji5je28sTKPRSWVfHd\noSyqLYbpTpYgtIlJKXXBeWfrcbYn5fHCnChGn2VY6pyxIazZe4IF6w6zLSmXPt28uHTwmZ+A9nRz\n5f6pg7jrknBe+uYIr39/jBWx1pWXe/p4EN3vzNfqjDRBKKUuCBkFZfzjy4N4ubvw2e5MLhvci+vH\nnn1thUsjehHs34XXvj8GwB+mDcbVpeklPr3cXXliZiQzhwfx/eFsAGL6BzTr2M5EE4RS6rxwqqKa\nX725DS83V64aGcR1Y0Lw8fzpFvfS+iOs2ZtJ964ehAR04e/XjWxyPWc3VxfWP3IZeaWVGGPo261L\ni2Ia1c+fUf38my7YSWmCUEo5rf0ZhXi6uTIo0IcF6w6zK6WAAT27Mv/T/byxMZEFN0QzLqw7mYVl\nfLwrjZvHh/LXa0a06BpdPFwJ9mhZYjhfaIJQSjmF8qoa3tyURHZxBX+YPpi96YXcsWQHGLjj4jCW\n/JjE3Iv689drRrAtMZfHVu7hhte38NtLB1JaWY3FwD2XDujoj+FUNEEopTq17OIK1u4/waIfEknJ\nK0UEvjl4krySSsJ6eNPXvwuLfkgkyM+Lx2cOAWDCgB6seXgy//N5Ql3/wXVjgunX3bsjP4rT0QSh\nlOq0lvyYxF8/T8BiYEhvX969awJe7i78bkU8vXw9efeuCfT08WRlXBrD+vjh6+Ved6yPpxv/+GUU\nVw7tzeIfk3jo8ogO/CTOSUztgqhOLiYmxsTGxnZ0GEqpNvLtoSzuWrqDqUMCeWzmEIb09q3rVK6s\ntmAxpl3XZz5fichOY0yMvX0OfVBORGaKyCEROSoiT9rZ/4iIJIjIHhH5RkT619tXIyLxtp/VjoxT\nKdW5pOSW8tCyXUQG+fHKLaOJDPJrMOLIw81Fk0M7cFgTk4i4Aq8C04A0YIeIrDbGJNQrtguIMcaU\nisi9wAvAjbZ9ZcaYaEfFp5TqvFbtSqekoprX547F20NbwjuKI2sQ44GjxphEY0wlsByYXb+AMeZb\nY0yp7e1W4OxPrSilLgjbknKJDPLTTuUO5sgEEQyk1nufZtt2JncBX9Z77yUisSKyVUSucUSASqnO\np7LaQlxKPhPCu3d0KBe8TlF3E5FfATHAZfU29zfGpIvIAGCDiOw1xhxrdNw9wD0AoaFnnkBLKeU8\n9qQVUF5l4aIBmiA6miNrEOlAv3rvQ2zbGhCRK4E/AbOMMRW1240x6bb/JgLfAaMbH2uMWWSMiTHG\nxPTqdeYJtJRSzmNbUh4A48N7dHAkypEJYgcQISLhIuIB3AQ0GI0kIqOB17Emh6x62wNExNP2uidw\nMVC/c1spdZ7alpTH4N4+dO/q0dGhXPAcliCMMdXAA8Ba4ADwgTFmv4g8JyKzbMX+CfgAHzYazjoU\niBWR3cC3wD8ajX5SSp2Hqmss7EzOY4LWHjoFh/ZBGGPWAGsabZtf7/WVZzhuMzDSkbEppTrW+oST\njA71p4ePZ922XakFnKqsYYL2P3QKuqKcUqrdJeec4u63Y1m6OblumzGGF746SPeuHmddlEe1H00Q\nSql29+W+EwAcyCyq27ZqVzo7kvN5YuYQ/OrNqaQ6jiYIpVS7+2pfJgAHTxQDUFJRzd/WHCS6nz/X\nj+13tkNVO9IEoZRqV+kFZexOK6Snjydp+WUUlVex6UgOOSUVPD5jCC5Otizn+UwThFKqXX1la16a\nd5l18Z7DJ4rZnpSHp5sLMWHaOd2ZaIJQSrWrr/ZlEhnky8wRQYC1mWl7ci6jQ/3xcNNbUmeifw2l\nVLspq6xh5/F8rhgaSLB/F3w93YhNziMho0ifnO6ENEEopdpNQmYhFgPR/QIQEYYE+bJm3wksBp2c\nrxPSBKGUajd70woBiArpBkBkH18qqy24uQijQ/07MjRlhyYIpVS72ZNeSC9fT3r7eQEwJMgPgBHB\n3XRhoE5IE4RSqt3sTSskKrhb3fvIIF8AxmvzUqekCUIp1S5OVVRzLLuEEfUSxMjgbkwb1pvrxpxt\nLTHVUbROp5RqFwmZRVjMT/0PAF7urrxxW0wHRqXORmsQSql2UdtBPbJeDUJ1bpoglFLtYm96Ib39\nPAm0dVCrzk8ThFKqXcSnFmjtwcloglBKOdyx7BKSck4xOULXeXAmmiCUUg63dr91gr5pw3p3cCSq\nJTRBKKUc7uv9J4kK6UZf/y4dHYpqAU0QSimHOlFYTnxqATOGB3V0KKqFNEEopRxq3YGTAEzX5iWn\n49AEISIzReSQiBwVkSft7H9ERBJEZI+IfCMi/evtu11Ejth+bndknEopx9lw4CThPbsyKNCno0NR\nLeSwBCEirsCrwFXAMOBmERnWqNguIMYYEwWsBF6wHdsd+AswARgP/EVEAhwVq1LKcbKKKxjQsysi\nupSos3FkDWI8cNQYk2iMqQSWA7PrFzDGfGuMKbW93QqE2F7PANYZY/KMMfnAOmCmA2NVSjlIWWUN\nXTxcOzoM1QqOTBDBQGq992m2bWdyF/BlK49VSnVSZVU1dHHXBOGMOsVkfSLyKyAGuKyFx90D3AMQ\nGhrqgMiUUueqrEprEM7KkTWIdKBfvfchtm0NiMiVwJ+AWcaYipYca4xZZIyJMcbE9OqlT2gq1RmV\nVWoNwlk5MkHsACJEJFxEPICbgNX1C4jIaOB1rMkhq96utcB0EQmwdU5Pt21TSjkRi8VQUW3RGoST\nclgTkzGmWkQewHpjdwUWG2P2i8hzQKwxZjXwT8AH+NA2wiHFGDPLGJMnIn/FmmQAnjPG5DkqVqWU\nY5RV1QBoDcJJObQPwhizBljTaNv8eq+vPMuxi4HFjotOKeVodQlCaxBOSZ+kVko5TFmlNUF4aQ3C\nKWmCUEo5TLmtBuGtNQinpAlCKeUwpZXaB+HMNEEopRxGO6mdmyYIpZTD1CYIL21ickqaIJRSDlNe\nqX0QzkwThFLKYbQPwrlpglBKOYz2QTg3TRBKKYcp1z4Ip6YJQinlMGXaxOTUNEEopRymrKoGd1fB\n3VVvNc5I/2pKKYcprazRaTacmCYIpZTDlOtqck6t2bO5iogr0Lv+McaYFEcEpZQ6P+hqcs6tWQlC\nRB4E/gKcBCy2zQaIclBcSqnzgK4m59yaW4N4GBhijMl1ZDBKqfOL1iCcW3P7IFKBQkcGopQ6/2gN\nwrk1twaRCHwnIl8AFbUbjTELHBKVUuq8UFZVQ7cu7h0dhmql5iaIFNuPh+1HKaWapE1Mzq3JBGEb\nveRrjHm0HeJRSp1HyrWJyak12QdhjKkBLm6HWJRS55lSrUE4teZ2UseLyGoRmSsi19X+NHWQiMwU\nkUMiclREnrSz/1IRiRORahGZ02hfjYjE235WNzNOpVQnop3Uzq25fRBeQC5web1tBvj4TAfYmqZe\nBaYBacAOEVltjEmoVywFuAOw13xVZoyJbmZ8SqlOxmIxVFRbtAbhxJqVIIwxd7bi3OOBo8aYRAAR\nWQ7MBuoShDEm2bbPYu8ESinnVV6tM7k6u+Y+Sb0Ea42hAWPMr89yWDDW5ydqpQETWhCbl4jEAtXA\nP4wxn7TgWKVUB6tbTU5rEE6ruU1Mn9d77QVcC2S0fTgN9DfGpIvIAGCDiOw1xhyrX0BE7gHuAQgN\nDXVwOEqplqhdC0Jnc3VezW1i+qj+exFZBmxq4rB0oF+99yG2bc1ijEm3/TdRRL4DRgPHGpVZBCwC\niImJOa2Go5TqOOW63KjTa+103xFAYBNldgARIhIuIh7ATUCzRiOJSICIeNpe98Q6zDbh7EcppTqT\n2vWovbWJyWk1tw+imIZ9ECeAJ852jDGmWkQeANYCrsBiY8x+EXkOiDXGrBaRccAqIAD4hYg8a4wZ\nDgwFXrd1Xrtg7YPQBKGUEynV5UadXnObmHxbc3JjzBpgTaNt8+u93oG16anxcZuBka25plKqc6it\nQXhpDcJpNauJSUS+ac42pZSqVa41CKd31hqEiHgB3kBPEQkAxLbLD+swVqWUskv7IJxfU01MvwV+\nB/QF4uptLwL+46iglFLOr0xHMTm9syYIY8xLwEsi8qAx5pV2ikkpdR6oew5CaxBOq7nDXBeLyJ9F\nZBGAiESIyM8dGJdSysmVaR+E02t2ggAqgUm29+nA/zgkIqXUeaGsqgZ3V8HdtbWPW6mO1ty/3EBj\nzAtAFYAxppSfOqyVUuo0ZVU1Os2Gk2tugqgUkS7YHpYTkYHUW5taKaUa07UgnF9zlhwV4DXgK6Cf\niLyHdeqLOxwbmlLKmel61M6vyQRhjDEi8hgwBbgIa9PSw8aYHAfHppRyYqcqtAbh7Jo73XccMMAY\n84Ujg1FKnT8yCsro082ro8NQ56C5CWICcKuIHAdOYa1FGGNMlMMiU0o5tbT8UmLCAjo6DHUOmpsg\nZjg0CqXUeaWwrIqi8mpCArp0dCjqHDR3Ntfjjg5EKXX+SM0rBaBfgHcHR6LOhT7BopRqc2n5ZQD0\n664JwplpglBKtbm0fK1BnA80QSilGjDG8Lvlu1i8KanB9q2JuTy0bBeHTxY3eY7UvFJ8Pd3w69Lc\nbk7VGelfTynVwM7j+XwSn8En8Rn07+FNZB8/nl29n68TTgIQl5LPp/dfTA8fzzOeIy2/jJDu3lif\ns1XOShOEUqqB97al4OvpRr/u3vxueTw1xroc/WMzhjC2fwC3Ld7OvHd3ct+UQUT09iHETjNSan4p\nYT26tnfoqo1pE5NSqk7+qUq+2JvJtWOCeX3uWLw8XBkf3p21v7uU+6cO4qIBPfjnnCjiUgq4c+kO\nJr/wLSm5pQ3OYYwhNa9MO6jPA1qDUErV+SgujcpqC7dMCKVfd2+2/fEKXFwaNhPNjg7mkkE92ZGc\nx7x349iWlEtoj5+SQd6pSsqqavQZiPOA1iCUUgAUl1ex5MdkxoT6ExnkB3BacqjVw8eT6cOC8PNy\nIy6loMG+1NohrjqCyek5NEGIyEwROSQiR0XkSTv7LxWROBGpFpE5jfbdLiJHbD+3OzJOpRQ891kC\nmYVl/Onqoc0q7+IijA4NIO54foPtdQ/JaROT03NYghARV+BV4CpgGHCziAxrVCwF67Th7zc6tjvw\nF6xzQI0H/iIiOqmLUg7y1b4TfLgzjfumDGJs/+7NPm5MaACHs4opKq+q21b7kJw2MTk/R9YgxgNH\njTGJxphKYDkwu34BY0yyMWYPYGl07AxgnTEmzxiTD6wDZjowVqUuaG9sTGRQoA8PXRHRouPG9PfH\nGNidam1mSs0rZdWuNHr5etLVU7s4nZ0j/4LBQGq992lYawStPTa4cSERuQe4ByA0NLR1USp1gTPG\ncDSrhKuj+uDh1rLvjNH9/BGBuOMFuLm4MO/dnViM4eWbRzsoWtWenDrFG2MWAYsAYmJiTAeHo5RT\nyi+torCsigE9W/7cgq+XO0N6+7J6dzqv/3CMYP8u/Pf2GPrrMxDnBUc2MaUD/eq9D7Ftc/SxSqkW\nSMwuAWBgL59WHT86NIBj2afo6ePJe3dP0ORwHnFkgtgBRIhIuIh4ADcBq5t57FpguogE2Dqnp9u2\nKaXaWGL2KQAG9Grdjf3qkX2ICunGu3dNINBPV5A7nzisickYUy0iD2C9sbsCi40x+0XkOSDWGLNa\nRMYBq4AA4Bci8qwxZrgxJk9E/oo1yQA8Z4zJc1SsSl3IjuWU4OHqYnfKjOa4JKInl0Rc0sZRqc7A\noX0Qxpg1wJpG2+bXe70Da/ORvWMXA4sdGZ9SylqD6N/DG9czPBSnLlz6JLVSF7jE7JJWNy+p85sm\nCKUuYNU1FlLySgnv2boOanV+0wSh1AUsLb+MqhqjNQhllyYIpS5giTm1Q1w1QajTaYJQ6gJWN8RV\nm5iUHZoglLqAHcs+RYC3OwFdPTo6FNUJaYJQ6gJljGHzsRyiQvw7OhTVSWmCUOoCdfhkCcdzS5k+\nvHdHh6I6KU0QSl2gvt5/AhGYNkwThLJPE4RSF6ivE04yup8/gb46f5KyTxOEUhegjIIy9qYXMn14\nUEeHojoxTRBKXYDWJZwEYLo2L6mz0ASh1AXoh8PZhPfsyoBWrgGhLgyaIJS6wFTXWNielMfEgT06\nOhTVyWmC6ABHs0p4ZEU85VU1HR2KugDtyyiiuKKaiQM0Qaiz0wTRARZ+d5SPd6WzP6Ooo0NRrfTt\noSyuemkjxeVVHR1Ki205lgvARZogVBM0QbSzwtIqvtiTCcCxrJIOjka11vLtKRzILOLT+IyODqXF\ntiTmEhHoQy9fz44ORXVymiAcqMZiKCitpLC0qq456ZP4dCqqLYjA0WxNEJ3BBztS+fuXB1ixI4WS\niuomy5dX1fDD4RwA3t+WgjHG0SG2maoaC7HJeVp7UM3i0CVHL1QFpZXctGgrB08U121zEbh+bD/i\nUvIZGdyNqhoLR7UG0eF+OJzN4x/tQQSMgW8OZLHotpizHvPj0RzKqmqYNqw36xJOsje90GnmM9qT\nVkBpZY12UKtm0QThAP/zxQGOZJXwwNRBdO/qgQGSc06xbHsK1RbD364dyY/HctibVtjRobapuJR8\nPFxdGBHcraNDaZackgoe+WA3EYE+fHL/xby84QiLfkgkOecUYT3PvD7C+gMn8fF04x/XjWTTkRyW\nbU9xmgSxalc6IjAhvHtHh6KcgCaINrbxSDYrd6Zx35SBPDpjSIN9d1wcxtr9J7huTDAni8pZszeT\n8qoavNxdOyjatlNcXsWvl+4gJKALnz84uaPDaZa/rN5PUXkV79w1nq6ebtx1cTiLNyWxdHMyz8wa\nbvcYi8Ww/kAWlw3uRQ8fT4U34eUAACAASURBVH4e1YdVu9K5e/IABnbyZwq+PZjFu1tTuGNSGD18\ntP9BNc2hfRAiMlNEDonIURF50s5+TxFZYdu/TUTCbNvDRKRMROJtP685Ms62YrEY/vzJPgb07MpD\nV0Sctn9gLx/umzIIL3dXBgX6YAwk5ZzqgEjb3tIfkykorSIho6hZ7fgd7Vh2CWv2ZnLP5AEM7eMH\nQKCfF7+I6ssHsakUltkfnRSXkk92cUXdBHePTB+Mt4cb978XR1ll5x22nF1cwWMrdxMZ5MuTV0V2\ndDjKSTgsQYiIK/AqcBUwDLhZRIY1KnYXkG+MGQS8CPxvvX3HjDHRtp95joqzLW1NyuV4bikPXxnR\nZK1gUKD12+b50A9RVF7FGxsT6e3nicVAfEpBR4fUpP9uTMTd1YXbJ4U12P7rS8Iprazh3+sPn9b5\nbIzhhbWH8Pd25/KhgQD06daFF2+M5tDJYp77fH97hd9i/9lwhMKyKl6+efR5UWNV7cORNYjxwFFj\nTKIxphJYDsxuVGY28Jbt9UrgChERB8bkUJ/sSsfH043pw5qeAC28Z1dc5PxIEEt/TKaovJqXbhqN\nCMQez+vokM4qu7iCj+LS+eWYkNOGeo4I7sbci/qz5MdkXtlwtMG+VbvS2Z6UxxMzI/Hzcq/bftng\nXtw6IZSVO9M6ZS0it6SCFbGpzI4OZnBv344ORzkRRyaIYCC13vs02za7ZYwx1UAhUDu8IlxEdonI\n9yJit1FbRO4RkVgRic3Ozm7b6FuovKqGL/eeYOaIILp4NP0NzcvdlX7dvc+Loa7rEk4yPrw7Fw3o\nwZDevuw8nt/RIdlVUV3D53sy+P2KeKpqLPxmcrjdcs/OGs51Y4JZsO4wn+22PudQVF7F39YcILqf\nPzfG9DvtmCsie1NVY9iV0jGfPauonOkvfs8jK+I5ntuw2fKtLccpr7Iw77IBHRKbcl6dtZM6Ewg1\nxuSKyFjgExEZboxp8OixMWYRsAggJiamQwejrz9wkuKKaq4d3TgHntnAXj5O/7BceVUNBzKL+M2l\n1ptPTFgAq+LSqa6x4ObauR6zeWb1fpZtT8Xf251Hrhx8xonqXFyEf84ZRUJGEa9sOMLVI/uw6PtE\nckoqWXLHeFxcTq/kjg0LwEVga1Iekwb1dPRHacBiMfzhw90czy0lJa+Uj3el4+HqgpurcPGgnuxI\nzmPasN4MCtTag2oZR/4fnA7U/6oVYttmt4yIuAHdgFxjTIUxJhfAGLMTOAYMdmCs5+yTXekE+Xm1\n6AGkQYE+JOacorrG4sDIHOtAZhHVFsOoEOvQ1nFh3TlVWdPgGZD2diy7hFve2EpGQVndttwSa7PS\n9WNDiP3TlTxoZxBBfa4uwrzLBnL4ZAkf7kxl8Y9J/DyqDyND7A/h9fNyZ1hfP7Yn5bbpZ2mOJZuT\n2Xgkh/m/GMYPj03l0emDuWtyONeODmZvWiFFZVXcO2Vgu8elnJ8jaxA7gAgRCceaCG4CbmlUZjVw\nO7AFmANsMMYYEekF5BljakRkABABJDow1nNSVWPhx6O53BATgqudb5dnEhHoQ2W1heN5pZ1+iOSZ\n7E61dkiP6md9DmBs/wAAdh7P77DnIVbFpbP5WC5/WrWXxXeMQ0RYviOVymoL91w6oNk1m59H9eGf\naw/xx4/3AvD7aWf/jjIhvAfvbj1ORXUNnm7t0xFcXlXDv9Ye4orIQG4ZH4qI8MDlPyW/v8425Jyq\n0FXjVKs4rAZh61N4AFgLHAA+MMbsF5HnRGSWrdibQA8ROQo8AtQOhb0U2CMi8Vg7r+cZYzptz+eB\nzCLKqmqICWvZw0eRQdbhlYc78Nv2udqdVkigrydBftYbULB/F4L8vIjtwH6Ibw9l4enmwreHslm9\nO4OqGgvvbDnO5IieRLSgk9bN1YV7Lh2AxcAvx4Q0mcQnhHenotrC7tT2ewAyLiWfsqoabplgTQ6N\nubiIJgfVag7tgzDGrAHWNNo2v97rcuB6O8d9BHzkyNjaUm2nbExYQIuOGxTogwgcPFHMVSP7OCK0\nFsstqaB7Vw+7Nxt7dqcWMKqff115ESEmLIDY5I7J51lF5ezPKOIP0waz/mAWf/x4L69+e5QTReU8\nf+2IFp/vxnH9yCmpYO7E/k2WHWf7grA9KZfx7fSk8tbEPFwExumT0coBOlcvopPaeTyfvt286NOt\nS4uO6+LhSliPrhzqJDWIo1klTPz7BpZuTm5W+cKyKhJzThHdr+E0EzH9A8gsLCe9Xh9Ae/nusHU0\n2xVDe/PyTdHMHBFEn25duG5MMFOGBLb4fF7urvxh+pBmfQsP6OpBZJAvWxLbrx9i67FcRgR3azDs\nVqm20llHMTmVuOP5jOnfstpDrSG9fTl0snMkiH+vP0xljYUlPyZz28SwJvtTaueSimrUcVvb1Bab\nnEdwdPNHdbWF7w5l0dvPk6F9fBERFtwQ3a7Xv3JobxZ+d5S0/FJCArxP22+MaXbtrClllTXEpxZw\n58VhbXI+pRrTGsQ5yigoI6OwnJjWJoggX5JzT3X46nIHMov4fE8mI4L9SMkr5fvDWWctb4zh20PW\nMlHBDWsQkUG+eHu4ttvzEDklFUz913fc/14cGw/nMGVwYJvdhFvq5gmhALy3LaXB9i/3ZnLnku0M\nnf8Vn+xqPJivdeJS8qmssejU3cphNEGco9qb4Nj+rWsDjgzyxRg4crJjn4dYsO4wvl5uLL1zPIG+\nnry1+fgZyx45Wcyc17bw5qYkpgzpRTfvhs0bbq4ujAkNYEdy+ySIdQknSco5xQ+HsymuqOaKoS1v\nSmorwf5duHJob1bsSK1L+su2p3Dve3EcySrBmLZ70nxrYi6uLqL9D8phNEGco53H8+ni7srQPq17\nCGlwkPW4gyc6bvnRk0XlrEs4yZ2Twujp48mtE/rz/eFsjmad3vS1PSmP6/5vM8k5p/jHdSN58/Zx\nds85tn8Ah04UtcuSnOsTThIS0IUdf76SlfMm1k2k11FumxhG3qlKFn53jP9uTORPq/YyZUgvvn10\nCkOCfDmeW9om19lyLJeRwd3w8dSWYuUY+i/rHO08nk90P/9WPzUc1qMrnm4uHO7AfogNB61NRT+L\nso6kumVCKG9uSuR3K+JZOW9S3eRuscl5/OrNbYQEdOHtX4+328ZeKyYsAIuBXSkFXDq4l8NiL6us\nYdPRHG4eH4qXu2uLhxo7wsWDehAR6MPL3xwBYEyoPwtvHYO7qwv9unuzL93+MNiKautKdVV2Hpwc\nFOjTYB6l3JIK4lLyuX/qIMd8CKXQBHFOisqr2J9RyIOXn/2p3LNxdREievt06JPHGw5mEezfhSG2\nG1AvX08W3BDN3W/H8uxn+/n7dVEAvPTNEQK83Vk5bxLdu3qc9ZyjQ61TT8Qez3dogth0NIeKakuH\n1xrqExHeu3sCybml+HVxY1Avn7ovEP27e7N23wmqayzUGMPCb49x1+Rw/Lzc+XRXBo9/tMfuOXt0\n9WDbU1fUnefLfSewGLg6qnMMj1bnJ00Q52Dn8Xws5txX5xrS248fjmS36QiX5iqvqmHTkRzmjA1p\ncO0rh/XmvikDWfjdMS4a0IOhffzYeCSHx2YMaTI5APh4ujG0j5/Dn4dYn3ASX0+3umcQOotAPy8C\n/U4fGtu/hzfVFkNGQTlHs4t56ZsjBPt34YZx/dibXoivpxsf3jsR4ae/xbakXOZ/up/t9eZ5+mJP\nJgN7da1L6ko5gvZBnINtiXm4uwqjQ1s3gqnWmP7+ZBdXdMjU31sTcymrqqlb36C+R6YNZkyoP09/\nso8XvjqEp5sLt4wPbfa5Y/oHEJ9a4LC5pqprLHxzMIvLhvTCw805/imHdrcuZZqSV8reNGu/074M\na5PTgcwiIvv4Ehnkx5Ag37qfOWND8HJ34av9JwDIKi5nW1IuV0f17bDRWurC4Bz/V3VS25JyiQrx\nb9b03mcz1fYAV21fQHvacDCLLu6uTLQzVNLN1YUFN0RTVWNYf+Ak140JIaAZtYdaY8O6U1pZw4FM\nxzSfvbXlODklFVzTzs9anIv+Paz9NsfzTrHX1hexL70QYwwHTxTXTb9Sn7eHG5cN7sVX+05gsRjW\n2pqXfq7NS8rBNEG0UmllNXvTCttkSoW+/l2IDPJt9wRhsRi+OZDFxYN6nHGVsbCeXXlm1jD8vNy4\n65KwFp2/9tmQxsM6809VkllYRkFpZaviBsgsLGPB14eYOqRXhw5rbanefl54uLqQklvK/rqaQzHH\nc0spqaiuW/60satG9CGruIKv9p9gyeZkIhp1WivlCNoH0UJVNRZKK2vYm1ZItcWcc/9DrSuGBvLa\n94kUllXRrUv7TJuw6WgO6QVlPD5zyFnL3TgulOvGhODewpFaff27EOzfhdjkfO68OJw9aQW8suEo\n6xJOAiACXz18KUOCWn6je+6zBKothudmj3CqZhZXFyGkexfiUvLJLCxnaB8/DmQWsWZfJgCRZxgu\nPTUyEHdX4b734ujq4cprc8e2Z9jqAqU1iBZ6ZvV+xvx1HU98tAcX+Wl663N1eWQgNRbDxiPttzLe\nsu0pBHi7M3NE00uktjQ51BrbP4DY43lsPJLNNa/+yPakPO6fOpBnZw3HGOvUGC315d5Mvtx3goeu\niKBf9zMPte2s+nf3rpvt9qZx1iVTVsamIcIZO527dXFn5og+hHb35qP7JjE5wnEjw5SqpQmiBYrL\nq/g4Lp0hvX2ptli4eFBPfNtokrTofgEEeLvzxsYkfvN2LC+uO9wm5z2TrGLrw3FzxoY4dO2CmLAA\nThZVcN97cQwK9GHjE1N5bEYkt08KY1CgD5uPtWxiu7xTlTz96T5GBPtxz6XOuYRm/x5dMbb1D2dH\n98XTzYXEnFP07+5N17M89PbiDaP47tEpdvsplHIEbWJqgdW7MyirquFv142sW0Gtrbi6CNOHBbEi\nNhVfLze+OWC9eTvqG/KHsWlUWww3t2BUUmvU1rBqLIaFt45tMOvopIE9WLkzjaoaS7NrKH/9PIHC\nsireuWtCq2s1HS3U9jcN79kVf28PhvbxIz614Iz9D7U62xKu6vyn/+JaYMWOVCKDfBkV0g0RafO2\n72dnD2f7U1fw9e8vxUWEJT8mt+n5ayVml/DfjYlMHNDjjOsyt5XIID+mD+vNghuiGRTY8FoTB/Sg\ntLKGPWkFzTpXTkkFn8anc8eksCZvpp1ZbYKoXXFvRLD1s2jNQHU2miCaaX9GIXvSCrlxXD+HdYp6\nubsS6GddV+LnUX1YsSOFwrK2ncvoZFE5c9/cjosIf7tuZJue2x5XF2HRbTF2+zlqZyHdfLR5zUxr\n91uHd147OqRNY2xvYT2tz0KMtCWG4X2tiaK183kp5SiaIJpp9e4M3F2l3cbc3z15AKcqa1jyY1Kb\nnfNkUTm3/ncbBaWVLL1zPOG2G1VHCehqbV45Wz9ESUU1haXWJPnFnkwG9OzaaW+kn3zyCSLCwYMH\nz1puYK+uvDAniptszXszhgdxy4TQuqekWyMsLIycnJzTti9evJiRI0cSFRXFiBEj+PTTTwGYMmUK\nsbGxrb5ee4mPj2fNmp8WpVy9ejX/+Mc/HHa9mTNnMmrUKIYPH868efOoqTl9Gn5jDA899BCDBg0i\nKiqKuLi4ulgnTpzI8OHDiYqKYsWKFXXHJCUlMWHCBAYNGsSNN95IZaV1iPeCBQsYNmwYUVFRXHHF\nFRw//tMsym+99RYRERFERETw1ltvnRbHrFmzGDHip1USb7zxRqKjo4mOjiYsLIzo6DZYC8UYc178\njB071pyrHUm5pqyy2u6+Wa9sNHP+78dzvkZL3LV0h+n/xOfmiZW7zamKqnM6V2reKXPpCxvMsKe/\nNFuP5bRRhOfuuc/2m4g/rTErdqSY9PzSBvtSck+ZSX//xkx4fr3Zl15gwp/83Pxr7cEOirRpN9xw\ng7nkkkvM/Pnz2/3a/fv3N9nZ2Q22paammgEDBpiCggJjjDHFxcUmMTHRGGPMZZddZnbs2NGqa1VV\nndu/xZacb8mSJeb+++9v0+udTWFhoTHGGIvFYq677jqzbNmy08p88cUXZubMmcZisZgtW7aY8ePH\nG2OMOXTokDl8+LAxxpj09HQTFBRk8vPzjTHGXH/99XXn+u1vf2sWLlxojDFmw4YN5tSpU8YYYxYu\nXGhuuOEGY4wxubm5Jjw83OTm5pq8vDwTHh5u8vLy6mL46KOPzM0332yGDx9u93M88sgj5tlnn23W\nZwZizRnuq1qDsNmbVsic17Zw55IdlFZWN9hXUlHNvowiJoS378IsC28dw71TBrIiNpVnVye0+jxJ\nOae44bUt5J+q5N27JzChEy0wc31MCP5d3Hl85R4m/WMDc9/cxvvbUvhkVzo3LdpKSUU1xeVV3PDa\nlk49OV1JSQmbNm3izTffZPny5XXbv/vuO6ZMmcKcOXOIjIzk1ltvxdiGMIWFhfGXv/yFMWPGMHLk\nyLqaxzPPPMO//vWvunOMGDGC5ORkAK655hrGjh3L8OHDWbRo0VljysrKwtfXFx8fa9+Pj48P4eHh\ndfs//PBDxo8fz+DBg9m4cSMAycnJTJ48mTFjxjBmzBg2b95c9zkmT57MrFmzGDZsGMnJyXWfZ+jQ\nocyZM4fSUus05jt37uSyyy5j7NixzJgxg8zMzNNiu+OOO5g3bx4TJkzg8ccfZ/v27UycOJHRo0cz\nadIkDh06RGVlJfPnz2fFihVER0ezYsUKli5dygMPPFAX6+WXX1737TslJeW067SUn5+12a+6uprK\nykq7zcmffvopt912GyLCRRddREFBAZmZmQwePJiICOvEnX379iUwMJDsbOscaxs2bGDOnDkA3H77\n7XzyyScATJ06FW9va5/URRddRFpaGgBr165l2rRpdO/enYCAAKZNm8ZXX30FWP+tLViwgD//+c92\nP4Mxhg8++ICbb775nH8fmiBs4lKs49K3JuVyx+IdlFT8lCRik/OosZh2X7nLw82FJ2ZGMmdMCF/s\nzWzVqnNHThZzw+tbKK+2sOyei8553qi2Fhnkx7anrmDt7y7ld1dGcCyrhKdW7eV3K+Ipqajmvbsn\n8PLNoymrqmFAJ56c7tNPP2XmzJkMHjyYHj16sHPnzrp9u3bt4t///jcJCQkkJiby448/1u3r2bMn\ncXFx3HvvvQ2SwpksXryYnTt3Ehsby8svv0xu7pmb50aNGkXv3r0JDw/nzjvv5LPPPmuwv7q6mu3b\nt/Pvf/+bZ599FoDAwEDWrVtHXFwcK1as4KGHHqorHxcXx0svvcThw9Yh2IcOHeK+++7jwIED+Pn5\nsXDhQqqqqnjwwQdZuXIlO3fu5Ne//jV/+tOf7MaXlpbG5s2bWbBgAZGRkWzcuJFdu3bx3HPP8dRT\nT+Hh4cFzzz3HjTfeSHx8PDfeeGOD4x988EFuv/129uzZw6233tog1lrffvttXbNL/Z9Jkyad8fc2\nY8YMAgMD8fX1rbup15eenk6/fv3q3oeEhJCe3nCVwO3bt1NZWcnAgQPJzc3F398fNze3M5YHePPN\nN7nqqquavMbTTz/NH/7wh7rE0tjGjRvp3bt3XbI6Fw4d5ioiM4GXAFfgv8aYfzTa7wm8DYwFcoEb\njTHJtn1/BO4CaoCHjDFrHRnr7rQCevp48uys4Ty0fBe3vbmNpb8ej5+XO1sT83BzEcb092/6RA4w\nK7ovH+5M47tDWcwc0fxv0BkFZcx9czsAK+65iIhOenMVkbqJ6R68PIKMgjLKq2oI9POiWxd3RgR3\nY8md4/Hzcuu0T00vW7aMhx9+GICbbrqJZcuWMXas9Wnn8ePHExJi7ViPjo4mOTmZSy65BIDrrrsO\ngLFjx/Lxxx83eZ2XX36ZVatWAZCamsqRI0fo0cP+FxdXV1e++uorduzYwTfffMPvf/97du7cyTPP\nPHPatWtrKFVVVTzwwAPEx8fj6upalwxqP0f9Gki/fv24+OKLAfjVr37Fyy+/zMyZM9m3bx/Tpk0D\noKamhj597P+bvf7663F1tT6DU1hYyO23386RI0cQEaqqmh6csWXLlrrf2dy5c3n88cdPKzN16lTi\n4+ObPFd9a9eupby8nFtvvZUNGzbUfZbmyszMZO7cubz11lu4uDTvO/i7775LbGws33///VnLxcfH\nc+zYMV588cW6v1ljy5Yta5PaAzgwQYiIK/AqMA1IA3aIyGpjTP22kruAfGPMIBG5Cfhf4EYRGQbc\nBAwH+gLrRWSwMcZhCzfvTi1gVEg3ro7qg6uL8OCyOOb+dxvv3D3BNilfN7w9OuaxkYkDetDTx4PV\nuzOanSAKS6u4Y8l2TlVU88G8iZ02OTTm6iJ2n/24zIFrSpyrvLw8NmzYwN69exERampqEBH++c9/\nAuDp6VlX1tXVlerqn2qntfvqb3dzc8Ni+WkG3PLycsDazLN+/Xq2bNmCt7c3U6ZMqdt3JiLC+PHj\nGT9+PNOmTePOO++sSxD2rv3iiy/Su3dvdu/ejcViwcvrpynLu3btetq5G783xjB8+HC2bNnSxG+t\n4fmefvpppk6dyqpVq0hOTmbKlClNHt8c3377Lb///e9P2+7t7V3XfGaPl5cXs2fP5tNPPz0tQQQH\nB5Oamlr3Pi0tjeBg6+CVoqIirr76ap5//nkuuugiAHr06EFBQQHV1dW4ubk1KA+wfv16nn/+eb7/\n/vu6v0lwcDDfffddg2tMmTKFLVu2EBsbS1hYGNXV1WRlZTFlypS6stXV1Xz88ccNarDnwpFNTOOB\no8aYRGNMJbAcmN2ozGygtnt+JXCFWP/VzQaWG2MqjDFJwFHb+RyiuLyKxJxTjOpnrSHMHBHE/906\nlv0ZRdy9NJY9aYUdujC8m6sLPxvZh28OZDVo+jqbJZuTOJpVwuu3jXXqZwacwcqVK5k7dy7Hjx8n\nOTmZ1NRUwsPD69r1WyosLKxuZExcXBxJSdaRbIWFhQQEBODt7c3BgwfZunXrWc+TkZFRdx6wfvvs\n37//WY8pLCykT58+uLi48M4779gdxVMrJSWlLhG8//77XHLJJQwZMoTs7Oy67VVVVezfv7/Jz1xY\nWFh301y6dGnddl9fX4qL7c8GPGnSpLr+nvfee4/JkyefVqa2BtH4x15yKCkpqesvqa6u5osvviAy\nMvK0crNmzeLtt9/GGMPWrVvp1q0bffr0obKykmuvvZbbbrutQdOUiDB16lRWrlwJWEcnzZ5tvRXu\n2rWL3/72t6xevZrAwJ8mnZwxYwZff/01+fn55Ofn8/XXXzNjxgzuvfdeMjIySE5OZtOmTQwePLhB\nIlm/fj2RkZF1NdZz5cgEEQyk1nufZttmt4wxphooBHo081hE5B4RiRWR2Ozs1s9htDe9EGMgqt7T\n0VcO682/rh/Fdlv/Q0d37M4a1ZeKaguf785osL2qxsKetIK6js9a8akFDO7ty6SBrR86qZpn2bJl\nXHvttQ22/fKXv2TZsmWtOt8vf/lL8vLyGD58OP/5z38YPHgwYB2CWV1dzdChQ3nyySfrvqGeSVVV\nFY8++iiRkZF1nbwvvfTSWY+57777eOuttxg1ahQHDx48rdZQ35AhQ3j11VcZOnQo+fn53HvvvXh4\neLBy5UqeeOIJRo0aRXR09Fm/qdd6/PHH+eMf/8jo0aMb1LCmTp1KQkJCXfz1vfLKKyxZsoSoqCje\neeedJj9bU06dOsWsWbOIiooiOjqawMBA5s2bB8Brr73Ga6+9BsDPfvYzBgwYwKBBg/jNb37DwoUL\nAfjggw/44YcfWLp0aV1fR23z1v/+7/+yYMECBg0aRG5uLnfddRcAjz32GCUlJVx//fVER0cza9Ys\nALp3787TTz/NuHHjGDduHPPnz6d796YnBl2+fHmbNS8BSOMbS5udWGQOMNMYc7ft/VxggjHmgXpl\n9tnKpNneHwMmAM8AW40x79q2vwl8aYxZeabrxcTEmNaO6/6/747xv18dZNfT005b7+CdLcmsjEtn\n2W8mdFgTE1in5p796o8cOlHMyzePZkx/f77ef5LXfzhGal4ZS+8cxxTbuhLGGMY9v54pQwL51/Wj\nOixmdf5KTk7m5z//Ofv27evoUNQ5EpGdxpgYe/scecdLB/rVex9i22avTJqIuAHdsHZWN+fYNrMn\nrYDQ7t52F8OZOzGMuRPDHHXpZnNxEd65azx3Lt3Bve/trJvsbVRIN04UlrMtKa8uQZwoKienpJKR\nwW07X5RS6sLiyASxA4gQkXCsN/ebgFsalVkN3A5sAeYAG4wxRkRWA++LyAKsndQRwHZHBbonrZDR\noR0zQqkl/L09eO/uCSz89hg+Xm5cMqgnw/v6ce3Czey0TR8N1mc64Ke5fpRqa2FhYVp7uAA4LEEY\nY6pF5AFgLdZhrouNMftF5DmsT+6tBt4E3hGRo0Ae1iSCrdwHQAJQDdzvqBFM2cUVpBeUcefFYY44\nfZvz9nDj0RkNF/gZ2z+Ad7cer5sVdW96IS4Cw7RzWil1DhzaqG6MWQOsabRtfr3X5cD1Zzj2eeB5\nR8YH4OvlxpI7xp0206gzGRMawJubkkjIKGJUP3/2phcSEeh7zmtlK6UubBf8k9Re7q5MjQx0ypXJ\natU+wBeXko8xhn3phdq8pJQ6Zxd8gjgf9OlmXft55/H8eh3U2ryklDo3miDOE2P6BxCbnM+ybdYJ\ny0a28Yp3SqkLjyaI88TYUH9OFJXz8oajjA/rrk1MSqlzpmtSnyd+MaoviTmnmDk8iIkDe3TaSe2U\nUs5DE8R5ooePJ8/NHtF0QaWUaiZtYlJKKWWXJgillFJ2aYJQSilllyYIpZRSdmmCUEopZZcmCKWU\nUnZpglBKKWWXJgillFJ2OWzJ0fYmItnA8XM4RU8gp43CcYbrXqjX1s+s1z5fr9ta/Y0xveztOG8S\nxLkSkdgzrct6Pl73Qr22fma99vl6XUfQJiallFJ2aYJQSilllyaInyy6wK57oV5bP7Ne+3y9bpvT\nPgillFJ2aQ1CKaWUPQZGDwAAEe5JREFUXZoglFJK2aUJQp0T6cCl6y7Ua7en+p/zQvnMnUVn+H1r\ngjhHIjJQRHw7Oo72JCLTReRvAKadO7FEpKeI+NReuz3/JxKR3iLSs72vLSKDRcSrPa5lR4CIuELd\nZ26Xe4aIXC4iv22Pa3UmHfn/lj2aIM6BiFwFrAK6d8C1LxWRS9rrf9h6150OvAZMEJGIdr72TOBz\n4GURWQTt9z+R7W/9FfAfEXmt9tqOThIiEgocBO4XkQBHXsvOtWfx/9s793ArqvMOv9+5cBMOiKBB\nDaZCg3L3ioLKRQLeAgdBTUUR8ZZoaoqKqSampuZRq9bYCkmNqdjEpioI1qIYamKiMU8NqYo3NJjE\nqghqYiAS4g2+/vGtbaa7+8A5sGbPnj3f73nmYa+Z4bzzm5k135q11qwFD2GebwVQ1a1V4t4MrC1b\nn3pAzipfBXZmeasteYDYQYnIp4AbgAtU9X9KpazE9tRuZhEZC/wIuB67mapVqpsMXANcjA1rclw1\nuIE9EbgR+CpwHdBdRLoltqd2DkRkFPD3wDzgy7bKeFUoVb8H/AI4FpgtIr1SZH2k8IC6CrvWVwH9\nReS+0ttbWp5FpDNwEnC+qi4Tke4i0hvSLwxkla8CO7O8tS15gOigxNQTuAB4WFUfFZHdga+IyFwR\nORPSu5lFpBMwEJgOfBf4CnB4yg9ICR4vBC5S1aXAd4DzROTAtLgJ9i7AQcDnVHU50ASMBuaKyA1g\nJdsUg3I3YLGqPgQ0Yg/ra0RkYdpsVX0D+DZWoj4OmC4io0Vk/zR4CW0A1gCrVfV1VZ0MbAL+LRxX\nWp63AD2BRhHZA3tjvE1EHhSRwZBO4UtEmrF8dSJVyleBm8xbc6uZt9ojDxAdlJo2AguALiJyBfAw\n9uDoAUwUkQtT5L8P/AewQlW/AfwA+BIwpvwtJiJTVfVNYKaq/jhkpp8C9wFDAVJm/wGYH9gtwOXY\ng2opMFJE7intm8YxAB8AM0TkSqzK5Vbsod0/bXZ4QH0CEGAq8DngUeDjKbAk/NuEPah/B3w0ppCq\nngp0FpH5IR3ds6p+CNwLDMPe1u5Q1VbgeewNMiq35FlVP6DK+SpwS3nrdFV9pJp5q70H6Es7F2AE\nMA3YI6QPweqlLwjpJuAs4MoU2MOwEuRehA8cE9vmAQ9gJaAzsVJ+LO5hwHnBe7+wrvSB5TnAs8Au\nKZ3vg4EzgAOBXcO6TsDQxD4fA/4FaI7MPgw4FxgR0gcAk4HvJPbpCdwBdI3seVbwvFtYNwqYiQWK\nV4H/Bs4HWiJ77leWPiWwjkisGwjclMJ1LnneJaT/Hfg+MDqx33Jg38jsPmVpSfxOLV+Fvz8MOD7k\n6eaybanmrXYfY5bwPC3AFOAVrOS6DPgbYA+gJXlxgYuA20KwkEjs47GGykXY28rYsD7JnQ28jNVf\nDo3IfRn4ZngILwQOLttnIdYuEMVrGfv58PfvAWa1sd/ZwAqgW2R2yfcd4RgODNseAAaH32cAPwG6\np+B5SckzcGi499YD44E9sVL2bhE9TwW2ApdUOL8/x6pe+gNzsBJulPNd5nlpwvOx2NvavBAwpgGr\nInuegjWEz0msE6AhkY6erxK+S3n6h4k83ZTYJ5W81aHjzAqcpyXcNDcBx4b0eKyOcgHw54n95gBP\nAvtHZB8QMtChIX0p8Ghie0P4txXYWHp4RWJfiVUrAQwCPg/cDxyU2Ods4OtAl4jcoVjp6ZCQPh2r\nVumc2KcLVqp7KqbnNnz/ZfDdPzDfxoLHM8CQanjG3hiOT/qP6HdvLPB9EXgNmFe2fTrWBrIE+Bkw\nPEXPjyU8jwXmYnXyy2Nxw98eADyBNcA/ThtBIqV81d48HT1vdfhYswLnbcGi+dcT6eFYHellWLXH\n4HBzR3lgJDj7An9Rtm4ZocolpDuHB1ds9tXArYl0nxAkbgH6hnUtlFVNROD2DA+LZEluGTAokd4H\nawuIGhy24ftC4JaQPgoYB/xZFTzvX7ZfY3iARStVYm2Rk8PvwcBbFYJEZ2BXYPcMPHcBekW+xo3A\n1PD7aKygMadsn04p5avt5umwrgXYMya7w8eaJTxPC1b/uxg4LbFuEtYG0bt0QVPgNgA9Er+bsFf+\nQWHdPmFdQwrsXsAjJKodsFLfncAnUzrPpfaN5vBvY/j3R8Dh4fcQoJnEG0WVfC9Kw/d2PI9OeO6d\nFrvsOPZPBgmsDWTvjK5zn5jc8Hf/X17BagWeAs4K6cFYe0j06p125uko1ZY7u3gvpvZrPfaAGCci\nswBUdQXwR6yxGuCd2FBV3aqqpb/bBCjwe2C9iJyMvYJ208gfMIlIg6puwF5/x4jIF8PxPIv1cEll\nxiwNOUStVwlYSQ/gTWCdiEzDvj/pqarvxeZvx/f7pOB7O55fD56vI3KvQxGRErt0HCLSrKqrsbek\nL4jIcmA+ds2jc7dzna+LxUyqUl5R1Yex9sOzRGQx9pbcJXl+YvK3k6dvpEZ6mPpw39uQiDSq6pZE\nujvWeHYK8AZWf3opcKSqvpYWuzwji8g3sQw1HDhXVZ+OwGtoK8iIyCHA32GNdWuwutGJqvrrneW2\nxa7g+QasZNsHOFtVn4nE7gtsVOs+XL4tNd+VuFX0PAh4U1V/1xY7rPtbrO1jfAx2e7hpeS47DgnB\nsJLnfwQ+A3xKVVdVi51Gno6hmohStSQRGS8iXwNQ1S0i0pjoh7w7Nhn5hVjf+L2B1ljBoQ12Q7ih\n9hORI8OuQ4AZWN/pGMFhCnBt8qOg0m8RGYrVPU/Bel18iHmOFRwqsoPn4aEkCXaux2KNx7EelK1Y\nR4P+iW8AUvfdFrdKnidhfeyPCummMvbUsH4EcDgwIVJw2B43Tc/jRORyEZkpIrsFZjJfjQn7jQKO\nAI6OFRzawU4lT0dT1nVctbJgDX+dsO6DfwCuL9s+HntjGJUBe1ySDUwg0WC7k+zJWG+OiRW2TcB6\n6oxL6Zxviz0+sI8K6QFErP/Huo6+QOheWLbt6LR8t5ObludJ2HcNK4DvlW0bG9hjQrqBSPX/7eSm\n5fnTWPfYa7Euy8cktk0I+ergkG4iYoeLdrKj5+mYi1cxlUlETsT6mR8JbFDV80Kp8hzgN6p6T6VX\n02qxI/OGY1+PzlXVJWJj3gzAunG+jvV9f09VF8f23EF2m9VfO8E/GThMVS8SGxBvHPAu1hNtFNYf\n/e4UfLeXG9WziIwDbsfegp4SkZ8C31bV28L284H14Vr8n6rVKnJje+6KfZN0k6o+LiJfxQpg92P3\n2QlYPlsU03NH2bGYaagp6wOoFSUeBM1YP+VLsFEs78Wqk2aq6vtpBIcM2euBF4E9xcZ9uRnrvbIV\nWA1co6qbUgqIHWGnMYLoJqxxEOBfgecC+2Jghqq+mpLv9nJje14LnKKqT4X097CADIDa8BKlezHa\ng7KD3Niet2JtGceIyFrsa/RVWBtHd+BiVX0lBc8dZdduKT3rV5isF6wvdksi3Qm4LvyeToj69cQO\n3FLX3H5YSf5l4Jywbgz28DqgDtkt4XdfLEAtIwyVEtZfC3y2HrgJ9q4V1g8N5/2Y2MwsuQl2r/B7\nCPZ2thwrdIB98LiA8B1EvbDTWArdSC0iM7CuqytEZI6IDMO68/UW68FxNdYg3U3CqKF5Zye4D4jI\nuWH1acClqloa8/8x7G3mY7G4NcRekWAfi30pPSGx6xbsA6Vcc8vYyxP3GPBRt92rgZkSeQjxrLhl\n7AfFJhx6W1XHYF+Krw3H8Ap2j+1VL+y0VNg2CBHZC4vsZ2BRvxWrC16Cfel4Ffah0L1h38ZwcXPL\nrsCdhs03sEhVVyb2mw5cAUxJ0XNW7BasfeOPwN3Yef8hf+rrPwOr0nshr9w22NOAzcCDqvpI2GcE\n8A9Yd9KX8sytwC7dY5ux870Jq8Z8APvWYh7wGVVdk3d2mipyG0QXrArnabUupa8DJ2Mjpq4ETlDV\nF0Md4dpt/aEcsdvitorIO6r6gojMxoYPOTHWA7oG2esC+2SsNHsQ1qOqN/alfJSHdIbcbbEni8hb\nqrpaVVeJyM+w+vK8cyuxS/fYScBd2Eelf4UNY35m5Ad0luz0lHUdV5YLNuDa5YTBsID9wrrTQjq1\nURSzYlfgDgrrSqNo7gsMLBB7Thq8rLntOd/1xm3nPdaJ9IZoyYyd1lLINgiRj2akuhfraXCqiHRV\nK8EtwaZ27KbhqtYDexvcFwN3loj0UNVfacTX/hywTxWbsS6qsuK2kz1LEtO15p3bDvbSwO6uqu9r\n5CFasmSnrUIFiMSFLOlhbHjuwcBlYrM57YrVHcbud58Ju4PcD4ioHLGjjjOUBXcH2FndY1nkq16B\n/WG9sKulQrRBiI0BswkbbO0tVVURaVL7tuA/seEzTsCmGdwF63L5bp7ZRfScJds9F8Nz1uyqK+s6\nrrQX7HP3n2Ovel/GJqAvDS08Efhnwhj32Dgw0cadz4pdRM9+vt1zvbOzWDI/gFTNWSPRs9jcrweG\ni1qa57cFm0nqpHpiF9Gzn2/3XO/srJZ6r2LqA7ymqs+IDdU9AFggIr/CBg87TlV/G7qTxm6Qzopd\nRM9Zst1zMTxnzc5E9d5IvRLoKiIPAb/ERlS8ERsMbhzwgYShd+uIXUTPWbLdczE8Z83ORlm/wsRe\nsHq/nol0F2yM9+8m1u2HjU0fdQrHrNhF9Ozn2z3XO7sWlrp6gxCbiOUhbNrAvgCq+q6q/gTYJCJ/\nHXYdiHU/a6z8l/LDLqLnLNnuuRies2bXiupmLKZwAe8EXgFew6YEvVNVfxO2TwI+D/QAdsO+WI4y\nc1NW7CJ6zpLtnovhOWt2LameAkQnrJfBL7A+yEcBLwF3q+obYXsXbM7XX6rquryzi+g5S7Z7Lobn\nrNm1pNwHCLFZudZjM3FtTqyfjk1nuEZVbxaRkfqnSUtyzS6i5yzZ7rkYnrNm16Jy3QYhIsdjQ+jO\nBxaKyH6lbWrTc/4Y6Cs2M9ujIrJn3tlF9Jwl2z0Xw3PW7JpVNVrCYy+AAB8nTCwP7IFN07kOGFK2\n7x3YDFbD8swuomc/3+653tm1vmR+ADtxURuBb2EzM5Wqyr6Azdz0yZDuBzwPjKwHdhE9+/l2z/XO\nruUl8wPYgQs5EDgE6zlwFzZdZXL7pcDtQNeQ7p53dhE9+/l2z/XOzsOS+QF08GKeADyN1QXOB6Zg\nr3uXJfb5BHALkSfcyYpdRM9+vt1zvbPzsuRmLCYRGQ1cD5yqqk+KyLeAQ4HRwH+JSCPWb/kIbCrH\nXtj0frllF9Fzlmz3XAzPWbNzpawjVAei/WhgdiLdF7g//N4XuA34BjZoVtQGpKzYRfTs59s91zs7\nT0vmB9CBC9oItCR+743N3tQvrNsHmwCpZ72wi+jZz7d7rnd2npbcfAehqltU9fchKcAG4G1VXSci\np2GThTer6sZ6YRfRc5Zs91wMz1mz86Rcf0ktIrdjfZUnYa+Lz9Q7u4ies2S752J4zppdq8plgBAR\nAZqB1eHfo1V1TT2zi+g5S7Z7LobnrNm1rlwGiJJEZDawUlWfKwq7iJ6zZLvn6qqo7FpV3gNEZlP7\nZcUuoucs2e7Z2UVWrgOEy+VyudJTbnoxuVwul6u68gDhcrlcroryAOFyuVyuivIA4XK5XK6K8gDh\nckWSiFwpIpdsY3uriAyu5jG5XDsjDxAuV/XUCniAcOVG3s3V5doJiciXgDOAN4FXsdE/NwLnAp2A\nl4DTgZHAsrBtIzA9/IkF2Eiim4FzVPWFah6/y7UteYBwuXZQInIQNtvYKGzkzyeAfwIWqupvwz5f\nA95Q1ZvDWD/LVHVx2PYD4LOqukZERgHXqOqE6jtxuSorNxMGuVw1qCOBpaq6GUBE7gvrh4bA0Avo\nDny//D+KSHdsToJFNhQQAJ1TP2KXqwPyAOFyxdftQKuqrgrj+4yrsE8DsEFVR1bxuFyuDskbqV2u\nHdcjQKuIdBWRHsCnw/oewDoRaQZmJvZ/J2wjzEXwaxE5CWwcIBEZUb1Dd7m2Lw8QLtcOSlWfAO4C\nVgHLgZVh0xXA48BjQLLR+U5gnog8KSIDsOBxloisAp4Dplbr2F2u9sgbqV0ul8tVUf4G4XK5XK6K\n8gDhcrlcroryAOFyuVyuivIA4XK5XK6K8gDhcrlcroryAOFyuVyuivIA4XK5XK6K+l8u7afUtHvU\nowAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOEQgWfCi8gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(model_lstm.state_dict(), 'Best_LSTM.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}